[{"content":"本节中, 我们主要考虑PPT时间内的随机算法的去随机化, 当问题是判定问题时, 能被这样求解的问题即为$\\mathbf{BPP}$问题.\n枚举 枚举是相当简单的, 对于$L\\in\\mathbf{BPP}$的一个PPT算法$\\mathcal A$, $\\mathcal A(x)$其用到的随机比特数必然是$\\operatorname{poly}(|x|)$, 因此, 我们可以用一个确定性算法来判定$L$, 该算法\n 枚举这$2^{\\operatorname{poly}(|x|)}$个随机比特$r\\in{0,1}^{\\operatorname{poly}(|x|)}$, 计算$\\mathcal A(x;r)$ 统计满足$\\mathcal A(x;r)=1$的$r$所占的比例, 如果达到$\\mathcal A$要求的输出$1$的阈值, 则输出$1$, 否则输出$0$.  显然, 上述算法能够正确判定$L$, 而其运行时间是$O(2^{\\operatorname{poly}(|x|)})$, 因此我们可以证明$\\mathbf{BPP}\\in \\mathbf{EXP}$, 即\n 定理\n$\\mathbf{BPP}\\in \\mathbf{EXP}$.\n 一个比较惊人的事实是, 我们目前无法证明$\\mathbf{BPP}$和$\\mathbf{NP}$的关系, $\\mathbf{BPP}\\subsetneq \\mathbf{NP}$, $\\mathbf{NP}\\subsetneq \\mathbf{BPP}$或者$\\mathbf{BPP}=\\mathbf{NP}$都是可能的.\n非一致性 我们可以证明$\\mathbf{BPP}\\in \\mathbf{P}_{/\\operatorname{poly}}$, 即可以用一个多项式大小的电路族来判定任意$\\mathbf{BPP}$问题. 证明的方式也很简单: 只需要证明对于每个长度的输入, 都有一个$L\\in\\mathbf{BPP}$的某个算法$\\mathcal A$中用到的随机串$r$, 满足$\\mathcal A(x;r)=1\\iff x\\in L$. 如此, 就可以把这个$r$作为advice.\n具体可以参考文章Averaging Argument.\n非确定性 虽然$\\mathbf{BPP}$和$\\mathbf{NP}$的关系是未知的, 但是我们可以证明$\\mathbf{RP}\\in\\mathbf{NP}$.\n对于$L\\in\\mathbf{RP}$问题来说, 可以构造一个算法$\\mathcal A$判定$L$, 且该算法没有$0$-sided error, 即永不可能在$x\\notin L$时输出$1$. 那么, 对于任意$y\\in L$, 我们认为$r$是$y$的witness, 如果$\\mathcal A(y;r)=1$. 这样一来, 任意$x\\notin L$就每一任何witness, 方可证明:\n 定理\n$\\mathbf{RP}\\in\\mathbf{NP}$.\n 对于$\\mathbf{BPP}$的讨论会复杂一些. 如果读者熟悉计算复杂性的话, 我们可以证明$\\mathbf{BPP}\\in\\Sigma_2\\cap \\Pi_2$. $\\Sigma_2$和$\\Pi_2$是落在$\\mathbf{PH}$第二层的复杂性类, 前者包括所有形如$\\exists y\\forall z.P(x,y,z)$的论断, 后者包括所有$\\forall y\\exists z.P(x,,z)$的论断.\n 定理\n$\\mathbf{BPP}\\in\\Sigma_2\\cap \\Pi_2$.\n 该定理的证明思路是这样的, 我们将任意$L\\in\\mathbf{BPP}$用某个出错率低于$2^{-n}$的算法$\\mathcal A$来表示, 假设其使用$m$个数基比特, 定义 $$ A_x={r:\\mathcal A(x;r)=1}\\subset \\lbrace 0,1\\rbrace^m $$ 那么对于$x\\in L$, 其$A_x$就比较大, 我们定义$A_x$的偏移 $$ A_{x;s}={r\\oplus s:r\\in A_x}\\subset \\lbrace 0,1\\rbrace^m $$ 这样, 选取少数个$s_1,\\cdots, s_m$, 我们就有把握使得$A_{x;s_1}\\cup \\cdots\\cup A_{x;s_m}=\\lbrace 0,1\\rbrace^m$. 对于$x\\neq L$, 由于其每个$A_{x;s}$都很小, 我们有把我认为无论我们如何选取$s_1,\\cdots, s_m$, 都有$A_{x;s_1}\\cup \\cdots\\cup A_{x;s_m}=\\lbrace 0,1\\rbrace^m\\subsetneq \\lbrace 0,1\\rbrace^m$. 严格来说, 我们需要将上述说法转换为QBF的形式, 即, 我们要证明的是 $$ \\begin{align} \\begin{array}{rlrl} x \\in L \u0026amp; \\Rightarrow \\exists s_{1}, s_{2}, \\ldots, s_{m} \\in{0,1}^{m} \\forall r \\in{0,1}^{m}. r \\in \\bigcup_{i=1}^{m}A_{x;s_i} \\newline \u0026amp; \\Leftrightarrow \\exists s_{1}, s_{2}, \\ldots, s_{m} \\in{0,1}^{m} \\forall r \\in{0,1}^{m}. \\bigvee_{i=1}^{m}\\left(A\\left(x ; r \\oplus s_{i}\\right)=1\\right) \\newline x \\notin L \u0026amp; \\Rightarrow \\forall s_{1}, s_{2}, \\ldots, s_{m} \\in{0,1}^{m} \\exists r \\in{0,1}^{m}. r \\notin \\bigcup_{i=1}^{m}A_{x;s_i} \\newline \u0026amp; \\Leftrightarrow \\forall s_{1}, s_{2}, \\ldots, s_{m} \\in{0,1}^{m} \\exists r \\in{0,1}^{m}. \\neg \\bigvee_{i=1}^{m}\\left(A\\left(x ; r \\oplus s_{i}\\right)=1\\right) \\end{array} \\end{align} $$ 我们首先证明第二个论断. 当$s_1,\\cdots, s_m$固定的时候, 随机选取$R$, 我们计算$R \\in \\bigcup_{i=1}^{m}A_{x;s_i}$的概率 $$ \\begin{aligned} \\operatorname{Pr}\\left[R \\in \\bigcup_{i}A_{x;s_i}\\right] \u0026amp; \\leq \\sum_{i} \\operatorname{Pr}\\left[R \\in A_{x;s_i}\\right] \\\n\u0026amp;\u0026lt;m \\cdot 2^{-n}\u0026lt;1 \\end{aligned} $$ 因此, 无论我们如何选择$s_{1}, s_{2}, \\ldots, s_{m}$, 总有某个$r\\notin \\bigcup_{i=1}^{m}A_{x;s_i}$, 这便是我们要证明的结论.\n现在继续证明第一个论断. 更加论断的形式, 我们均匀选取$S_1,\\cdots, S_m$, 并证明对于某个固定的$r$, $r\\notin \\bigcup_i A_{x;s_i}$的概率. 根据选取方式, 所有事件$r\\notin A_{x;S_i}$是相互独立的, 因此 $$ \\begin{aligned} \\operatorname{Pr}\\left[r \\notin \\bigcup_{i}A_{x;S_i}\\right] \u0026amp;=\\prod_{i} \\operatorname{Pr}\\left[r \\notin A_{x;S_i}\\right] \\\n\u0026amp;=\\prod_{i} \\operatorname{Pr}\\left[S_{i} \\notin A_{x;r}\\right] \\\n\u0026amp;\u0026lt;\\left(2^{-n}\\right)^{m} \\end{aligned} $$ 对于每个$r$来说, 上述结论都是成立的, 那么存在一个$r$满足上述论断的概率呢? 无非最多就是全部加起来: $$ \\operatorname{Pr}\\left[\\exists r. r \\notin \\bigcup_{i}A_{x;S_i} \\right]\u0026lt;2^{m} \\cdot\\left(2^{-n}\\right)^{m} \\leq 1 $$ 注意上述概率是在均匀选取$S_1,\\cdots, S_m$下的概率, 那么也就是说, 存在$s_1,\\cdots, s_m$使得$\\exists r. r \\notin \\bigcup_{i}A_{x;S_i} $不成立. 即 存在$s_1,\\cdots, s_m$使得$\\forall r. r\\in \\bigcup_i A_{x;s_i}$成立, 这便是我们要的结论.\n习题 Problem 2.1\n","date":"2021-07-13T17:05:55Z","image":"https://lingerois.com/p/%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%80%A72-%E5%9F%BA%E7%A1%80%E5%8E%BB%E9%9A%8F%E6%9C%BA%E6%96%B9%E6%B3%95/random_hu613cca1bb6de80908186546a0e089760_470936_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%80%A72-%E5%9F%BA%E7%A1%80%E5%8E%BB%E9%9A%8F%E6%9C%BA%E6%96%B9%E6%B3%95/","title":"伪随机性(2) 基础去随机方法"},{"content":"注意, 本系列是Foundation of Lattice-Based Cryptography, 而不是Basic Lattice-Based Cryptography, 这意味着我们更多是关注基本定义, 困难问题, 算法, 而不是关注具体的密码方案. 此外, 基石对应foundation, 基础对应basics.\n在文章中, 我们可能会用到SageMath作为计算工具以展示例子, 这是一个语法类似于Python的功能强大的开源计算软件.\n基本定义 格实际上就是$\\mathbb R^n$空间中周期出现的点阵, 它是$\\mathbb R^n$的一个子集, 这里, \u0026ldquo;周期\u0026quot;是一个非常不精确的说法, 因此精确来说格可以定义如下.\n 定义\n令$\\Lambda\\subset \\mathbb R^n$, 如果存在$\\mathbb R^n$中的线性无关向量组$\\mathbf b_1,\\cdots,\\mathbf b_m$, 满足\n$$ \\mathbf v\\in\\Lambda\\iff \\exists z_1,\\cdots,z_m\\in\\mathbb Z:\\mathbf v=\\sum_{i\\in[m]}z_i\\mathbf b_i $$\n那么就称$\\Lambda$为$\\mathbb R^n$中的一个格. 当$m=n$时, 就说$\\Lambda$是满秩的.\n 定义中, 我们要求格点是基的系数为整数的线性组合. \u0026ldquo;秩\u0026quot;一词是从英文\u0026quot;rank\u0026quot;中翻译过来的. 如果读者具有较好的代数基础, 那么可以得出实际上格上一个$\\mathbb Z$-模. 这里的格的秩实际上就是这个$\\mathbb Z$-模的秩.\n其他 用SVP$\\gamma$的Oracle求解GapSVP$\\gamma$\n当给定GapSVP$\\gamma$的输入$(\\mathbf B,r)$的时候, 访问一次SVP$\\gamma$的Oracle可以得到一个向量$v$长度为$r^\\prime$使得$r^\\prime\\in[\\lambda_1(\\mathbf B),\\gamma\\lambda_1(\\mathbf B)]$, 此时我们可以根据$r^\\prime$来决定输入. 根据$r,\\lambda_1(\\mathbf B)$的大小不同, 有如下几种情况:\n\r其中阴影部分是我们能够得到的$r'$的大小. 可见, 将得到的结果和$\\gamma r$进行比较, 当$r'\u0026lt;\\gamma r$时, 就是1.或3.两种情况, 都应该输出NO. 反之, 则输出YES.\n用GapSVP$_\\gamma$的Oracle输出$[\\lambda_1(\\mathbf B),\\gamma \\lambda_1(\\mathbf B)]$中的一个值\n对于有理数的$\\lambda_1(\\mathbf B)$, 要求$\\lambda_1(\\mathbf B)$, 需要带不同的$r$到GapSVP$_\\gamma$的Oracle中尝试. 当$r\\leq\\lambda_1$时, oracle输出YES, 而当$r\u0026gt;\\gamma\\lambda_1$时, oracle输出NO, 在$\\lambda_1\u0026lt;r\\leq \\gamma \\lambda_1$时, oracle的输出是不确定的, 带入不同的$r$, oracle典型的输出如下图\n\r无论怎样的情况, 任取一对YES, NO, $[\\lambda_1,\\gamma\\lambda_1]$中的一个数都在其间. (边界的情况要略微处理一下).\n","date":"2021-07-08T14:03:36Z","image":"https://lingerois.com/p/%E5%9F%BA%E4%BA%8E%E6%A0%BC%E7%9A%84%E5%AF%86%E7%A0%81-%E5%9F%BA%E7%9F%B3%E7%AF%871-%E5%9F%BA%E7%A1%80/lattice_hua6f54cc5d80ac1079aa515d877acc994_770352_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E5%9F%BA%E4%BA%8E%E6%A0%BC%E7%9A%84%E5%AF%86%E7%A0%81-%E5%9F%BA%E7%9F%B3%E7%AF%871-%E5%9F%BA%E7%A1%80/","title":"基于格的密码 基石篇(1) 基础"},{"content":"本章主要通过一些随机化的算法介绍了两个工具:\n 马尔可夫不等式(Markov Inequality)和切尔诺夫界(Chernoff Bound) 用代数的方法研究图论, 即随机游走  笔记中, 我们不会关注本章中讲的具体算法, 而是主要关注有关谱图论(spetral graph theory)的部分.\n约定\n 在研究图$G$, 一般认为$G=(V,E)$, 其中$V,E$分别是点集和边集. 一般记为$|V|=n$, 图算法的复杂度也用有关$n$的函数来表示. 在本系列中, 如果向量(如$x$)出现在矩阵(如$M$)前面, 则$x$是行向量, 反之$x$为列向量. 记本文记号$xMx$相当于标准记号$\\mathbf x^T\\mathbf M\\mathbf x$.  概率不等式  引理 Markov不等式\n令$X$是一个飞负的随机变量, 则对于任意$\\alpha\u0026gt;0$, 有 $$ \\Pr[X\\geq \\alpha]\\leq \\frac{\\operatorname E[X]}{\\alpha} $$\n Markov不等式的证明非常简单, 也显得非常粗略, 但是它对于推出Chernoff界已经足够了.\n书中介绍的是广义的Chernoff界, 证明同伯努利分布的证明略有不同.\n 定理 Chernoff界\n令$X_1,\\cdots,X_t$是独立随机变量, 且都在$[0,1]$上取值, 令$X=(\\sum_i X_i)/t$, 且$\\mu=\\operatorname{E}[X]$. 则有 $$ \\Pr[|X-\\mu|\\geq \\varepsilon]\\leq 2\\operatorname{exp}(-t\\varepsilon^2/4) $$\n Chernoff界在随机算法中的非常重要, 它使得我们可以重复一个随机算法多次, 以大多数次数的输出结果为最终结果, 使得我们计算正确的概率显著提高.\n随机游走 伪随机性研究的一个重要工具就是谱图论. 它允许我们用代数的手段来研究图论. 谱图论中, 我们经常用到digraph和无向图:\n digraph: 即directed multigraph, 在有向图的基础上, 允许多重边的存在. 且允许点到自身的边(称为自回路, self-loop). 多重无向图: 在无向图的基础上, 允许多重边的存在, 且允自回路.  值得注意的是, 在随机游走的研究中, 我们认为点到自身的边只它贡献1度(degree). 这是由于我们需要用到$d$-正则(regular)图的概念:\n $d$-正则图: 即图中每条边的度都是$d$  我们经常需要将任意图补上若干自回路, 使其变成一个$d$-正则图. 如果按照一般的图论, 认为自回路为点贡献2度, 那么这样的操作就无法完成.\n随机游走即从某个点出发, 然后在该点的边(如果digraph则为出边)中均匀随机选择一条, 完成一步移动. 并重复此过程. 这个过程虽然简单, 但是对它进行分析可以解决很大一类问题, 因此具有研究的价值(这里面已经诞生了非常多的哥德尔奖了).\n我们可以将随机游走用一个矩阵来表示, 例如, 我们可以将下图\n 的随机游走矩阵表示为 $$ M=\\left[ \\begin{matrix} 1/4\u0026amp;\t0\u0026amp;\t3/4\u0026amp;\t0\\newline 0\u0026amp;\t3/4\u0026amp;\t0\u0026amp;\t1/4\\newline 3/4\u0026amp;\t0\u0026amp;\t0\u0026amp;\t1/4\\newline 0\u0026amp;\t1/4\u0026amp;\t1/4\u0026amp;\t1/2\\newline \\end{matrix} \\right] $$ 如果我们将某一步随机游走后, 在各点的概率表示成一个向量$x$, 那么$xM$就是在走一步之后的概率分布. 例如, 假设我们的从点$1$开始, 那么初始的分布就是$x=(1,0,0,0)$, 在经过一步游走后, 可以得到 $$ xM=(1/4,0,3/4,0) $$ 从图中也可以看出正确性. 该结论是比较容易证明的, 就不再赘述. 此外, 我们将均匀分布记作$u$, 即$u=(1/n,\\cdots,1/n)$.\n值得注意的是$M$是个非常特殊的矩阵, 具有一些平常不太引人注意的性质:\n  对于无向图来说, $M$是个实对称矩阵, 这意味着它可以被对角化, 且可以找到$\\operatorname{rank} M$个正交的特征向量. 显然, 不同特征值的特征向量是正交的.\n  对于正则图来说, $M$的各列之和为$1$, 那么 $$ u M=u $$ 因此$u$是$M$的一个对应特征值$1$的特征向量.\n  对于无向正则图, $M$另外的一些特点不太显然, 都会在习题2.9中证明\n $M$的特征值的绝对值最大为$1$ $M$有关特征值$1$的特征空间为$1\\iff G$是连通图 $M$有特征值$-1\\iff G$是二部图  对于有向图$G$及其随机游走矩阵$M$的特点, 我们也有\n对于$d$-正则有向图$G$, 以及其随机游走矩阵, 应该具有如下特点\n  $u$是$M$的一个对应特征值$1$的特征向量\n  $G$的每一个弱连通分支都是强连通的. 这是由于如果一个弱连通分支, 这个现象很有趣, 因此如果$G$的某一个弱连通分支, 按照DAG的方式, 将强连通分支排出来, 例如\n   其中虚线箭头代表从弱连通分支之间的多条边. 选择没有出边的分支(如图中$E$), 由于对于连通分支来说入度和出度也得相等, 因此$E$应该有指向其他分支的回向边, 例如指向$D$, 那么$E$和$D$就可以合成一个强连通分支. 依次这样进行下去, 那么所有的弱连通分支都可以合并为强连通分支.\n从直观上来讲, 这一事实说明了其实对于有向正则图来说, 只要能从$i$走到$j$, 那么也应该能从$j$走回$i$, 说明用无向来研究有向的愿望是有可能能实现的.\n习惯上, 我们喜欢将$M$的特征值按照绝对值从大到小排序, 且$\\lambda_1=1$, 这样得到的$\\lambda_1,\\cdots,\\lambda_n$称为图$G$的谱(spectrum).\n 定义\n给定正规图$G$1, 对应随机游走$M$, 我们定义 $$ \\lambda(G) \\stackrel{\\text { def }}{=} \\max _{\\pi} \\frac{|\\pi M-u|}{|\\pi-u|}=\\max _{x \\perp u} \\frac{|x M|}{|x|} $$ 其中, 第一个$\\max$中$\\pi$在所有概率分布中取, 第二个$\\max$中$x$在所有垂直于$u$的向量中取. 我们记$\\gamma(G)=1-\\lambda(G)$.\n 上式中, 两个定义是相等的, 因为\n 对于任意$u$, 可以令$x=\\pi-u$, 那么$x\\perp u$. 对于任意$x\\perp u$, 可以令$\\pi=u+\\alpha x$, 对于某些$\\alpha$, $\\pi$是概率分布.  根据习题2.9:\n $\\lambda(G)\\in [0,1]$ $\\lambda(G)=|\\lambda_2|$ $\\gamma(G)=\\lambda_1-|\\lambda_2|$, 因此也被称作是谱鸿沟(spectral gap)2.  在正规图的连通图上随机游走, 我们容易想到的一个问题就是, 在游走到足够的步数后, 得到的分布会不会是接近均匀分布的? $\\lambda(G)$能够帮助我们获得有关图的直接结论就是, $\\lambda(G)$越小, 我们越是能够更快的逼近均匀分布, 有如下结论.\n 引理\n令$G$是正规图, $M$是其随机游走矩阵, 对于任意初始分布$\\pi$和$t\\in\\mathbb N$, 有 $$ \\left|\\pi M^{t}-u\\right| \\leq \\lambda(G)^{t} \\cdot|\\pi-u| \\leq \\lambda(G)^{t} $$\n 现在我们运用上述引理证明, 在$t\\geq\\ln(n/\\varepsilon)/\\gamma(G)$时候, $\\pi M^t$的最大的分量都至少有$1/n-(1-\\gamma(G))^t$.\n注意到\n$$ \\max|(\\pi M^t-u)i|\\leq \\left|\\pi M^t-u\\right|\\infty\\leq \\left|\\pi M^t-u\\right|\\leq \\lambda(G)^t $$\n因此$|\\pi M^t-u|\\leq \\lambda(G)^t$蕴含对于任意$i\\in [n]$,\n$$ |(\\pi M^t-u)_i|\\leq \\lambda(G)^t \\Rightarrow (\\pi M^t)_i\\geq 1/n-\\lambda(G)^t $$\n成立. 证明$1/n-(1-\\gamma(G))^t\\geq (1-\\varepsilon)/n$等价于证明$\\lambda(G)^t\\leq \\varepsilon/n$. 令$p = \\ln (n/\\varepsilon)$, 令$x=\\lambda(G)$, 则\n$$ \\begin{align} \\lambda(G)^t\\leq \\varepsilon/n \\iff \u0026amp;x^{p/(1-x)}\\leq e^{-p} \\iff x\\leq e^{x-1} \\end{align} $$\n紧接着用一些小技巧: 令$f(x)=x- e^{x-1}$, 则$f'(x)=1-(x-1)e^{x-1}$. 对于$0\\leq x\u0026lt;1$, 有$f'(x)\u0026lt;0$. 因此对于$x\\in[0,1]$, $f(x)\\leq 0$. $\\square$\nUPATH问题 到此, 我们可以解决一个非常重要的问题, 即无向图点对连通性问题(UPATH问题).\n UPATH问题\n给定无向图$G$和其中的两个点$s,t$, 判定是否存在一条从$s$到$t$的通路.\n 显然, 深度优先搜索和宽度优先搜索都可以在多项式时间内解决这一问题, 而我们要考虑的是, 能否在对数空间内解决这一问题. 我们解决该问题用到的算法时随机的; 更加精确地讲, 我们想要证明$\\mathsf{UPATH}\\in\\mathbf{RL} $.\n根据谱图论的指示, 在连通的正规图中, 我们可以以多项式步的随机游走, 以极大的概率来触及到图中的每个点, 以这一思想设计出来的算法非常简单: 在图$G$中从$s$开始随机游走$\\operatorname{poly}(n)$步, 当达到$t$时, 接受; 否则, 拒绝.\n为了更好的描述这个问题, 我们定义一个图$G$的hitting time.\n 定义\n给定图$G=(V,E)$, 定义其hitting time为 $$ \\operatorname{hit}(G)=\\max_{i,j\\in V}\\min\\lbrace t: \\Pr[从i开始经过t步随机游走到达过t]\\geq 1/2\\rbrace $$\n 简言之, 从任意点$i$开始, 经历$t$步随机游走后, 图上的任意点$j$被访问过的概率至少是$1/2$. 显然, 对于图$G$, 如果$\\operatorname{hit}(G)=\\operatorname{poly}(n)$, 那么进行多项式步随机游走, 就可以压倒性地概率遍及每一个点. 那么, 我们如果证明了任何一个连通图$G$的$\\operatorname{hit}(G)$是多项式, 就可以证明我们给出的随机游走的$\\mathsf{UPATH}$算法是正确的. 我们需要证明的是如下定理.\n 定理\n给定任意连通的无向图$G$, 包含$n$个点, 其中点的最大的度为$d$, 则有$\\operatorname{hit}(G)=O(d^2n^3 \\log n)$.\n 任何一个给定的无向图, 我们都可以通过向其添加自回路, 使得该图变为一个$d$-正则或$(d+1)$-正则的非二部图. 而这一操作只可能增大图的hitting time(因为增大了每一步随机游走中, 停留在出发点的概率), 因此我们对正则非二部图证明上述结论就可以了, 详见习题2.9.\n习题 习题实在是难, 没法一次性搞定, 只有慢慢更新.\n Problem 2.1\n证明采用归纳法.\n命题对于$n=1$是成立的. 这是由于$f$的次数为$d$, 因此最多有$d$个根, 因此任意$S$中也不会包含$d$个以上的$f$的根, 因此随机选取到根的概率是大于$d/|S|$的.\n对于归纳步骤, $$ f(x,\\cdots,x_n)=\\sum_{i=0} ^d x_{n}^if_i(x_1,\\cdots,x_{n-1}) $$ 对于$f_i$来说由于次数最多为$d-i$, 有 $$ \\Pr_{\\alpha_1,\\cdots,\\alpha_{n-1}\\gets S}[f_i(\\alpha_1,\\cdots,\\alpha_{n-1})=0]\\leq \\frac{d-i}{|S|} $$ 由于$f$是非零多项式, 那么存在$i\\in[d]$使得$f_i$不是零多项式. 令$f_k$为非零多项式满足$i\u0026gt;k$时$f_i$是零多项式(即$k$是最大的使得$f_k$不是零多项式的数), 记$\\overrightarrow{\\alpha_i}=(\\alpha_1,\\cdots,\\alpha_i)$则 $$ \\begin{align} \\Pr[f(\\overrightarrow{\\alpha_n})=0]\u0026amp;=\\Pr[f(\\overrightarrow{\\alpha_n})=0\\wedge f_k(\\overrightarrow{\\alpha_k})=0]+\\Pr[f(\\overrightarrow{\\alpha_n})=0\\wedge f_k(\\overrightarrow{\\alpha_k})\\neq 0] \\newline \u0026amp;\\leq \\Pr[f_k(\\overrightarrow{\\alpha_k})=0]+\\Pr[f(\\overrightarrow{\\alpha_n})=0\\wedge f_k(\\overrightarrow{\\alpha_k})\\neq 0] \\end{align} $$ When $f_k(\\overrightarrow{\\alpha_k})\\neq 0$, $f(\\overrightarrow{\\alpha_k},x_{k+1},\\cdots,x_n)$ is a nonzero polynomial with degree as most $k$, then we have $$ \\Pr[f(\\overrightarrow{\\alpha_n})=0]\\leq \\frac{d-k}{|S|}+\\frac{k}{|S|}=\\frac{d}{|S|} $$\n Problem 2.2\n给定$m$,\n 我们可以将每个均匀的$\\alpha\\in[m]$的低$\\lfloor \\log m\\rfloor$位看作是这么多位的均匀随机比特. 同样, 我们有至少$1/2$的概率可以将$\\lceil \\log m\\rceil$个随机比特看做是均匀随机的$\\alpha\\in[m]$, 且这个过程可以用一个高效的算法来完成.   Problem 2.3\n  对于任意$L\\in \\mathbf{RP}\\cap \\mathbf{coRP}$, 存在算法$\\mathcal A_{b}$, 其中$b\\in\\lbrace 0,1\\rbrace$, 使得$\\mathcal A_b$在多项式时间内判定$L$, 且只有$b$-sided error. 那么对于任意的$x$, 我们同时用$\\mathcal A_b$来计算它, 输出$1$如果$\\mathcal A_0(x)=1$, 输出$0$如果$\\mathcal A_1(x)=0$. 这两种情况是互斥的.\n  对于任意$L\\in\\mathbf{ZPP}$, 令$\\mathcal A$是判定$L$的算法, 且对于任意$x\\in L$, $\\mathcal A(x)$在期望多项式时间$p(|x|)$停机并总是输出正确答案. 现构造算法$\\mathcal B$: $\\mathcal B$用$\\mathcal A(x)$计算$2p$时间, 根据Markov不等式, 它有至少$1/2$的概率输出一个答案. 如果$\\mathcal A$输出一个答案, 则$\\mathcal B$输出$\\mathcal A$的答案; 否则, 输出 $0$. 显然, $\\mathcal B$在多项式时间内停机, 且$\\mathcal B$只有one-sided error并且总是以至少$1/2$的概率在$x\\in L$时输出$1$.\n用类似的方法可以证明$L\\in\\mathbf{coRP}$.\n   Problem 2.4\n(1) (做不出来, 查了资料)\n(2) 给定多项式$p$, 我们选取随机数$N=\\operatorname{poly}(|p|)$且使得$N/\\deg d\u0026gt;c_1$完成检查($c_1$为某个常数). 需要注意的是, 由于打开括号可能使得中间或最终结果长度超过$\\operatorname{poly}(|p|)$, 因此我们模$M$来完成测试, 即检查$p(N)\\bmod M\\equiv 0$是否成立, 来规避这一问题. 当$N$足够大时, 有对应的$c_2$, 使得 $$ \\Pr[N\\not\\equiv 0 \\bmod M]\\geq c_2/\\log\\log N $$ 成立. 对于零多项式, 无论无何选取$N$和$M$, 由于$p(N)=0$, 就有$p(N)\\bmod M=0$. 因此检验的结果始终为$0$. 对于非零多项式$d$次多项式, $\\Pr[p(N)=0]\u0026lt;c_1$. 那么再模上$M$有 $$ \\Pr[p(N)\\bmod M=0]\\leq c_1(1-c_2/\\log\\log N)\u0026lt;O(1)=c $$ 重复检验足够多的次数就可以满足$\\mathbf{coRP}$的要求\n Problem 2.5\n这个问题和多项式次数小于域的阶数的区别在于, 可能存在作为多项式函数是零多项式, 但是作为多项式形式是非零多项式的那些特殊多项式. 如果对这些多项式带入随机数测试, 得到的永远都是$0$, 但是它却不是一个零多项式, 因此, 我们需要将其模到一个次数比较小的多项式来测试.\n(1) (我感觉我方向想错了) 假设$f$可以分解为如下不可约多项式的乘积 $$ f=p_1^{e_1}\\cdots p_n^{e_n} $$ 其中对于任意$i\\neq j$有$p_i\\neq p_j$. 那么它就应当有$\\prod_{i=1}^n(e_i+1)$个不同的因子.\n$f\\bmod g\\neq 0$当且仅当$g$是$f$的一个因子. 为了求$f\\bmod g\\neq 0$的概率的下界, 我们让$f$尽可能地有更多的次数在$d=c\\log D$以下的因子, 即认为次数为$d$以下的不可约因子都是次数为$2$. 那么次数在$d$以下的因子总数就最多只有 $$ 2^{d/2}=2^{c\\log D/2} $$ 而次数在$d$以下的多项式总数却有\n Problem 2.6\n(1) 用二项式定理展开 $$ (x+1)^n=x^n+C_n^1x^{n-1}+C_{n}^2x^{n-2}+\\cdots+C_n^{n-1}x+1 $$ 其中, 当$n$为素数的时候$C_n^1,\\cdots,C_n^{n-1}$都有一个约束$p$, 因此命题得证.\n(2) 选取不同得$x$按照(1)中得方式来测试$n$. 如果对于每个$x$得选择都有$(x+1)^n\\equiv x^n+1$, 那么就认为$n$是素数. 否则认为$n$是合数. (待续)\n Problem 2.7\n需要注意的是, 这个题目里面的$X$定义和Chernoff界定理中的不一样.\n(1) 查了以下Moment Generating Function的性质, 便大概知道个所以然. 实际上, $M_X(r)=\\operatorname E[e^{rX}]$, 如果$X$和$Y$相互独立, 显然有$M_{X+Y}(r)=M_X(r)M_Y(r)$. 利用这个性质: $$ \\begin{align} \\operatorname E[e^{rX}] \u0026amp;=\\prod_{i=1}^t\\operatorname E[e^{rX_i}]\\leq \\prod\\operatorname E[1+rX_i+(rX_i)^2]\\leq \\prod (1+\\operatorname E[{rX_i}+(r^2X_i^2)]) \\newline \u0026amp;\\leq \\prod e^{r\\operatorname E[X_i]+r^2\\operatorname E[X_i^2]}\\leq e^{r\\operatorname E[X]+r^2t} \\end{align} $$\n最后一个不等式用到了$\\operatorname E[X_i^2]\\leq 1$.\n(2) (还没做出来)根据(1)中结论, 有 $$ \\begin{align} \\Pr[X\u0026gt;\\operatorname{E}[X]+t\\varepsilon]=\\Pr[e^{rX}\\geq e^{r\\operatorname{E}[X]+r^2t}e^{r\\varepsilon t-r^2 t}]\\leq \\frac{\\operatorname{E}[e^{rX}]}{e^{r\\operatorname{E}[X]+r^2t}e^{r\\varepsilon t-r^2 t}}\\leq \\operatorname{exp}(r^2t-r\\varepsilon t) \\end{align} $$ 如果$\\varepsilon\\leq 1$, 令$r=\\varepsilon/2$就有$\\Pr[X\u0026gt;\\operatorname{E}[X]+t\\varepsilon]\\leq \\operatorname{exp}(-\\varepsilon^ 2t/4)$. 如果$\\varepsilon\u0026gt;1$, ?.\n另外一个方向的证明类似.\n(3) Independence of $X_i$是在$1$中第一个等式成立的必要条件.\n Problem 2.8\n还没做出来.\n Problem 2.9\n(1) 假设$x$是$M$的特征向量(eigenvector), 考虑$x$中绝对值最大的一个值$x_i$, 由于$xM=\\lambda x$对于某个$\\lambda$成立, 那么 $$ \\lambda x_i=\\sum_j x_jM_{ji} $$ 由于所有的$M_{ji}$的和为$1$, 因此$| \\lambda x_i|\\leq \\sum |x_j M_{ji}|\\leq \\sum |x_iM_{ji}|\\leq |x_i|$. 因此有$\\lambda\\leq 1$.\n(2) 如果$G$是不连通的, 那么它有多个连同分支. 考虑这一的分布$\\pi_i$: 在第$i$个连同分至上为均匀分布, 在其他连通分支上为$0$, 那么$\\pi_i$是$M$的特征值为$1$的特征向量. 对于不同的连通分支, 这些特征向量$\\pi_i$是线性无关的.\n考虑$x$使得$xM=x$, 令$x_i$是$x$中绝对值最大的分量. 由于$x_i=\\sum_jx_jM_{ji}$, 因此$|x_i|\\leq \\sum_j|x_jM_{ji}|$, 由于所有$M_{ji}$的总和不会超过$1$, 因此如果$M_{ji}$非零, 那么$|x_j|$都需要和$x_i$一样大且符号相同. 因此, 在连通图中, 只能有$\\pi$这个特征向量的特征值为$1$.\n(3) 如果$G$是二分的(bipartite), 那么其随机游走矩阵有如下形式 $$ M=\\left[ \\begin{matrix} \u0026amp;\tA\\newline A\u0026amp;\t\\newline \\end{matrix} \\right] $$ 这是由于两个部分的点的个数相等(由于每个点的度一样, 那么每个部分的度之和一样). 现在将$\\pi$分成长度相等的两部分, 即$\\pi=(\\pi',\\pi')$ $$ \\pi M=(\\pi',\\pi')\\left[ \\begin{matrix} \u0026amp;\tA\\newline A\u0026amp;\t\\newline \\end{matrix} \\right] = (\\pi\u0026rsquo;A,\\pi\u0026rsquo;A) = \\pi = (\\pi',\\pi') $$ 因此$\\pi'$是$A$的一个特征值为$1$的特征向量. 可以构造出$M$特征值为$-1$的特征向量$(\\pi',-\\pi')$.\n令$x$是$M$特征值为$-1$的特征向量. 同样按照(2)的方式, 考虑$x$中绝对值最大的那个值$x_i$. 那么根据$|x_i|\\leq \\sum_j|x_jM_{ji}|$, 如果$M_{ji}$不为$0$, 那么$x_j=-x_i$. 这样, 用正负号就可以将图分为两部分.\n(4)\n(第一步, 证明$\\lambda_2$等于等式左边)注意到 $$ \\langle xM,x\\rangle=(\\alpha_1v_1+\\cdots+\\alpha_nv_n)M(\\alpha_1v_1+\\cdots+\\alpha_nv_n) = \\sum_{i\\in[n]} \\lambda_i|\\alpha_i v_i|^2 $$ 其中$\\lambda_i, v_i$是特征值和特征向量. 注意到$\\sum_{i\\in [n]}\\alpha_i^2=1$, 那么当$x=v_2$时, 上式取最大值, 即 $$ \\max_{x}\\langle xM,x\\rangle= \\mu_2|v_2|=\\mu_2 $$ 其中, $\\mu_2$是$M$第二大的特征向量(没有绝对值), 而$v_2$是对应的特征向量. 上述证明中, 我们用到了$M$是个对称矩阵这一特点, 而对称矩阵的特征向量可以是正交的.\n(第二步: 证明t中的等式成立) 定义有关$G$的矩阵$L$为 $$ L_{ij}=\\begin{cases} 1-w(i,i)/d, \u0026amp;i=j\\newline -w(i,j)/d, \u0026amp;i,j,,\\text{are adjacent}\\newline 0, \u0026amp;\\mathrm{otherwise}\\newline \\end{cases} $$ 这个矩阵为图$G$的Laplacian, 其中$w(i,j)$为$i,j$节点之间的边数. 根据定义, 有$M=I-L$, 因此 $$ xMx=xIx-xLx=1-xLx $$ 注意到 $$ \\begin{align} (xL)_i\u0026amp;=\\sum_{j\\in[n]}x_iL_{ji}=x_iL_{ii}+\\sum_{j\\neq i}x_iL_{ji} \\newline \u0026amp;=x_i-w(i,i)x_i/d-\\sum w(i,j)x_i/d \\newline \u0026amp;= \\frac1d\\sum_{j\\in[n]}w(i,j)(x_i-x_j) \\end{align} $$ 这是由于$\\sum_{j\\in[n]}w(i,j)=d$. $$ \\begin{align} xLx \u0026amp;=\\frac1d\\sum _{j\\in[n]}w(i,j)(x_i-x_j)x_i \\newline \u0026amp;= \\frac1d\\sum_{i\\leq j} w(i,j)[(x_i-x_j)x_i+(x_j-x_i)x_j] \\newline \u0026amp;= \\frac1d\\sum_{i\\leq j}w(i,j)(x_i-x_j)^2 \\end{align} $$ 此处, 我觉得书中符号的意思是$E$是允许重复元素的集合, 如果$(i,j)$之间有多条边, 那么就有多个$(i,j)$在$E$中, 因此 $$ xLx=\\frac1d\\sum_{(i,j)\\in E}(x_i-x_j)^2 $$ 那么 $$ \\langle xM,x\\rangle=1-\\frac1d\\sum_{(i,j)\\in E}(x_i-x_j)^2 $$ 便对每个$x\\perp u$及$|x|=1$的$x$成立, 我们便证明了等式.\n(第三步, 计算bound.) 根据作者的提示, 考虑$\\lbrace -\\alpha,\\beta\\rbrace^n$这样的点, 我选择带入特殊值. 例如, 选择$x$中一半是$1/n$, 另一半是$-1/n$, 那么 $$ xLx\\leq\\frac1d\\cdot \\frac{nd}2\\cdot \\left(\\frac{1}n\\right)^2=1/n=\\frac1{\\operatorname{poly}(n,d)} $$ (5) 我们可以对(4)中的计算都套上绝对值, 就有 $$ \\max_{x}|\\langle xM,x\\rangle|=\\left|1-\\frac1d\\sum_{(i,j)\\in E}(x_i-x_j)^2\\right|=\\lambda_2|v_2| $$ 此时$v_2$是$\\lambda_2$对应的特征向量.\n在题设限子下, $|\\lambda_2|\\neq 1$, 那么就可以得出结论.\n(6) 在research过程中找到了答案. 选一个这样的特殊的$x$: $|x_i|\\geq \\frac1{\\sqrt n}$且$x_j=0$. 令$i$到$j$的路径为$i=i_1\\to i_2\\to i_3\\to \\cdots\\to i_{m-1}\\to i_m=j$, 那么 $$ \\begin{align} \\frac1{\\sqrt m}\u0026amp;\\leq |x_j-x_i| \\newline \u0026amp;= \\left|\\sum_{i=k}^{m-1}(x_{i_k}-x_{i_{k+1}})]\\right| \\newline \u0026amp;\\leq \\sum_{i=k}^{m-1}|x_{i_k}-x_{i_{k+1}}| \\newline \u0026amp;= \\sum_{i=k}^{m-1} \\sqrt{1} \\cdot \\sqrt{(x_{i_k}-x_{i_{k+1}})^2} \\newline \u0026amp;\\leq \\sqrt{D}\\sqrt{\\sum_{i=k}^{m-1}(x_{i_k}-x_{i_{k+1}})^2} \\newline \u0026amp;\\leq \\sqrt D \\sqrt{\\sum_{(i,j)\\in E}(x_i-x_j)^2} \\end{align} $$\n其中, 倒数第二个不等式用了Cauchu-Schwarz不等式, 而$D$表示图$G$的直径. 根据上式有 $$ \\gamma(G)\\geq \\frac{1}{nd}\\frac 1D $$ 根据$D\u0026lt;nd$就可以得出$\\gamma(G)\\geq \\frac1{n^2d^2}$即$\\gamma(G)=\\Omega\\left(\\frac1{n^2d^2}\\right)$.\n Problem 2.10\n(1) 我们直接考虑直觉的最坏的情况(即下图)的hitting time:\n 如果这个图的hitting time都达不到题目中的要求, 那我也就不知道要如何构造出更大的$\\operatorname{hit}(G)$了. 假设该图有$n+1$个点. 一次性通过$(n+1)/2$步前$n/2$个点走到终点, 就需要在后至少$n/3$步都向前走, 概率小于$2^{-n/3}$ (用$n/3$主要是为了避免$n$是奇数的问题). 假设从起点开始尝试走$t$个$(n+1)/2$步, 根据union bound, 那么$t\\geq 2^{n/3}/2$才能以至少$1/2$的概率走到终点. 因此 $$ \\operatorname{hit}(G)\\geq 2^{n/3}/2 \\cdot (n+1)/2 = 2^{\\Omega(n)} $$ (2) 根据定义$\\lambda(G) \\stackrel{\\text { def }}{=} \\max _{x \\perp u} \\frac{|x M|}{|x|}$. 对于任意$x\\perp u$, $$ |xM|^2=\\langle xM,M^Tx\\rangle=xMM^Tx\\leq |xMM^T||x| $$ 因此$\\left(\\frac{|xM|}{|x|}\\right)^2\\leq \\frac{|x MM^T|}{|x|}$. 而当$x$为$MM^T$中$\\lambda_2$对应的特征向量时, $xMM^T=\\lambda_2x$, 因此$xMM^Tx=\\langle\\lambda_2x,x\\rangle=\\lambda_2|x|^2=|xMM^T||x|$, 此时等号成立. 因此有$\\lambda(G)=\\sqrt{\\lambda(G')}$.\n(3) 实际上Eulerian digraph就是强连通的正则有向图. (待续)\n  可以是有向图或者无向图\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Gap这个词我一直不知道怎么翻译, 翻译成什么都觉得怪怪的. 不过, 为了表明这一gap是难以跨越的, 推荐翻译为\u0026quot;鸿沟\u0026quot;, 但我还是继续使用英文.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2021-07-06T17:01:01Z","image":"https://lingerois.com/p/%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%80%A71-%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95-%E8%B0%B1%E5%9B%BE%E8%AE%BA/random_hu613cca1bb6de80908186546a0e089760_470936_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%80%A71-%E9%9A%8F%E6%9C%BA%E7%AE%97%E6%B3%95-%E8%B0%B1%E5%9B%BE%E8%AE%BA/","title":"伪随机性(1) 随机算法 谱图论"},{"content":" Warning\nThis is not a overall introduction to the field theory. Please resort to a textbook if you are a beginner in field theory.\n Field are those commutative rings s.t. every element except $0$ has an invers element. We start with the simplest fields.\n Prime Field\nFor any field $k$, define its prime field to be the intersection of all subfields\n For any field, its prime field must be $\\mathbb Q$ or $\\mathbb F_p$ for some prime $p$. For field with prime field $\\mathbb F_p$, we say it has characteristic $p$, for field with prime field $\\mathbb Q$, we say it has characteristic $0$.\nExample.\n $\\mathbb C,\\mathbb R$ has characteristic $0$ because they have prime field $\\mathbb Q$. $\\mathbb F_{p^n}$ for prime $p$ has characteristic $p$. $\\mathbb Q[i]$, $\\mathbb Q[\\sqrt2]$ has characteristic $\\sqrt 2$. The fractional field $\\mathbb F_p(x)$ of $\\mathbb F_p[ x ]$ has character $p$.  For a field $k$ with finite characteristic $p$, then $p\\alpha=0$ for any $\\alpha\\in k$. Of course, finite field has nonzero characteristic, since if a field $k$ satisfy $|k|=q$ then $q\\cdot 1=0$.\n Field Extension\nFor field $k$, if $K$ is a field s.t. $k\\subsetneq K$ and there\u0026rsquo;s an injective homomorphism $\\sigma: k\\to K$, then we say $K$ is a extension of $k$.\n If $K$ is an extension of $k$, we often say \u0026ldquo;field extension $K/k$\u0026rdquo;.\nExample.\n $\\mathbb Q[i]$ is an extension of $\\mathbb Q$. $\\mathbb F_{p^n}$ is an extension of $\\mathbb F_p$, as we\u0026rsquo;ll construct later. $\\mathbb F_p(x)$ is an extension of $\\mathbb F_p$, and the injective homomorphism is $\\sigma(\\alpha)\\to \\alpha$ for any $\\alpha\\in\\mathbb F_p$ (which maps elements in $\\mathbb F_p$ to constants in $\\mathbb F_p(x)$.  For field extension $K/k$, $K$ is a vector space over $k$ (check can be done by checking $K$ meets the definition of vector space). If $K$ is finite dimensional $\\dim_k K=n$, then we say extension $K/k$ has degree $n$; otherwise, we say $K/k$ is an infinite extension. The degree of field extension $K/k$ is denoted by $[K:k]$.\nExample. $\\mathbb C$ is a extension of $\\mathbb R$ and $\\dim_\\mathbb R\\mathbb C =2$. The basis of $\\mathbb C$ over $\\mathbb R$ is $\\lbrace 1,i\\rbrace$. $\\mathbb R/\\mathbb Q$ is an infinite extension.\n Splitting Field\nLet $k$ be a field and $f(x)\\in k[ x]$, then $f(x)$ can be split to multiplication of linear polynomials with coefficients in some field $E$, we say $f(x)$ splits in $E$. Let $K$ be the intersection of all such fields, we say $K$ is the splitting field of $f$.\n The splitting field of a polynomial always exits, this is Kronecker Theory, which has a simple proof.\nThe interpretation \u0026ldquo;the intersection of all such\u0026rdquo; is not hard to be understood, it is the accurate language for \u0026ldquo;the smallest such\u0026rdquo;.\nExample.\n For $x^2-2\\in\\mathbb Q[x ]$, we have $x^2-2=(x-\\sqrt2)(x+\\sqrt2)$, then the splitting field of $x^2-2$ is $\\mathbb Q(\\sqrt 2)$. For $x^3-2\\in\\mathbb Q[x ]$, we denote $\\omega=2\\pi\\sqrt{-1}/3$, then the polynomial has three roots $x_1=\\sqrt[3]2,x_2=\\sqrt[3]2\\omega,x_3=\\sqrt[3]2\\omega^2$. Thus, $x^3-2=(x-x_1)(x-x_2)(x-x_3)$, and its splitting field is $\\mathbb Q[\\sqrt[3]2, \\omega]$. Note that $\\mathbb Q[\\sqrt[3]2]$ is the smallest field that include $\\mathbb Q$ and $\\sqrt[3]2$. We have $[\\mathbb Q(\\sqrt[3]2,\\omega):\\mathbb Q]=6$ and $[\\mathbb Q(\\sqrt[3]2):\\mathbb Q]=3$. The basis of $\\mathbb Q(\\sqrt[3]2,\\omega)$ is $\\lbrace 1,\\sqrt[3]2, (\\sqrt[3]2)^2, \\omega,\\sqrt[3]2\\omega,(\\sqrt[3]2)^2\\omega \\rbrace$.   They are cases that an irreducible polynomial has repeated roots. Such cases are more complex to deal with. We deal with simpler cases first.\n Algebraic Extension\nFor field externsion $K/k$, if $\\alpha\\in K$ is a root of some $f(x)\\in k[ x]$, then we say $\\alpha$ is algebraic over $k$; otherwise, we say $\\alpha$ is transcendental over $k$. If every $\\alpha\\in K$ is algebraic over $k$, we say $K/k$ is an algebraic extension; otherwise, we say $K/k$ is transcendental.\n For an algebraic element $\\alpha$ over $k$, their must be some irreducible $f(x)\\in k[ x]$ having $\\alpha$ as a root. By multiple the inverse of $f(x)$\u0026rsquo;s highest degree coefficient, we can make it to have hightes degree coefficient $1$. We say such $f(x)$ is the minimal polynomial of $\\alpha$ in $k$, denoted by $\\operatorname{irr}(\\alpha,k)=p(x)$.\n Separable Polynomial\nAn irreducible polynomial $p(x)$ is separable if it has no repeated roots. An arbitrary polynomial $f(x)$ is separable if each of its irreducible factors has no repeated roots; otherwise, it is inseparable.\n Mathematics has figured out that cases of transcendental extensions can be deal similar to the splitting field of a separable polynomial. Thus, we treat the splitting fields of a separable polynomials and transcendental extensions equally, and call them separable extensions.\n Separable Extension\nLet $E / k$ be an algebraic extension. An element $\\alpha \\in E$ is separable if either $\\alpha$ is transcendental over $k$ or $\\alpha$ is algebraic over $k$ and its minimal polynomial $\\operatorname{irr}(\\alpha, k)$ is separable; that is, $\\operatorname{irr}(\\alpha, k)$ has no repeated roots.\nAn extension field $E / k$ is separable if each of its elements is separable; we say that $E / k$ is inseparable if it is not separable.\n Separable extensions are common, as the follows:\n Any extension of a field with characteristic $0$. Every finite extension of a finite field.  The above fact says that following extensions are all separable extension: $\\mathbb R/\\mathbb Q$, $\\mathbb C/\\mathbb Q$, $\\mathbb Q(\\pi)/\\mathbb Q$, $\\mathbb F_{p^m}/\\mathbb F_{p^n}$ for $n\\mid m$.\nExample. Let $k=\\mathbb F_p(t)=\\operatorname{Frac}(\\mathbb F[t])$. Let $\\alpha$ be a root of $f(x)=x^p-t\\in k[ x]$, then $\\alpha^p-t=0$. Let $E=k(\\alpha)$, then in $E[ x]$, we have $$ f(x)=x^p-t=x^p-\\alpha^p=(x-p)^\\alpha $$ Moreover, we have $\\alpha\\notin k$. If $\\alpha\\in k$, then there are $g(t),h(t)\\in \\mathbb F_p[t]$ s.t. $\\alpha=g/h$. Hence, $g^p=(ah)^p=th^p$, so that $$ \\deg(g^p)=\\deg (th^p)=1+\\deg (h^p) $$ which contradicts. Thus, $f(x)$ is irrecducible in $k[ x]$ and splits in $E$. However, $f(x)$ has repeated root in $E$, then $E/k$ is inseparable. $\\square$\nOne might think its hard to interprete $t$ as an field element it the last example. A simple example might help is to think of $\\mathbb Q(\\pi)$. What are elements in $\\mathbb Q(\\pi)$? Of course $\\mathbb Q(\\pi)$. To make $\\mathbb Q(\\pi)$ a field, we have to add the integer powers of $\\pi$, their additions and quotients to $\\mathbb Q(\\pi)$. Thus, $\\pi^2, 1/\\pi,\\frac{3\\pi^2+\\pi}{4\\pi^4+2\\pi^3+7\\pi^2}\\in\\mathbb Q(\\pi)$. Finally, we reach $\\mathbb Q(\\pi)$ that contains all fractions of $\\pi$ with coefficients in $\\mathbb Q$. A keen reader might find out that the parentheses in fractional field of a polynomial field over ring and field extension shares the same meaning.\n We now show the existence of finite fields with fixed order $p^n$ of any prime $p$ and positive integer $n$.\nOne can prove that the multiplication group $k^\\times$ of a finite field $k$ is cyclic. (the proof uses some nontrivial fact of cyclic group, with order $p^n$) We call a generator $\\alpha$ for $k^\\times$ a primitive element in $k$.\nNotice that finite field has characteristic $p$ for some prime, then it must contain a subfield $\\mathbb F_p$. Thus any finite field is a vector space over some $\\mathbb F_p$. Since finite vector space over finite field has finite dimension, say $n$, then it must have elements of number $p^n$.\nBefore counstruting all finite fields, we introduce an important result. Let $k$ be a field and $f(x)\\in k[ x]$ be a irreducible polynomial over $k$. Note than $$ I=(f(x))=\\lbrace rf(x):r\\in k[ x]\\rbrace $$ is an ideal in $k[ x]$. Consider the quotien ring $k[ x]/I$. Notice that for any $+$, we have $f\\nmid g$. Then there are $s,g\\in k[ x]$ s.t. $sg+tf=1$. Then $(s+I)(g+I)=sg+I=1+I$. Thus we can find the inverse for any $g+I\\in k[ x]/I$ and $k[ x]/I$ is a field. Note that $k$ is a subfield of $k[ x]/I$, the embedding if $\\sigma(\\alpha)=\\alpha+I$ for any $\\alpha\\in k$. It would be more interesting to check that, $x+I$ is a solution of $f(x)$ in $K=k[ x]/I$. (By repeating this, $f$ would finally being splitted in some field $K'\\supset K$, and Kronecker Theory proved.)\nHow to explicitly contruct the field with $p=q^n$ elements? Here we mean to construct a field of order $q^n$ that the elements of it can be represent explicilty with objects we are familiar with. And we wish to do the computation in such construction explicitly. To do that, one have to find of a irreducible polynomial of degree $n$ over $\\mathbb F_p$. One could prove that such polynomial always exists, but there isn\u0026rsquo;t a general algorithm to find such. To find all such polynimal, one can try to factor $x^{p^n}-x\\in\\mathbb F_p[ x]$.\nTo prove that every field of order $p^n$ of any prime $p$ and positive integer $n$ are isomorphic, we need next lemma.\n Lemma\nLet $\\varphi: k \\rightarrow k^{\\prime}$ be an isomorphism of fields, and let $\\varphi_{*}: k[ x] \\rightarrow$ $k^{\\prime}[ x]$ be the ring isomorphism: $$ \\varphi_{*}: g(x)=a_{0}+a_{1} x+\\cdots+a_{n} x^{n} \\mapsto g^{\\prime}(x)=\\varphi\\left(a_{0}\\right)+\\varphi\\left(a_{1}\\right) x+\\cdots+\\varphi\\left(a_{n}\\right) x^{n} $$ Let $f(x) \\in k[ x]$ and $f^{\\prime}(x)=\\varphi_{*}(f) \\in k^{\\prime}[ x] .$ If $E$ is a splitting field of $f$ over $k$ and $E^{\\prime}$ is a splitting field of $f^{\\prime}$ over $k^{\\prime}$, then there is an isomorphism $\\Phi: E \\rightarrow E^{\\prime}$ extending $\\varphi$ :\n\r Then any splitting of a given polynomial is the same one. That\u0026rsquo;s why we say \u0026ldquo;the splitting field\u0026rdquo; instead of \u0026ldquo;a splitting field\u0026rdquo;. Consider a field $E$ with $p=q^n$ elements. Then $E^\\times$ has order $q-1$ and $\\alpha^{q-1}=1$ for all $\\alpha\\in E^\\times$. Then every element of $E$ is a root of $g(x)=x^q-1\\in\\mathbb F_p[ x]$. Then $E$ is a splitting field of $g$. Since the splitting fields of $g$ are isomorphic, the fields with order $q=p^n$ are isomorphic.\n","date":"2021-03-21T14:31:42Z","image":"https://lingerois.com/p/field-theory-1-field-field-extension/cover_hu26eba08667d9da1525a3a08e64e34e3d_134973_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/field-theory-1-field-field-extension/","title":"Field Theory (1) Field, Field Extension"},{"content":"背景介绍 Ring-LWE和Modular-LWE问题已经在密码学理论和应用中非常广泛地使用了，而其中最为广泛使用的环，则是环$R_q=\\mathbb Z_q[x]/\\Phi_m(x)$，因此在这个环上快速进行乘法，成了基于Ring/Modular-LWE的密码算法实现中的效率方面关注的重要问题。\n现假设我们有多项式$a,b\\in R_q$并且要计算它们相乘后在，如果采用直接在$\\mathbb Z[x]$中计算乘积再求模的方式，我们首先得计算出$a\\cdot b\\in\\mathbb Z[x]$，然后再依次模上$\\Phi_m(x)$和$q$——这将会造成非常大的开销。幸运的是，我们有一个非常聪明的办法可以避免这个问题，该问题可以避免求多项式模$\\Phi_m(x)$这一经常使用的操作，使得整个计算过程极大地加速，再配合上模素数运算的相关算法，可以使得整个运算在很快地时间内完成，极大提高了Ring/Modular-LWE相关算法的效率和实际应用价值。\n这个巧妙的办法就是运用称作数论变换$\\mathsf{NTT}(\\cdot)$的同构，将多项式变换$a,b$均为向量$\\hat a,\\hat b$，然后计算$\\widehat{ab}=\\hat a\\odot \\hat b$，计算完成后，再用逆数论变换$\\mathsf{NTT}^{-1}$将$\\widehat{ab}$恢复为$a\\cdot b$。这里的$\\mathsf{NTT}$和$\\mathsf{NTT}^{-1}$均为非常简单的操作，而\u0026quot;$\\odot$\u0026ldquo;就是简单地将两个相同长度的向量的对应位乘起来再模$q$以得到一个新的向量，是一个非常简单的操作！以上两个运算使得多项式的乘法可以高效的计算，更进一步如果我们将反复用到一个多项式用作乘数，我们甚至可以让它暂时始终保持数论变换下的形式，来取得更好的计算效率。\n下文中，我们将对上述过程进行形式化的描述，并介绍具体的算法，以及算法背后的一些数学知识。\n数论变换算法 数论变换算法的形式多种多样，我们采用文章[LN16]中的方式进行介绍，但对记号做一定的修改。选择这个文章中的方式的主要原因一来是因为该文对数论变换的描述非常接近离散傅里叶变换，因此熟悉离散傅里叶变换的读者可以快速明白整个算法的过程；二来该文中的描述足够简洁和清晰，这样想要阅读原文的读者也不会花费大量时间。改变原文的记号的是希望同Ring-LWE的开山之作[LPR12]及其其他相关文章相统一，以能更好地进行理论方面的解释。同时不熟悉傅里叶变化的读者也完全没有必要再去研究它的具体过程，以及它到底有什么用，我们在文章将其当成一个固定的模块来使用，它是数论变换的一个环节，而其逆变换也是数论逆变换的一个环节。\n   符号的意义 [LN16]中的符号 本文中的符号     傅里叶变换 $\\mathrm{NTT}$ $\\mathsf{DFT}$   傅里叶逆变换 $\\mathrm{INTT}$ $\\mathsf{DFT}^{-1}$   数论变换形式的多项式 - $\\hat a$    我们考虑最常见的情形，设$m=2^d$是一个2的幂次，并令$n=\\phi (m)$, 其中$\\phi(\\cdot)$是高斯函数，则有$n=2^{d-1}$。在这样的参数下，分圆多项式具有非常简洁的形式$\\Phi_m=x^n+1$，模这样的分圆多项式的多项式环也是Ring/Modular-LWE算法中最常选择的环。如果素数$q$的选择也恰好使得$\\mathbb Z_q^\\times$中有一个阶为$m$的元素$r$，此时数论变换也就派上用场了。现在假设上述参数全部满足，计算环元素$a,b\\in\\mathbb Z_q[x]/\\Phi_m(x)$可以通过数论变换来进行，由于多项式也可以写成由系数组成的向量的形式，对于任意多项式$c=c_0+c_1x+c_2x^2+\\cdots+c_{n-1}c^{n-1}\\in\\mathbb Z_q[x]/\\Phi_m(x)$，$\\mathbb Z_q^n$中的向量，即$c=(c_0,c_1,\\cdots,c_{n-1})$，有了这种对应后，我们不再区分几种变换函数中的参数是多项式还是向量。首先我们假设$\\omega=r^2$，并令矩阵\n$$ \\mathbf A=\\left[ \\begin{matrix} \\omega^0 \u0026amp; \\omega^0\t\u0026amp; \\omega^0 \u0026amp; \\cdots \u0026amp; \\omega^0 \\newline \\omega^0 \u0026amp; \\omega^1\t\u0026amp; \\omega^2 \u0026amp; \\cdots \u0026amp; \\omega^{n-1} \\newline \\omega^0 \u0026amp; \\omega^2 \u0026amp; \\omega^4 \u0026amp; \\cdots \u0026amp; \\omega^{2(n-1)} \\newline \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\newline \\omega^0 \u0026amp; \\omega^{n-1}\t\u0026amp; \\omega^{2(n-1)} \u0026amp; \\cdots \u0026amp; \\omega^{(n-1)^2} \\end{matrix} \\right] $$\n实际上这个矩阵就是离散傅里叶变换的矩阵，我们记$\\mathsf{DFT}(c)=\\mathbf {A}c$。这里$\\mathsf{DFT}$也可以看作是对多项式的赋值，通过赋给$x$不同的值来形成一个新的多项式，我们有$\\mathsf{DFT}(c)=(c(\\omega^0),c(\\omega^1),\\cdots,c(\\omega^{n-1}))$。对多项式做傅里叶变换不是我们的终极目的，在这之前，我们还需要另一种变换，我们称之为$R$变换。对一个多项式进行$R$变换，可以表示为$R(a)=(a_0,ra_1,r^2a_2,\\cdots,r^{n-1}a_{n-1})$。这个过程也可以用矩阵来表示，即令\n$$ \\mathbf R=\\left[ \\begin{matrix} r^0 \u0026amp; \u0026amp; \u0026amp; \\newline \u0026amp; r^1 \u0026amp; \u0026amp; \\newline \u0026amp; \u0026amp; \\ddots \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; r^{n-1} \\end{matrix} \\right] $$\n则显然有$R(a)=\\mathbf Ra$。我们整个数论变换$\\mathsf{NTT}(a)$可以表示为$\\mathsf{NTT}(a)=\\mathsf{DFT}(R(a))=\\mathbf{AR}a$。我们固定用$\\hat a$表示$a$经过数论变换后的形式，即$\\hat a=\\mathsf{NTT}(a)$。由于$\\mathbf A$和$\\mathbf R$均为可逆矩阵，则显然也就是一个同构变换，其逆变换也可以很快地通过$a=\\mathsf{NTT}^{-1}(\\hat a)=(\\mathbf{AR})^{-1}\\hat a$来求出。矩阵$\\mathbf A$的逆矩阵为\n$$ \\mathbf A^{-1}=n^{-1}\\left[ \\begin{matrix} \\omega^0 \u0026amp; \\omega^0\t\u0026amp; \\omega^0 \u0026amp; \\cdots \u0026amp; \\omega^0 \\newline \\omega^0 \u0026amp; \\omega^{-1}\t\u0026amp; \\omega^{-2} \u0026amp; \\cdots \u0026amp; \\omega^{-(n-1)} \\newline \\omega^0 \u0026amp; \\omega^{-2} \u0026amp; \\omega^{-4} \u0026amp; \\cdots \u0026amp; \\omega^{-2(n-1)} \\newline \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\newline \\omega^0 \u0026amp; \\omega^{-(n-1)}\t\u0026amp; \\omega^{-2(n-1)} \u0026amp; \\cdots \u0026amp; \\omega^{-(n-1)^2} \\end{matrix} \\right] $$ 其中$n^{-1}$表示$n$在$\\mathbb Z_q^times$中的逆元。显然矩阵$\\mathbf A^{-1}$是对向量的作用是求它的傅里叶逆变换。而$\\mathbf R$的可以根据对角矩阵求逆的方式简单求出: $$ \\mathbf R^{-1}=\\left[ \\begin{matrix} r^0 \u0026amp; \u0026amp; \u0026amp; \\newline \u0026amp; r^{-1} \u0026amp; \u0026amp; \\newline \u0026amp; \u0026amp; \\ddots \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; r^{-(n-1)} \\end{matrix} \\right] $$ 有了以上的基础操作，整个通过数论变换来求多项式$a,b\\in\\mathbb Z_q[x]/\\Phi_m(x)$在该环中的积可以可以表示为$a\\cdot b=\\mathsf{NTT}^{-1}(\\mathsf{NTT}(a)\\odot\\mathsf{NTT}(b))$，其中$\\odot$就是在前文中提到过的向量逐位乘。除此之外，更加可喜的是，由于$\\hat a=\\mathbf{AR}a,\\hat b=\\mathbf{AR}b$，如果用$\\oplus$来表示向量的逐位加，那么根据$a+b=a\\oplus b$有$\\hat a\\oplus \\hat b=(\\mathbf{AR}a)\\oplus(\\mathbf{AR}b)=\\mathbf{AR}(a\\oplus b)$，因此$a+b=(\\mathbf{AR})^{-1}(\\hat a\\oplus \\hat b)$。也就是说，向量的加法也可以在数论变换的形式下通过逐位相加完成！\n还原最初的形式 我们将傅里叶变换用作数论变换中的一个模块，来帮助读者快速理解数论变换的过程，但是要探究它的本质，我们还是要回到最初的形式，即研究复合变换$\\mathsf{NTT}(a)=\\mathsf{DFT}\\circ R (a)$做了什么样的操作。根据矩阵的计算结果，我们有 $$ \\mathbf{AR}=\\left[ \\begin{matrix} r^0\u0026amp;\tr^1\u0026amp;\tr^2\u0026amp;\t\\cdots\u0026amp;\tr^{n-1}\\newline r^0\u0026amp;\tr^3\u0026amp;\tr^6\u0026amp;\t\\cdots\u0026amp;\tr^{3( n-1 )}\\newline r^0\u0026amp;\tr^5\u0026amp;\tr^{10}\u0026amp;\t\\cdots\u0026amp;\tr^{5( n-1 )}\\newline \\vdots\u0026amp;\t\\vdots\u0026amp;\t\\vdots\u0026amp;\t\\ddots\u0026amp;\t\\vdots\\newline r^0\u0026amp;\tr^{2n-1}\u0026amp;\tr^{2( 2n-1 )}\u0026amp;\t\\cdots\u0026amp;\tr^{( n-1 ) \\left( 2n-1 \\right)} \\end{matrix} \\right] $$ 我们可以看出$\\mathsf{NTT}(a)=(a(r),a(r^3),\\cdots,a(r^{2n-1}))$，其中$r$在$\\mathbb Z_q$中的阶为$m=2n$，而$1,3,5,\\cdots,2n-1$则正是$\\mathbb Z_m^\\times$中的元素。这一切究竟是为什么？为什么这样一种奇怪的多项式赋值可以让我们如此简便地对$\\mathbb Z_q[x]/\\Phi_m(x)$中的元素做运算？要探究背后的原因，一切都还要从“数的故事”说起。\n数的故事 数的故事就像神话一样长，我们没有办法从故事的序章开始讲，只好假设绝大部分读者都听过其中很多广为人知的章节，今天我们就讲那些章节之后的故事。如果读者没有听过太多数的故事，那么阅读任何一本初等数论或代数的读物都是不错的选择。\n在数的世界中，我们熟悉的有大世界$\\mathbb C$，即所有复数的世界；也有小世界$\\mathbb Q$，即有理数的世界；甚至还有迷你世界$\\mathbb Z$即所有整数的世界。读者都应该知道，在大世界和小世界之间，应该存在其它的世界，例如著名的“次大世界”$\\mathbb R$就介于$\\mathbb C$和$\\mathbb Q$之间，然后大家却经常忽略二者之间的一些“中等世界”。在讲中等世界的故事之前，我们需要对数的大世界了解更多。\n代数数 即使是大世界中的数，也要分很多的等级，例如整数是一种非常稀有的数，而有理数则相对要普遍一些，无理数相比有理数来说，又要多得多。但是在无理数和有理数之间，实际上还有一个等级——代数数。代数数，就是可以那些作为有理系数的代数方程（即多项式$p(x)=0$的形式）的解的数，例如$\\sqrt 2$，它就是方程$x^2-2=0$的一个解，因此是一个代数数；而$\\pi$和$e$就不是那么幸运了，它们不能被表示成任何一个有理系数的代数方程的解，因此不是代数数，这样的数我们也给它们一个名字，称为\\textbf{超越数}。\n在复数的世界中，有理系数的代数方程的解并不一定是落在实数中的，我们可以将代数数推广到整个复数世界中来，称为复数中所有是某个有理系数的多项式$f(x)\\in\\mathbb Q[x]$的根的数为代数数（这里需要注意到多项式和代数方程的一一对应关系，以及前者的根就是后者的解）。复数中的代数数最简单的例子就是$i$，由于$i$是$x^2+1$的一个根，因此它是一个代数数。\n代数数的故事还没完。一个代数数显然可以是无穷多个有理系数的多项式的根，因为对于任意的$\\alpha\\in\\mathbb Q$而言，多项式$p(x)$和$\\alpha p(x)$显然有着相同的根；除此之外，若$\\zeta$是多项式$p(x)\\in\\mathbb Q[x]$的一个根，那么对于任意的$q(x)\\in\\mathbb Q[x]$，$\\zeta$也是$p(x)\\cdot q(x)\\in\\mathbb Q[x]$的一个根，则是由于$p(\\zeta)\\cdot q(\\zeta)=0\\cdot q(\\zeta)=0$。在以代数数$\\zeta$为根的千千万万个有理系数多项式中，实际上有一个就可以代表它们的所有，即那个最高次项的系数是$1$的有理数域中的不可约多项式，我们称这样的多项式为首一不可约多项式，也称其为$\\zeta$的最小多项式。也许一些简单的故事主角更能说明问题：\n $x^2+1$是$i$的最小多项式。$x^2+1$的最高次项系数为$1$，满足了“首一”的条件；由于在复数域上，它可以分解为$x^2+1=(x-i)(x+i)$，尚若它能在有理数域上分解，分解的结果应该是同实数域中的分解相同，因此实数域上的分解结果表明$x^2+1$不能在有理数域中分解，因此它是一个不可约多项式，也是$i$的最小多项式。 $x^3+1$不是$-1$的最小多项式。$x^3+1=(x+1)(x^2-x+1)$是一个可约的多项式。  当然，寻找一个代数数的最小多项式并不是一个简单的问题，需要更多的背景知识，但是我们可以按照例子中，利用一个结论来论证一些多项式是最小多项式。根据多项式分裂的原理，如果一个多项式能够在域$K$上分裂，又能在它的子域$E$上分裂，那么在两个域上分裂的结果应当是相同的。那么显而易见，如果一个多项式$f(x)$在实数域上能分解为系数中含有复数的一次多项式，那它就一定是一个有理数域上的不可约多项式。这是由于$\\mathbb Q$是$\\mathbb C$的子域，如果$f(x)$在$Q$上分裂，那么其分裂出的多项式应当是系数是有理数，那么它在$\\mathcal C$上分裂出的多项式系数也就应当是有理数了，与事实显然是矛盾的。除此之外，所有的代数数也是可以构成一个域的，称为\\textbf{代数数域}，证明的方法多种多样，读者不妨自己尝试一下。到此为止，我们找到了一个“中等世界”。\n代数数中还有一类很特殊的数，这些数是代数数中的“整数”，它们是那些最小多项式是整系数多项式的代数数，我们称它们为\\textbf{代数整数}。根据这个定义$\\sqrt 2,i,\\frac{\\sqrt 2}{2}+\\frac{\\sqrt 2}{2}i$都是代数整数，因为它们的最小多项式分别是$x^2-2,x^2+1,x^8+1$。可以证明，有理数中的代数整数就是整数，因此我们可以将有理数域和代数数域对应起来，它们各自包含一个“整数环”，代数数域包含的就是代数整数环，而有理数域包含的就是整数环。\n域扩张 现在就让我们来看看，其他“中等世界”到底是什么样。如果我们试图向有理数域中添加一个代数数，为了保持域的特征，我们添加一个元素是远远不够的，但是添加进去所有的代数数肯定又是够的，那么就可能有如下两种可能：\n 必须同时添加其他所有的代数数 可以只添加一部分代数数  我们用一个简单的例子来说明，第二种说法是对的。我们知道$\\sqrt 2$是一个代数数，现在考虑向$\\mathbb Q$中添加$\\sqrt 2$并向其中尽可能少的添加代数来形成一个新的域$\\mathbb Q(\\sqrt 2)$。首先根据域的定义，所有形如$a+b\\sqrt 2$（以下默认$a,b\\in\\mathbb Q$）的元素都必须加入$\\mathbb Q(\\sqrt 2)$。那么加入这些元素够了吗？可以肯定的是，任意两个形如$a+b\\sqrt 2$的数的加法、乘法、减法都可以表示成这样的形式，而除法也不难证明。既然除法可以保证，那么$r=a+b\\sqrt 2$的乘法逆元也可以通过$1/r$来计算，也就是说，所有$a+b\\sqrt 2$的数组成的集合就是我们需要的$\\mathbb Q(\\sqrt 2)$。$\\mathbb Q(\\sqrt[3]2)$的形式要更加复杂一些，需要加入所有形如$a+b2^{1/3}+c2^{2/3},a,b,c\\in\\mathbb Q$的数才行。\n如果更加深究一点我们会发现，无论是$\\mathbb Q(\\sqrt 2)$还是$\\mathbb Q(\\sqrt[3]2)$，其中的元素都可以用“一串”$\\mathbb Q$表示出来，而并不需要一些“外来魔法”。对于任意的代数数$\\zeta$这样还是行得通吗？即，我们是否可以将$\\mathbb Q(\\zeta)$表示成由$\\zeta$的次数为基的$\\mathbb Q$中的向量？现在我们给代数数定义一个新的属性，叫做它的次数，这个次数也就是它的最小多项式的次数。假设$f(x)=x^n+a_{n-1}x^{n-1}+\\cdots+a_0$是$\\zeta$的最小多项式，那么根据$f(\\zeta)=0$就有$\\zeta^n=-(a_{n-1}\\zeta^{n-1}+\\cdots+a_1\\zeta^1+a_0)$，即$\\zeta^n$可以表示为由${1,\\zeta,\\cdots,\\zeta^{n-1}}$为基组成的向量。这个操作对于所有的$\\zeta^m$（其中$m$为大于$n$的整数）也可行，只需要反复代入$\\zeta^n=-(a_{n-1}\\zeta^{n-1}+\\cdots+a_1\\zeta^1+a_0)$就可以将$\\zeta^m$表示成上述形式。实际上，可以验证$\\mathbb Q(\\zeta)$就可以表示为以${1,\\zeta,\\cdots,\\zeta^{n-1}}$为基的$\\mathbb Q$中的向量。\n通过这样引入新的元素，将域扩大到一个最小的能包含原先的域和该新元素的域这样的操作，称为域扩张。而在$\\mathbb Q$中引入代数数后，扩张后的域可以表示成$\\mathbb Q$的向量，这个向量的维数就称为域扩张的次数。显然对于$n$次代数数$\\zeta$来说，$\\mathbb Q(\\zeta)$是一个$\\mathbb Q$的$n$次扩张。我们将所有向$\\mathbb Q$中引入代数数进行域扩张后得到的域称为\\textbf{数域}。\n有关域扩张，还有说不完的故事，扩张可以通过不引入代数数，而是引入超越数来进行，或者扩张又可以是针对某个多项式的根来说，又或是在有限域中研究扩张，这些都是精彩的故事。今天让我们关注我们的故事，继续说完数论变换的故事。\n分圆多项式和分圆域 现在我们将问题进一步简化，我们只找那些让我们看起来“舒服”一些素多项式作为模多项式。一个天然的选择就是“分圆多项式”。分圆多项式是这样的：对于一个$m$次分圆多项式来说\n  首先找到所有的$m$阶本元根，即$\\omega_m^k = e^{\\frac{2\\pi k}{m}}$\n  计算$\\Phi_m(x)=\\prod_{i\\in\\mathbb Z_m^\\times}(x-\\omega_m^i)$\n分圆多项式始终是一个整系数的多项式。我们将域$Q[\\omega_m^{1}]$这样的域都叫做分圆域，显然它同构于$\\mathbb Q[x]/\\Phi_m(x)$。\n  当$m=2^d$为某个2的幂次方时，我们有$\\Phi_m(x)=x^{m/2}+1$。这里显然对于所有的$\\omega_m^i,i\\in\\mathbb Z_q^\\times$来说，$\\Phi_m(x)$就是$\\zeta_i$的最小多项式。我们稍后就会说，这一的选择会使得我们在计算上有相当大的优势。我\n从代数扩张到多项式域 对于一个代数数$\\zeta$来说，扩域$\\mathbb Q(\\zeta)$中的元素可以被表示为$a_{n-1}\\zeta^{n-1}+\\cdots+a_1x+a_0$的形式，这不得不让人想到多项式。实际上，作映射$\\kappa:\\zeta\\mapsto x$，则$a_{n-1}\\zeta^{n-1}+\\cdots+a_1\\zeta+a_0$就可以表示为$a_{n-1}x^{n-1}+\\cdots+a_1x+a_0$，这也就是$\\mathbb Q[x]/f(x)$中的多项式！可以确定的一点是，由于$f(x)$是一个$\\mathbb Q$不可约中的不可约多项式，$\\mathbb Q[x]/f(x)$也就是一个域，并且其元素同$\\mathbb Q(\\zeta)$的元素是一一对应的，进一步可以检查映射$\\kappa$是满足同态关系的，也就是说$\\mathbb Q(\\zeta)$和$\\mathbb Q[x]/f(x)$是同一个域。我们研究Ring/Modular-LWE的时候，本质上是在研究复数中的元素，多项式只是我们看到的外在形式。\n扩域中的代数整数 接下来我们考虑的问题中，为了避免问题变得过于复杂，我们限定$\\zeta$为代数整数，并分析扩域$\\mathbb Q(\\zeta)$中的代数整数都是怎样的元素？这里需要注意的是，$\\mathbb Q(\\zeta)\\cong \\mathbb Q[x]/f(x)$中的$f(x)$是$\\zeta$的最小多项式，是一个整系数多项式。首先由于$\\zeta$本身是代数整数，且所有的代数整数构成环，那么所有形如$\\sum_{i=0}^{n-1}\\mathbb Z\\cdot \\zeta^i$的数都是代数整数。假设$K=\\mathbb Q(\\zeta)$中所有的代数整数集合为$R$，由于$\\mathbb Q(\\zeta)$本身具有加法和乘法封闭性，而所有的代数整数中的元素又在$\\mathbb C$中构成环，因此$R$中的数相互做加法和乘法仍然会落在$R$中，$R$也就是$K$的一个子环。我们又可以简单地验证$Z(\\zeta)=\\sum_{i=0}^{n-1}\\mathbb Z\\cdot \\zeta^i$（注意这里不是域扩张）也是$K$中的一个环，显然有$\\mathbb Z(\\zeta)\\subset R$。\n这个包含关系当$\\zeta$是$m$次本原根（即$\\zeta^m=1$）时可以改写为等号。如果要讲这里的故事，读者需要对环的性质具有充分的了解，我们决定暂时先跳过这一篇章，将它作为日后的谈资，而直奔我们的主题。当$R=\\mathbb Z(\\zeta)$后，那么，$K$中的代数等式，在先前到模不可约多项式域后，对应也就是那些系数为整数的多项式。到此，我们终于明白，数论变换处理的对象就是那些数域中的代数整数。\n中国剩余定理 我们都听过一个很神奇的定理，这个定理来自《孙子算经》中的一个小问题：“有物不知其数，三三数之剩二，五五数之剩三，七七数之剩二。问物几何？”，简而言之就是求一个整数$k$，它满足$k\\equiv 3\\mod 2, k\\equiv 3\\mod 5, k\\equiv 2\\mod 7$。这个问题的答案是多少并不重要，重要的是，任何一个数，都可以分解成这一的形式。我们知道$3,5,7$都可以看作是环$\\mathbb Z$的理想，而且，其中任意两个理想都可以生成整个环，例如$(3)+(5)=\\mathbb Z$。我们称环$R$的两个理想$I,J$互素，如果$I+J=R$。这个问题实际上是将一个环中的元素写成了它们互素的理想的形式。\n例如上文中的题目答案是$23$，首先将$(3)$看作是一个理想，则$23$就应该对应商环$\\mathbb Z_3=\\mathbb Z/(3)$中的$2+(3)$。而在理想$(5),(7)$对应商环中，则是依次将23表示为$3+(5)\\in\\mathbb Z_5$和$2+(7)\\in\\mathbb Z_7$。\n上述的过程在环中有一个类似版本，可以将环中的元素分解到一组互素的理想中去。更加精确的说，如果我们找到环$R$中一组两两互数的理想$I_1,\\cdots,I_n$且$I=\\prod_{i\\in[n]}I_i$，那么$R/I$中的元素就可以映射为$\\bigoplus_{i\\in[n]}(R/I_i)$中的元素。如果$I=R$，那么我们也就可以将$R$中的元素化更最简单的形式。而且这个映射是非常容易做到的，就是商环的自然映射！例如对于$23$来说，环到商环$\\mathbb Z_3$的自然映射，就是将$23$映射到$\\mathbb Z_3$中$23+(3)$，也就是$\\mathbb Z_3$中的2。\n分圆域中代数整数环的分解 让我们回到代数整数环的中国剩余定理讨论中来。这里我们将问题进一步简化，我们认定$\\zeta=\\omega_m^i$，其中$i\\in\\mathbb Z_m^\\times$，由于$\\zeta$的最小多项式就是$\\Phi_m(x)$，因此$\\mathbb Q(\\zeta)=\\mathbb Q[x]/\\Phi_m(x)$。\n文中提到的论文 [LN16]: Patrick Longa and Michael Naehrig. Speeding up the Number Theoretic Transform for Faster Ideal Lattice-Based Cryptography. eprint\n[LPR12]: Vadim Lyubashevsky and Chris Peikert and Oded Regev. On Ideal Lattices and Learning with Errors Over Rings. eprint\n","date":"2020-04-12T21:19:24Z","image":"https://lingerois.com/p/%E6%95%B0%E8%AE%BA%E5%8F%98%E6%8D%A2%E7%AE%80%E4%BB%8B/fourier_hu450a0194d15d2e0104a8812847625760_1466219_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E6%95%B0%E8%AE%BA%E5%8F%98%E6%8D%A2%E7%AE%80%E4%BB%8B/","title":"数论变换简介"},{"content":"If $\\mathbf{P}=\\mathbf{NP}$, then $\\mathbf N=1$ or $\\mathbf{P}=0$.\n----Turing Machine\n$\\mathbf{NP}$完备性的是计算复杂性上一个至关重要的问题. 简而言之, $\\mathbf{NP}$问题就是那些能够在确定多项式时间内被验证答案的判定问题, 即那些很容易就被检验的问题. $\\mathbf{NP}$问题中, 有大量非常有现实意义但到现目前为止都没有好的解决办法的问题. 有关$\\mathbf{NP}$完备性的讨论热度也从来没有衰减过. 2000年, 美国克雷数学研究所将$\\mathbf{P}\\overset{?}=\\mathbf{NP}$列为七个千禧年大奖难题之一.\n非确定计算模型 现在我们介绍一个计算模型. 该计算模型机的功能非常强大, 能够在多项式时间内求解很多我们尚未发现高效算法的问题.\n非确定图灵机  非确定图灵机就像一台可以有无限个线程的计算机.\n 非确定图灵机(nondeterministic Turing machine, NDTM)与图灵机的定义大致相同. 不同的是, 非确定图灵机有两个转移函数, 每一步计算可以选择两个转移函数中的任何一个. 非确定图灵机物理上是不能实现的.\n 定义 非确定图灵机\n一个非确定图灵机$N$是一个三元组$(\\Gamma, Q, \\delta=(\\delta_1,\\delta_2))$.\n 有限集$\\Gamma$是字母表, 表示纸带可以记录的符号集. 有限集$Q$是状态集, 表示状态机的状态, 其中一个特殊的状态$q_\\text{start}$为起始状态, $q_\\text{accept}$为表示接受的停机状态, $q_\\text{reject}$为表示拒绝的停机状态. $\\delta_1,\\delta_2: Q\\times \\Gamma^k\\to Q\\times \\Gamma^{k-1}\\times \\lbrace \\text L,\\text S,\\text R\\rbrace ^k$是两个转移函数   至于如何选择转移函数, 不是我们关心的问题, 因为我们非确定图灵机对问题的判定只关心计算路径.\n非确定图灵机的中还有一点需要说的是, 非确定图灵机对一个语言的判定结果, 是从最终的停机状态进行输出的. 实际上我们也可以这样来定义图灵机, 但是 没有必要. 非确定图灵机之所以要这样定义, 是因为其判定一个语言的定义与图灵机有所不同. 在定义非确定图灵机判定一个语言之前, 我们首先定义计算分支.\n非形式化地讲, 一台非确定图灵机$N$在特定输入$x$下, 计算过程中一条计算分支定义为从起始状态开始, 随机选择$\\delta_1,\\delta_2$进行计算, 直到$q_\\text{accept}$或$q_\\text{reject}$而**停机**. 这样一来, 每一种直到停机状态地$\\delta_1,\\delta_2$选择序列, 就对应一条计算分支. 这里地分支的描述已经很接近非确定自动机中的计算分支.\n真正让非确定图灵机无法实现的是, 非确定图灵机停机和接受一个串的定义. 我们定义,\n 非确定图灵机$N$在$T(n)$时间内停机, 当且仅当对于任意的输入串$x\\in\\lbrace 0,1\\rbrace ^\\ast$, 无论$N$如何选择转移函数, 在$T(|x|)$时间内停机.\n 这里重申一下, 非确定图灵机的停机就是进入两个停机状态: $q_\\text{accept}$或$q_\\text{reject}$中的任意一个. 此外, 我们也可以将图灵机的输出也转换成用状态表示.\n 非确定图灵机$N$接受一个串$x$定义为, 输入$x$, 存在一个转移函数的选择方式, 使得$N$最终到达$q_\\text{accept}$状态, 记作$N(x)=1$.\n 可以看出, 就这点来说, 物理上实现非确定图灵机就不太容易了. 非确定图灵机每一步计算, 就相当于是将一个线程分成了两个, 两个不同的转移函数选择各自对应一个子线程. 最终, 所有的线程中, 只要任何一个达到了$q_\\text{accept}$就宣告图灵机接受该串. 还有一点需要注意的是, 我们这里并不要求图灵机每一条计算分支最终都会停机, 同时基于这一点, 我们可以通过如下方式定义非确定图灵机拒绝一个串.\n 非确定图灵机$N$拒绝一个串$x$定义为, 输入$x$, 至少存在一个转移函数选择方式使得$N$停机, 且当$N$停机时, $N$最终均将到达$q_\\text{reject}$状态, 记作$N(x)=0$.\n 现在我们加上时间的限定, 给出非确定图灵机在$T(n)$时间内停机的定义.\n 非确定图灵机$N$在$T(n)$时间内停机, 如果对于任意输入$x\\in\\lbrace 0,1\\rbrace ^\\ast$, 无论$N$如何选择转移函数, 都会在$T(|x|)$时间内到达$q_\\text{accept}$或$q_\\text{reject}$状态.\n 也就是说, 我们要求$N$的每一条计算分支都在$T(|x|)$步就算内停机.\n非确定图灵机的计算能力 首先我们说非确定图灵机$N$判定一个语言$L$可以被定义为$x\\in L\\iff N(x)=1$.\n可以证明, 非确定图灵机和图灵机具有同样的计算能力, 我们不做过多的证明, 但是我们对非确定图灵机拒绝一个串的定义做一些讨论.\n假设我们将非确定图灵机$N$拒绝一个串$x$定义为*非确定图灵机$N$拒绝一个串$x$定义为, 输入$x$, 当$N$停机时, $N$最终均将到达$q_\\text{reject}$状态*. 假设有一台图灵机, 它的两个转移函数是一样的, 那么它就是一台图灵机, 那么对于一个判定$\\mathbf{RE}$语言的图灵机$M$, 将它转换为一个两个转移函数均为$M$的转移函数的图灵机$N$, 那么$N$收到那些使得$M$不能停机的串$x$, 根据上述定义, 都应该有$N(x)=0$. 如果图灵机和非确定图灵机的计算能力相同, 也就有$\\mathbf R=\\mathbf{RE}$, 这显然是不正确的, 上述定义不是我们想要的.\n非确定时间  $\\mathbf{NTIME}$\n设$T:\\mathbb N\\to \\mathbb N$, 如果存在一台非确定图灵机$N$和一个常数$c$, 使得对于任意$x\\in\\lbrace 0,1\\rbrace ^\\ast$, $N(x)$在$cT(|x|)$时间内停机, 且对于任意$x\\in L$, 有$N(x)=1$且, 则$L\\in\\mathbf{NTIME}(T(n))$.\n 实际上我们就是结合了图灵机在指定时间内停机的定义和图灵机判定一个语言$L$的定义, 我们要求\n 非确定图灵机所有分支均在指定时间内停机 非确定图灵机判定指定语言  $\\mathbf{NP}$ 现在, 我们定义一个非常重要的复杂性类, 它对于计算机复杂性理论的研究具有重大意义.\n $\\mathbf{NP}$ $$ \\mathbf{NP}=\\bigcup_{c\\geq 1}\\mathbf{NTIME}(n^c) $$\n 用自然语言来叙述就是, $\\mathbf{NP}$就是那些能够被一台非确定图灵机在多项式时间内判定的语言, 即 $$ L\\in\\mathbf{NP}\\iff \\exists c \\exists i\\forall x\\in\\lbrace 0,1\\rbrace ^\\ast:N_i(x)=1\\leftrightarrow x\\in L\\text{ 且 }N_i在|x|^c\\text{时间内停机} $$\n但从语言的描述, 没有接触过的同学可能不知道$\\mathbf{NP}$问题意味着什么, 我们可以举一个简单的例子. 我们都知道判定一个数独的题目是否合法是困难的, 特别是在这个数独很大的时候. 但是对于非确定图灵机来说, 它只需要将这个数独填满再检查一遍这个答案是否通过即可. 由于每一条分支填写的答案不同(通过合理的编程即可容易地实现), 而且只要有一个分支是通过检查的就代表该数独题目确实有一个合法答案, 那这个题目也就是合法的. 对于一个输入规模为$n^2$的数独题目$x$来说, 每一条计算分支仅需要$O(n^2)$时间就可以完成猜测和检验, 因此整个问题输入$\\mathbf{NP}$.\n非确定通用图灵机 通用非确定图灵机(Nondeterministic Universal Turing Machine)类似于通用图灵机, 是一个可以模拟所有非确定图灵机运行的非确定图灵机. 同图灵机一样, 我们也可以对非确定图灵机进行编码, 将所有的非确定图灵机依次表示为 $$ N_0,N_1,N_2,\\cdots $$ 我们将编码$i$和要判定的串$x$输出到非确定通用图灵机$\\mathcal {V}$时, 非确定图灵机就会输出$\\mathcal V(i,x)=N_i(x)$. 由于非确定图灵机具有\u0026quot;猜\u0026quot;的能力, 因此通用非确定图灵机的构造相对通用图灵机来说会相对容易一些, 我们采取的策略是先猜想后验证.\n我们首先介绍快照(snapshot)的概念. 一条$k$带(非确定)图灵机的快照定义为 $$ \\langle a_1,\\cdots, a_k,q\\rangle\\in \\Gamma^k\\times Q $$ 其中$a_1,\\cdots,a_k$为每条纸带上读写头的位置, 而$q$表示当前机器所处的状态. 我们在知道(非确定)图灵机的快照后, 就可以知道它在某一步按照某一个转移函数的转移方式. 假设现在给你一台处于某个状态的(非确定)图灵机, 让你验证它从当前的快照是否能够跳转到下一个快照, 需要多少时间?\n首先, 我们要查看当前读写头的位置以及转移函数, 计算转移函数的结果, 然后根据转移函数的结果改写读写头处内容(虽然这一步与判定跳转的合法性无关, 但是可以维持我们的图灵机一直处在正确的计算步骤中), 转移读写头的位置和状态机的状态, 然后根据读写头的位置记录下读写头处的数据然后再和预期的快照进行匹配, 检查跳转是否正确. 整个过程都需要花费常数的时间.\n现在我们来构造通用非确定图灵机$\\mathbb V$. $\\mathbb V$在收到输入$(i,x)$后, 每一步模拟计算, 首先猜想$N_i(x)$下一个计算步骤的快照, 再检验计算步骤的合法性, 再检查到非法的猜想或者$N_i(x)$停机时停机. 且仅在模拟$N_i(x)$计算时进入$q_{\\text{accpte}}$状态时进入$q_{\\text{accpte}}$状态.\n假设$N_i(x)$需要$T$时间来完成计算, 由于猜想一个快照和检验当前状态的机器跳转到下一个快照(顺带维持机器的工作带)均只需要常数时间, 因此整个过程将$cT$时间内结束. 因此$\\mathbb V$模拟一台$T(n)$时间内停机的非确定图灵机$N$仅需用时$cT(n)$, 其中$c$是某个常数.\n如果你仔细思考就会发现, 相比通用图灵机, 这里之所以能节省出一个$\\log T(n)$系数是因为我们不需要花时间来回地移动纸带. 在通用图灵机中, 我们花了大量的时间去维护存储空间.\n非确定时间谱系定理 待写.\n$\\mathbf{NP}$完备性 $\\mathbf{NP}$的第二种定义 这一部分, 我们将从\u0026quot;证明\u0026quot;或\u0026quot;验证\u0026quot;的思想来陈述$\\mathbf{NP}$问题. 一个比较惊奇的结果是, $\\mathbf{NP}$也可以通过图灵机来进行定义.\n $\\mathbf{NP}$\n$L$是$\\mathbf{NP}$问题当且仅当存在一个多项式函数$p:\\mathbb N\\to\\mathbb N$和一个多项式时间的图灵机$M$, 对于任意$x\\in\\lbrace 0,1\\rbrace ^\\ast$有 $$ x\\in L\\iff \\exists u\\in\\lbrace 0,1\\rbrace ^{p(|x|)}: M(x,u)=1 $$ 并且称$u$是$x$在语言$L$中有关于$M$的一个认证(certificate, 或witness).\n 什么意思呢? 假设我们将一个语言$L$理解为一系列的真命题, 而所有的$\\lbrace 0,1\\rbrace ^\\ast\\backslash L$理解为假命题. 如果我们对所有的证明题都能给出一个(有关命题长度的)多项式长的证明, 且能够找到一台证明检验机器, 这台机器能够在多项式时间内完成证明的检验, 则称$L$是一个$\\mathbf{NP}$问题. 这个解释有两个重要的要求:\n 证明不能太长 检验过程不能过于复杂  这是一种接近我们自然人思维的东西, 就像平时处理数学命题一样, 去证明一个命题也许需要一些创造性工作, 但是不长且合理的证明, 我们总是能够在很短的时间内完成验证.\n回到我们刚才数独题目的合法性的例子, 如果有一台图灵机就是根据填入的答案的合理性来检查一个题目是否合法, 那么显然, 每一个合法的题目$x$, 其一个认证就是这个题目的答案.\n定义中还有几个需要注意的地方:\n 定义中并没有要求每个$x\\in L$只有一个认证, 也就是对于某个$x\\in L$可能有$M(x,u)=1$, 也有$M(x,u')=1$, 且两个认证都是多项式长的, 也都可以在多项式时间内完成验证. 定义中没有要求每个$x\\notin L$有一个\u0026quot;认证\u0026quot;能帮助$M$快速地判定$M(x,u)=0$.  两种定义的等价性 我们用$\\mathbf{NP}$表示第一种定义, 用$\\mathbf{NP}$表示第二种定义, 我们来证明两种定义的等价性\n$L\\in$$\\mathbf{NP}$$\\Rightarrow$$L\\in$$\\mathbf{NP}$ 设$L\\in$$\\mathbf{NP}$. 由于每个非确定图灵机$N$都是用一个图灵机$M$来代替, 并且将两个转移函数合并成一个. 用某个读写头的位置上的内容来表示下一步的计算使用哪个转移函数. 对于每个$x\\in L$, 就可以直接用$N(x)$计算步骤中每一个接受分支的转移函数选择序列作为$M$上进行判断的认证. 同样对于每个$x\\notin L$, 由于没有转移函数选择序列$u$使得$N(x)$某条计算分支接受, 因此$\\forall u\\in\\lbrace 0,1\\rbrace ^{\\text{poly}(|x|)}: M(x,u)=0$. 因此$L\\in$$\\mathbf{NP}$.\n$L\\in$$\\mathbf{NP}$$\\Rightarrow$$L\\in$$\\mathbf{NP}$ 假设$L\\in$$\\mathbf{NP}$, 则按照$L$定义中的符号$\\exists u\\in\\lbrace 0,1\\rbrace ^{\\text{poly}(|x|)}: M(x,u)=1$. 我们可以构造这样一台非确定图灵机$N$, 它拿到$x$后首先进行$\\text{poly}(|x|)$步骤的猜测, 然后再用$(x,u)$作为输入来模仿$M(x,u)$进行运算, 并输出$M(x,u)$. 显然$x\\in L\\iff \\exists u\\in\\lbrace 0,1\\rbrace ^{\\text{poly}(|x|)}: M(x,u)=1\\iff N(x)=1$. 由于$N$可以在多项式时间内停机, 因此$L\\in$$\\mathbf{NP}$.\n$\\mathbf{NP}$完备性 Karp归约 $\\mathbf{NP}$完备问题 Cook-Levin定理 其他$\\mathbf{NP}$问题 其他复杂度类 $\\mathbf{coNP}$与$\\mathbf{coNP}$完备性 $\\mathbf{NEXP}$ 其他主题 Ladner定理 Baker-Gill-Solovay定理 相对化 ","date":"2019-08-20T23:16:19Z","image":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A73-np%E5%AE%8C%E5%A4%87%E6%80%A7/turing_machine_hu0166a620cecfe8b8446df8ecb324d4a0_390991_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A73-np%E5%AE%8C%E5%A4%87%E6%80%A7/","title":"计算复杂性(3) NP完备性"},{"content":"BGV同态加密方案是由Zvika Brakerski, Graig Gentry, Vindo Vaikuntanathan提出于[BGV12] 1. 该方案是BV11b方案基础上一个较大的改进. 该方案挖掘出BV11b方案中模数切换可以降低密文的绝对噪声这一特点, 将其发扬广大, 使得在加密在无需Bootstrapping的情况下可以做到较多层数的同态乘法运算.\n如果需要实现全同态加密, 该方案仍需要引入Circular Security假设和Boostrapping. 但是由于模数切换使得我们可以在不进行Bootstrapping的情况下做较多次数的同态运算, 并且使得Bootstrapping之前的密文模数变得非常小, 因此Bootstrapping是非常容易的. 因此该方法能够显著降低Bootstrapping的次数和难度.\n简介 我们在介绍BV11b方案的时候, 介绍过密文的格式为$(\\mathbf v,w)$, 此处我们忽略了密文的同态层数. 密钥的解密可以表示为\n  $\\mathsf{Dec}(sk=\\mathbf s',(\\mathbf v,w))$: 计算并输出\n$$ (w-\\langle\\mathbf v,\\mathbf s'\\rangle\\mod q)\\mod 2 $$\n  我们将采用另一种形式的LWE加密来表示上述问题(在LWE介绍性文章(写成后地址将被更新到这里)以及本文之后的内容会有介绍), 用$\\mathbf c$表示密文, 用$\\mathbf s$表述明文, 上述解密过程可以被简化为$[[\\langle\\mathbf c,\\mathbf s\\rangle]_q]_2$, 其中$[\\cdot]_k$表示模$k$运算. 这种形式的密文噪声体现在哪里呢? 其实本身就是大$[\\langle\\mathbf c,\\mathbf s\\rangle]_q$概的噪声.\nBV11b的核心思想之一是在最后同态计算结束后, 需要将大密文(即维数和模数较大的密文)转换为小密文(即模数和维数较小的密文). 其中, 维数切换的操作是平凡, 而模数切换的操作需要一定的技巧性, 且其安全性依赖于稀疏子集和假设. 一个不太让人感觉到的惊奇的现象是, 在进行模数切换的时, 噪声也成比例减小了. 即我们有如下引理:\n 引理1 设$p$和$q$是两个奇数模数, $\\mathbf c$是一个整数向量. 令$\\mathbf c'$为一个距离$(p/q)\\cdot\\mathbf c$最近的一个整数向量满足$\\mathbf c'=\\mathbf c\\mod 2$. 则对于任意的$\\mathbf s$使得$|[\\langle\\mathbf c,\\mathbf s\\rangle]_q|\u0026lt;q/2-(q/p)\\cdot \\ell_1(\\mathbf s)$有 $$ [\\langle \\mathbf c',\\mathbf s\\rangle]_p=[\\langle\\mathbf c,\\mathbf s\\rangle]_q \\mod 2 $$ 且 $$ |[\\langle \\mathbf c',\\mathbf s\\rangle]_p|\u0026lt;(p/q)\\cdot |[\\langle\\mathbf c,\\mathbf s\\rangle]|+\\ell_1(\\mathbf s) $$ 其中$\\ell_1(\\mathbf s)$是$\\mathbf s$的第一范数.\n 第一个结果能够保持我们在输入正确密钥时解密结果的正确性, 而第二个结果则表明我们确实几乎在模数切换的同时几乎时等比例缩小了噪声, 这是由于从噪声分布中选择$\\mathbf s$的LWE具有从均匀分布中选择$\\mathbf{s}$的LWE具有几乎相当的平均意义下的困难性, 这使得我们的加密方案中$\\mathbf s$可以选自噪声分布$\\chi^n$使得$\\ell_1(\\mathbf s)$较小. 下面我们来证明上述引理.\n证明: 根据假设, 对于某个整数$k$有$[\\langle\\mathbf c,\\mathbf s\\rangle]_q=\\langle\\mathbf c,\\mathbf s\\rangle-kq$. 假设$e_p=\\langle\\mathbf c',\\mathbf s\\rangle-kp$, 我们现在证明$e_p$大概就是$\\mathbf c'$的噪声, 即$e_p=[\\langle\\mathbf c',\\mathbf s\\rangle]_p$. 由于$\\mathbf c'=\\mathbf c \\mod 2$且$p=q\\mod 2$, 因此$e_p=[\\langle\\mathbf c,\\mathbf s\\rangle]_q\\mod 2$. 由于 $$ \\begin{aligned} e_p\u0026amp;=\\langle \\mathbf c',\\mathbf s\\rangle-kp=\\langle \\mathbf c',\\mathbf s\\rangle-kq\\cdot \\frac pq \\newline \u0026amp;= \\langle \\mathbf c',\\mathbf s\\rangle+\\frac pq\\cdot ([\\langle\\mathbf c,\\mathbf s\\rangle]_q-\\langle\\mathbf c,\\mathbf s\\rangle)\\newline \u0026amp;=\\frac pq\\cdot [\\langle\\mathbf c,\\mathbf s\\rangle]_q+\\langle\\mathbf c'-(p/q)\\mathbf c,\\mathbf s\\rangle \\end{aligned} $$ 即$|e_p|\\leq (p/q)[\\langle \\mathbf c,\\mathbf s \\rangle]_q+\\ell_1(\\mathbf s)\u0026lt;p/2$. 从第二个不等式中, 我们得出, $e_p$大概就是$\\mathbf c'$的噪声, 因此有$|[\\langle \\mathbf c',\\mathbf s\\rangle]_p|\u0026lt;(p/q)\\cdot |[\\langle\\mathbf c,\\mathbf s\\rangle]|+\\ell_1(\\mathbf s)$.\n从上式的证明中, 我们也可以看出额外的噪声是如何引入的, 即从$\\langle\\mathbf c'-(p/q)\\mathbf c,\\mathbf s\\rangle$中产生.\n到了这里你也许就明白这个方案的工作原理了: 虽然噪声是和模数等比例缩小的, 但是如果噪声本身就比较小, 那么通过模数切换, 它将变得非常小, 使得一次乘法同态运算后噪声也不会变得太大. 例如两个模$q$噪声为$B$的密文进行同态乘法运算, 其结果噪声将会达到约$B^2$, 而将其模数切换为$p$后噪声为约$pB/q$. 再做乘法同态运算, 则噪声是$(pB/q)^2$. 我们发现, 虽然$B/q\\approx (pB/q)/p$, 但是做同态乘法运算后, 小密文产生的结果噪声占比约为$(pB/q)^2/q=p^2B/q^3$, 而原先的大密文噪声扎占比约为$B^2/q$, 显然小密文更占优势.\n基于如上的思想, 我们可以从一开始就选择非常大的模数$q_0$, 使得模数可以接受多次模数切换操作, 这样每次对噪声上界为$B$得密文做乘法后我们就进行一次模数切换, 将模数变成$q_i\\approx q_{i-1}/B$, 即模数变为原来的大概$1/B$, 来使得噪声不变得更大, 我们就可以在做到多次同态后, 使得噪声上界始终维持在一个较为稳定的范围内. 这个过程可以一直持续到我们将模数下降得太小(使得$B\u0026gt;q_L/2$)之前.\n如果不进行模数切换, 噪声是双指数倍数增长的, $B$噪声的密文经过$L$次同态变成$B^{2^L}$很快就能接近$q_0/2$, 而做模切换噪声则是指数下降的, 使得$q_i\\approx q_0/B^i$满足$B\u0026gt;q_i/2$显然要比原来的方案慢得多, 因此我们就可以进行更多次的同态乘法运算.\nGLWE介绍 在本文中, 作者将LWE与RLWE统一为了GLWE, 使得在介绍方案的时候不用重复劳动. 我们按照作者的思路, 对GLWE一些介绍.\nGLWE (General Learning with Errors) 是一种将LWE与RLWE统一的表示方式. 我们知道, LWE的元组都是$\\mathbb Z_q^n\\times \\mathbb Z_q$, 而RLWE的元组都是来自$R_q\\times R_q$, 我们注意到有一个维数$n$来描述元组中第一个选自均匀分布的元. 如果我们将$\\mathbb Z$也视作是一个环, 那么LWE的元组基于的环是$\\mathbb Z_q=\\mathbb Z/q\\mathbb Z$, 而RLWE基于的则是$R_q=R/qR$, 即可将二者也统一起来. 这样, 我们通过两个参数就可以确定我们选择的是LWE还是RLWE, 即元组中第一个元的维数$n$ (对于LWE来说, $n=\\text{poly}(n)$, 对于RLWE来说$n=1$), 以及元组所基于的环$R$. 我们用这种记法表示统一表示二者, 即GLWE.\n 定义2 GLWE\n设安全参数为$\\lambda$, 令$n=n(\\lambda)$为一个整数维数, 令$f(x)=x^d+1$其中$d=d(\\lambda)$是一个2的指数幂, ling $q=q(\\lambda)\\geq 2$是一个素数2, 令$R=\\mathbb Z[ x]/(f(x))$和$R_q=R/qR$, 令$\\chi=\\chi(\\lambda)$是一个$R$上的分布. GLWE$_{n,f,q,\\chi}$问题, 定义为区分如下两个分布:\n $R_q^{n+1}$上的均匀分布. 由如下方式产生的分布: 首选均匀生成$\\mathbf a\\overset{$}\\leftarrow R_q^n$和$\\mathbf s\\overset{$}\\leftarrow R^n_q$, 选择$e\\leftarrow \\chi$, 然后输出$(\\mathbf a,b=\\langle\\mathbf a,\\mathbf s\\rangle+e)$.   现在我们介绍GLWE困难的参数假设. 我们认为, 满足参数$n\\cdot d=\\Omega(\\lambda\\log(q/B))$的GLWE问题是安全的, 其中$B$表示$\\chi$输出的元素的长度上界. 目前该假设还未被证明, 但是也没有出现分析结果. 这里需要再次重申一下: GLWE的定义仅仅是为了我们的描述方便, 即我们实际上还是在基于LWE假设RLWE假设构造公钥加密方案和全同态加密方案. 也就是说, 你无需关心那些最终参数使得GLWE不是LWE或RLWE的参数.\nLeveled FHE构造 现在, 我们就来构造安全性基于GLWE的Leveled FHE方案. 这个方案采用了模数切换来控制噪声, 使得噪声始终维持在较小的水平, 而使得我们可以进行较多次的乘法同态运算. 不过在此之前, 我们还是像BV11b基于LWE的公钥加密方案一样, 我们先构造好基于GLWE的公钥加密方案.\n基于GLWE假设的公钥加密方案 该方案在选择$n=1$和环$R=\\mathbb Z$时, 得到的加密方案实际上是同BV11b中的LWE公钥加密方案是类似的, 但是有两点不同:\n 由于换了一种LWE的形式, 密钥的形式和最终解密的形式看起来略有不同. 基础密钥$\\mathbf s'$的选择来自于$\\chi^n$, 则是为了保证$\\mathbf s'$的第一范数较小, 从而使得我们在模数切换的时候能够有效控制噪声.  对于第一点不同, 熟悉LWE的读者可以立即看出来, 这仅仅是由于我们不再单独写出$\\mathbf b=\\mathbf A'\\mathbf s'+2\\mathbf e$, 而是将它作为矩阵的一列写进了$\\mathbf A=[\\mathbf b|-\\mathbf A']$.\n基于GLWE假设的公钥加密方案:\n  $\\mathsf{E.Setup}(1^\\lambda,1^\\mu,b)$: 由比特$b$来确定我们是构造LWE假设下的方案($b=0$)还是RLWE假设下的方案($b=1$). 选择一个$\\mu$比特的模数$q$和参数 $$ d=d(\\lambda,\\mu,b),n=n(\\lambda,\\mu,b),N=\\lceil (2n+1)\\log q\\rceil, \\chi=\\chi(\\lambda, \\mu, b) $$ 此处要求最终的参数使得GLWE问题实例具有安全性. 令$R=\\mathbb Z[ x]/(x^d+1)$, 并令参数集合$params=(q,d,n,N,\\chi)$.\n  $\\mathsf{E.SecretKeyGen}(params)$: 选择$\\mathbf s'\\leftarrow\\chi^n$, 输出$sk=\\mathbf s=(1,\\mathbf s'[1],\\cdots,\\mathbf s'[n])\\in R_q^{n+1}$.\n  $\\mathsf{E.PublicKeyGen}(params,sk)$: 均匀选择$\\mathbf A'\\overset{$}\\leftarrow R_q^{N\\times n}$, 选择$\\mathbf e\\leftarrow \\chi^N$并令$\\mathbf b=\\mathbf A'\\mathbf s'+2\\mathbf e$. 并令$pk=\\mathbf A=[\\mathbf b|-\\mathbf A']$.\n  $\\mathsf{E.Enc}(params,pk,m\\in\\lbrace 0,1\\rbrace )$: 令$\\mathbf m=(m,0,\\cdots,0)\\in R_q^{n+1}$, 选择$\\mathbf r\\overset{$}\\leftarrow R_q^N$, 输出密文$\\mathbf c=\\mathbf m+\\mathbf A^T\\mathbf r\\in R_q^{n+1}$.\n  $\\mathsf{E.Dec}(params,sk,\\mathbf c)$: 输出$m\\leftarrow [[\\langle\\mathbf c,\\mathbf s\\rangle]_q]_2$.\n  现在我们来看一下这个加密及解密过程为什么同BV11b中的方案是一样的. 对于加密来说, $$ \\mathbf c=\\mathbf m+\\mathbf [\\mathbf b|-\\mathbf A']^T\\mathbf r =(\\mathbf b^T\\mathbf r+m,-\\mathbf A'^T\\mathbf r) $$ 可见, 这就是把BV11b中密文的两部分写在了一起. 而解密操作也是类似 $$ \\begin{aligned} \\langle \\mathbf c,\\mathbf s\\rangle\u0026amp;=\\mathbf b^T\\mathbf r+m-\\langle\\mathbf A'^T\\mathbf r,\\mathbf s'\\rangle =\\mathbf b^T\\mathbf r+m-(\\mathbf A'\\mathbf s')^T\\mathbf r \\newline \u0026amp;= \\mathbf b^T\\mathbf r+m-(\\mathbf b-2\\mathbf e)^T\\mathbf r=m+2e \\end{aligned} $$ 其中$e=\\mathbf e^T\\mathbf r$. 可见, 解密过程也是和BV11b中的方案是相同的.\n其他符号介绍 这里使用的技术喝BV11b中基本是一样的, 只是由于模数切换的原因, 我们需要经常处理不同的模数, 因此几个函数中多了模数这一个参数. 此外, 结果的顺序也由有所不同.\n $\\mathsf{BitDecomp}(\\mathbf x\\in R_q^n,q)$: 即将$\\mathbf x$拆解成其二进制表示, $\\mathbf x=\\sum\\limits_{j=0}^{\\lfloor\\log q\\rfloor}2^j\\cdot \\mathbf u_j$, 其中$\\mathbf u_j\\in R_2^n$. 输出$(\\mathbf u_0,\\mathbf u_1,\\cdots,\\mathbf u_{\\lfloor\\log q\\rfloor})$.  显然有$\\mathbf x[i]=\\sum\\limits_{j=0}^{\\lfloor\\log q\\rfloor} 2^j\\cdot\\mathbf u_j[i]$. 类似的, 定义\n $\\mathsf{Powerof2}(\\mathbf x\\in R_q^n,q)$: 输出$(\\mathbf x,2\\cdot\\mathbf x,\\cdots,2^{\\lfloor\\log q\\rfloor}\\cdot \\mathbf x$).  根据以上的定义, 我们有 $$ \\langle\\mathsf{BitDecomp}(\\mathbf c,q),\\mathsf{Powerof2}(\\mathbf s,q)\\rangle=\\langle\\mathbf c,\\mathbf s\\rangle $$\n密钥切换 现在我们来介绍密钥切换的具体过程. 与其说是介绍, 不如说是熟悉我们的新记号. 回顾一下我们要将密钥$\\mathbf s_1$下的密文$\\mathbf c_1$切换的到密钥$\\mathbf s_2$下的密文$\\mathbf c_2$, 我们就要用$\\mathbf s_2$作为私钥来生成一个LWE公钥并\u0026quot;加密\u0026quot;$\\mathbf s_1$的每个项的每个Powerof2, 即需要每个$2^\\tau\\cdot \\mathbf s_{1}[i]$的\u0026quot;密文\u0026quot;. 我们将这些\u0026quot;密文\u0026quot;项的集合记作$\\tau_{\\mathbf s_1\\to\\mathbf s_2}$. 第二部就是将$\\tau_{\\mathbf s_1\\to\\mathbf s_2}$带入到$\\mathbf c_1$中来生成密文$\\mathbf c_2$. 我们将这两个过程形式化. 首先第一步是要生成$\\tau_{\\mathbf s_1\\to\\mathbf s_2}$, 即\n $\\mathsf{SwitchKeyGen}(\\mathbf s_1,\\mathbf s_2,n_1,n_2,q)$:  对于每个$N=n_1\\cdot \\lfloor\\log q\\rfloor$, 执行$\\mathbf A\\leftarrow \\mathsf{E.PublicKeyGen}(\\mathbf s_2,N)$. 令$\\mathbf B=\\mathbf A+[\\mathsf{Powerof2}(\\mathbf s_1)|\\mathbf 0]$. 输出$\\tau_{\\mathbf s_1\\to\\mathbf s_2}=B$.    其中第二步是一个批量操作, 此处是在将$\\mathsf{Powerof2}(\\mathbf s_1)$加到$\\mathbf A$的第一列上去.\n看到这里你也许会觉得蹊跷, 为什么没有二次项了? 实际上这里作者又换了一种写法, 将$\\mathbf s_1$就视作是含有二次项的项. 在之前的BV11b方案中, 假设两个密文$\\mathbf c,\\mathbf c^\\dagger$均为$\\mathbf s$的密文, 那么他们做第一步同态运算但不替换密钥时, 则新的多项式函数(由新密文$\\mathbf c'$表示的多项式函数)会包含$\\mathbf{s}[i]\\mathbf s[j]$项. 实际上, 我们大可不必这么认为, 我们可以认为有一个新的密钥向量$\\mathbf s_1$包含了所有的$\\mathbf{s}[i]\\mathbf s[j]$项, 我们只需要认为$\\mathbf s'=\\mathbf s\\otimes\\mathbf s$即可. 实际上作者比我们还要更激进一点, 此时作者认为还可以将$\\mathbf c'$进行$\\mathsf{Powerof2}$操作, 得到$\\mathbf c_1 = \\mathsf{Powerof2}(\\mathbf c')$, 该密文就应该是$\\mathbf s_1=\\mathsf{BitDecomp}(\\mathbf s')$下的密文. 同态运算第一步之后的结果即可认为是新密钥下的密文, 而我们的\u0026quot;加密\u0026quot;了所有的$2^\\tau\\cdot \\mathbf s_1[i]$项就是相当于时\u0026quot;加密\u0026quot;了所有的$2^\\tau\\cdot \\mathbf s_{i,j}$项了. 我们用$\\tau_{\\mathbf s_1\\to\\mathbf s_2}$即可进行下一步的私钥切换.\n $\\mathsf{SwitchKey}(\\tau_{\\mathbf s_1\\to\\mathbf s_2},\\mathbf c_1)$: 输出$\\mathbf c_2=\\mathsf{BitDecomp}(\\mathbf c_1)^T\\cdot \\mathbf B\\in R_q^{n_2}$.  模数切换 模数切换的方法我们也已经在前文中介绍完毕, 现在将其形式化\n $\\mathsf{Scale}(\\mathbf x,q,p,r)$: 输出距离$(p/q)\\cdot \\mathbf x$最近且满足$\\mathbf x'=\\mathbf x\\mod r$的向量$\\mathbf x'$.  很明显, 这里我们是要将$q$模数下的密文$\\mathbf x$切换到$p$模数下的密文$p$. 而一般来说, 我们只加密一个比特, 即选择$r=2$.\n我们之前已经估计了对于LWE下的密文, 这么做会导致噪声如何变化, 那么对于RLWE, 有类似的结果吗? 有的, 正如如下引理\n 引理3 设$d$是多项式环的次数. 令$q\u0026gt;p\u0026gt;r$为满足$p=q=1\\mod r$的正整数. 令$\\mathbf c\\in R^n$和$\\mathbf c'=\\mathsf{Scale}(\\mathbf c,q,p,r)$. 则对于任意$\\mathbf s\\in R^n$满足$|[\\langle\\mathbf c,\\mathbf s\\rangle]_q|\u0026lt;q/2-(q/p)\\cdot (r/2)\\cdot \\sqrt d\\cdot \\gamma (R)\\cdot \\ell_1^{(R)}(\\mathbf s)$, 则有 $$ [\\langle \\mathbf c',\\mathbf s\\rangle]_p=[\\langle\\mathbf c,\\mathbf s\\rangle]_q $$ 且 $$ |[\\langle\\mathbf c',\\mathbf s\\rangle]_p|\u0026lt;(p/q)\\cdot |[\\langle\\mathbf c,\\mathbf s\\rangle]_q|+(r/2)\\cdot \\sqrt d\\cdot \\gamma(R)\\cdot \\ell_q^{(R)}(\\mathbf s) $$\n 其中$\\gamma(R)$为仅与$R$相关的任何函数, 而$\\ell_q^{(R)}$表示环$R$上定义的第一范数. 这个地方在介绍了RLWE后我将会回来补充. 这个引理的证明方式和引理1类似, 就不在这里赘述, 希望知道具体过程的读者可以翻阅[BGV12]论文中Lemma 4的证明.\nLeveled FHE方案 铺垫到这里, 我们终于可以拿出LWE方案了. 实际上这里相比BV11b并没有多少新内容, 我们做的大部分工作是在带大家适应新的符号和解释模数切换的好处.\n首先和其他的Leveled FHE一样, 有个Setup阶段\n  $\\mathsf{FHE.Setup}(1^\\lambda,1^L,b)$: 设$\\mu=\\mu(\\lambda,L,b)=\\theta(\\log\\lambda+\\log L)$. 对于每个$j=L \\text{ to } 0$:\n 执行$params_j\\leftarrow\\mathsf{E.Setup}(1^\\lambda,1^{(j+1)\\cdot \\mu},b)$, 其中$params_j$中的模数逐渐从$q_L$降低到$q_0$.  对于每个$j=L-1\\text{ to } 0$\n 令$d_j=d_L$, $\\chi_j=\\chi_L$    这里的$q_L$大概有$(L+1)\\cdot \\mu$位, 其维数逐层降低到$q_0$的$\\mu$位. 此外, 每一层的$d,\\chi$参数需要与$L$层统一, 而维数$n$则没有这个要求. 这是由于在$q$变小时, 维数的减少不会影响方案的安全性, 毕竟当$q$下降时, 维数的减小不会然破解变得容易.\n $\\mathsf{FHE.KeyGen}(\\lbrace params_j\\rbrace )$: 对于每个$j=L\\text{ to }0$, 执行:  执行$\\mathbf s_j\\leftarrow \\mathsf{E.SecretKeyGen}(paramss_j)$和$\\mathbf A_j\\leftarrow\\mathsf{E.PublicKeyGen}(params_j,\\mathbf s_j)$ 令$\\mathbf s_j'\\leftarrow \\mathbf s_j\\otimes\\mathbf s_j$. 令$\\mathbf s_j''\\leftarrow \\mathsf{BitDecomp}(\\mathbf s_j',q_j)$. 令$\\tau_{\\mathbf s_{j}''\\to\\mathbf s_{j-1}}\\leftarrow \\mathsf{SwitchKeyGen}(\\mathbf s_j'',\\mathbf s_{j-1})$3. (当$j=L$时不执行该步骤)    实际上上述算法中, 我们就生成了每一层的公私钥, 并且做好了每一层的$\\tau_{\\mathbf s_{j}''\\to\\mathbf s_{j-1}}$, 则一部分在BV11b中被称为计算密钥. 注意我们先前已经说过了, 作者比较激进, 这里直接就将张量积后的密文做了$\\mathsf{BitDecomp}$再来生成密钥切换时的计算密钥, 那么对应的密文也要做$\\mathsf{Powerof2}$操作.\n $\\mathsf{FHE.Enc}(params,pk,m\\in\\lbrace 0,1\\rbrace )$: 计算并输出$\\mathsf{E.Enc}(\\mathbf A_L,m)$. $\\mathsf{FHE.Dec}(params,sk,\\mathbf c)$: 根据密钥的层数选择$\\mathbf s_j$, 计算并输出$\\mathsf{E.Dec}(\\mathbf s_j,\\mathbf c)$.  此处我们忽略了确定密文层数的参数来化简表示. 接下来我们演示同态计算. 同态计算中, 需要用到密钥切换过程, 该过程包括模数切换过程和维数切换过程, 我们将其统一为一个$\\mathsf{Refresh}$过程, 首先要根据计算密钥的格式, 将乘法(或加法)得到的结果进行$\\mathsf{Powerof2}$操作, 然后依次进行模数切换和密钥切换, 总的来说是把一个$\\mathbf s_j'=\\mathbf{s}j\\otimes\\mathbf s_j$下得密文变为$\\mathbf s{j-1}$下得密文. 我们将整个模数切换过程形式化.\n $\\mathsf{FHE.Refresh}(\\mathbf c,\\tau_{\\mathbf s_j''\\to\\mathbf s_{j-1},q_j,q_{j-1}})$:  计算$\\mathbf c_1\\leftarrow\\mathsf{Powerof2}(\\mathbf c,q_j)$ 计算$\\mathbf c_2\\leftarrow\\mathsf{Scale}(\\mathbf c_1,q_j,q_{j-1},2)$ 计算并输出$\\mathbf c_3\\leftarrow \\mathsf{SwitchKey}(\\tau_{\\mathbf s_j''\\to\\mathbf s_{j-1}},\\mathbf c_2,q_{j-1})$    最后我们补充完同态借助$\\mathsf{Refresh}$完成的同态运算过程:\n $\\mathsf{FHE.Add}(pk,\\mathbf c_1,\\mathbf c_2)$: 首先计算$\\mathbf c_3=\\mathbf c_1+\\mathbf c_2$, 再计算输出$\\mathbf c_4=\\mathsf{FHE.Refresh}(\\mathbf c_3,q_j,q_{j-1})$. $\\mathsf{FHE.Mult}(pk,\\mathbf c_1,\\mathbf c_2)$: 首先计算$\\mathbf c_3$, 即由$\\mathbf c_1,\\mathbf c_2$所表示的多项式函数相乘得到的多项式函数对应的密文, 再计算并输出$\\mathbf c_4=\\mathsf{FHE.Refresh}(\\mathbf c_3,q_j,q_{j-1})$.  这里要注意的是, 加法的密文后完全可以看做是$\\mathbf s_j'=\\mathbf s_j\\otimes\\mathbf s_j$下的密文, 只需要令二次项表示的位为$0$就可以了.\n其他 在作者阅读完代数数论和RLWE的知识后, 将会带各位阅读Batching部分的操作, 该部分内容可以极大地提升本方案的效率, 也被CKKS方案借鉴. Bootstrapping和安全性证明也将在之后完成.\n注释   Zvika Brakerski, Graig Gentry and Vindo Vaikuntanathan. Fully homomorphic encryption without bootstrapping. In Innovations in Theoretical Computer Science (ITCS'12), 2012.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 实际上LWE和RLWE的模数都不需要是素数, 而且后文中也没有提到是素数. 此处存疑.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 此处eprint上版本的原文中有笔误.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2019-08-18T15:40:01Z","image":"https://lingerois.com/p/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%863-bgv%E6%96%B9%E6%A1%88/fog_hu165ac214da6e531d826e0fd7ad766063_27843_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%863-bgv%E6%96%B9%E6%A1%88/","title":"同态加密(3) BGV方案"},{"content":"\r原文作者之一Zvika Brakerski在2018 CIS冬令营上为学员讲解全同态加密\r\r原文作者之一Vinod Vaikuntanathan在2018 CIS冬令营上为学员讲解全同态加密\r\nCIS 2018回顾\n符号说明 本文中, 我们采用方括号+下标的方式来表示向量中的具体某一位. 例如向量$\\mathbf s$的第$i$位用$\\mathbf s[i]$来表示. 我们有时候会用下标0来表示不存在的下标, 例如$h_i$可以用$h_{i,0}$来表示, 这样做的好处是, 我们不用显式地提及$h_i$, 而是用$h_{i,j}$就可以表示所有的$h_{i,j\\neq 0}$和$h_i$来避免描述地冗长.\n原文中的安全参数采用的是$\\kappa$, 由于这个字母容易和$k$混淆, 且为了与我其他博文统一, 我修改为了$\\lambda$.\n简介 假设我们采用的LWE的噪声为偶数, 即具有$2\\mathbf e$的形式, 则最终我们得到的加密密文具有$(\\mathbf a,b=\\langle\\mathbf a,\\mathbf s\\rangle+2e+m)\\in\\mathbb Z_q^n\\times \\mathbb Z_q$的形式, 其中$m\\in\\lbrace0,1\\rbrace$是我们加密的密文. 在有了这种形式的密文后, 通过$b-\\langle\\mathbf a,\\mathbf s\\rangle=2e+m$, 再模上2方可解除$m$.\n如果我们将解密的过程看作是一个函数, 即对于$\\bf a$来说, $f_{\\mathbf a,b}(\\mathbf x)=b-\\langle\\mathbf a,\\mathbf x\\rangle \\mod q$, 那么当我们输入正确的密钥$\\mathbf s$时, 最终计算出的结果再模上2就是解密的结果. 如果$\\mathbf a$具有$n$维, 我们有 $$ f_{\\mathbf a,b}(\\mathbf x)=b-\\sum_{i=1}^n \\mathbf a[i]\\cdot \\mathbf s[i] $$ 先假设另一个明文$m'\\in\\lbrace 0,1\\rbrace$采用$(\\mathbf a',b'=\\langle\\mathbf a',s\\rangle+2e'+m')$进行加密, 那么很显然的, $f_{\\mathbf a',b'}(\\mathbf x)$可以用来描述其解密过程. 我们发现, 如果将两个函数加或乘在一起, 传入正确的密文后, 我们将会得到原先密文的加或乘的加密. 当然, 这里的加是指比特异或或者$GF(2)$上的加法. 观察 $$ \\begin{aligned} f_{\\mathbf a,b}(\\mathbf x)\\cdot f_{\\mathbf a',b'}(\\mathbf x) \u0026amp;= (b-\\sum \\mathbf a[i]\\cdot\\mathbf x[i])\\cdot (b'-\\sum \\mathbf a'[i]\\cdot \\mathbf x[i])\\newline \u0026amp;= h_0+\\sum h_i\\cdot \\mathbf x[i]+\\sum h_{i,j}\\cdot \\mathbf x[i]\\mathbf x[j] \\end{aligned} $$ 这里传入参数$\\mathbf s$后, 就有 $$ \\begin{aligned} f_{\\mathbf a,b}(\\mathbf s)\\cdot f_{\\mathbf a',b'}(\\mathbf s) \u0026amp;= (2e+m)\\cdot (2e'+m \u0026lsquo;)\\newline \u0026amp;= 4ee\u0026rsquo;+2e\u0026rsquo;m+2em'+mm' \\newline \u0026amp;= 2(2ee'+e\u0026rsquo;m+em')+mm' \\end{aligned} $$ 最终模上2后确实可以得到$mm'$. 类似的加法我们也可以具体验证.\n但是这里的乘法也就带来了一个问题, 描述我们多项式的系数个数, 由原先的$O(n)$个变成了$O(n^2)$个\u0026mdash;-多了那些二次项的系数. 如果我们反复的进行乘法, 那么进行$L$次乘法, 描述多项式的系数个数就会变成$O(n^{2^L})$, 这显然不是我们想要的.\n解决这一问题的办法是, 让我们同态加密的加密方, 用一个新的密钥$\\mathbf t$将原先密钥$\\mathbf s$的所有一次项$\\mathbf s[i]$二次项$\\mathbf s[i]\\mathbf s[j]$都加密起来, 即生成密文$(\\mathbf a_{i,j},b_{i,j})$满足 $$ b_{i,j}=\\langle\\mathbf a_{i,j},\\mathbf t\\rangle+2e_{i,j}+\\mathbf s[i]\\mathbf s[j]\\approx \\langle a_{i,j},\\mathbf t\\rangle+\\mathbf s[i]\\mathbf s[j] $$ 如果我们将以上密文改写成解密多项式并带入到$f_{\\mathbf a,b}(\\mathbf x)\\cdot f_{\\mathbf a',b'}(\\mathbf x)$中, 我们将会得到一个全新的多项式函数 $$ g(\\mathbf x)=h_0+\\sum h_i(b_i-\\langle\\mathbf a_i,\\mathbf x))+\\sum h_{i,j}(b_{i,j}-\\langle\\mathbf a_{i,j},\\mathbf x\\rangle) $$ 这个多项式满足 $$ \\begin{aligned} g(\\mathbf t)\u0026amp;=h_0+\\sum h_i(b_i-\\langle\\mathbf a_i,\\mathbf t))+\\sum h_{i,j}(b_{i,j}-\\langle\\mathbf a_{i,j},\\mathbf t\\rangle) \\newline \u0026amp;= h_0+\\sum h_i\\cdot \\mathbf s[i]+\\sum h_{i,j}\\cdot \\mathbf s[i]\\mathbf s[j] \\end{aligned} $$ 其最终模2的结果也就是$mm'$.\n如果我们还想多进行一层的乘法运算怎么办? 由于$g$和$f_{\\mathbf a,b}$具有类似的形式, 因此我们也可以将$\\mathbf t$的一次项和二次项用另一个新的密钥$\\mathbf t'$进行加密, 再交由同态运算方处理即可\u0026mdash;-类似的过程再噪声没有过大的情况下可以一直持续下去.\n当然, 这里我们保持了噪声是偶数的性质了吗? 这一点毋庸置疑, 因为说明所有的噪声都是偶数, 无论如何也不可能凑出奇数的噪声来.\n潜在的问题 上面的方案由一个潜在的问题. $h_{i,j}$不是标准的LWE生成的项, 我们也没有理由假设它是一个较小的值, 而实际上它们确实可以很大. 当这些项很大的时候, 极有可能导致$h_{i,j}\\cdot (b_{i,j}-\\langle\\mathbf a_{i,j},\\mathbf t\\rangle)\\not\\approx h_{i,j}\\cdot \\mathbf s[i]\\mathbf s[j]$.为了避免这一情况的发生, 我们需要让$h_{i,j}$都不要太大. 我们采用的办法就是我们用过的\u0026quot;BitDecomp\u0026quot;大法, 即用二进制来表示$h_{i,j}$, 将其表示为$h_{i,j}=\\sum\\limits_{i=0}^{\\lfloor\\log q\\rfloor}2^\\tau\\cdot h_{i,j,\\tau}$. 到这里看起来也许就不那么美好了, 因此每项参数的意思需要你牢记, 这样你才能继续读下去.\n接下来更令人费解的是, 我们要构造一个是密文的形式, 但是又不是对任何东西的加密的一种\u0026quot;密文\u0026quot;, 令 $$ b_{i,j,\\tau}=\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle+2e_{i,j,\\tau}+2^\\tau \\mathbf s[i]\\mathbf s[j]\\approx\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle+2^\\tau \\mathbf s[i]\\mathbf s[j] $$ 这里像是将$\\mathbf a_{i,j},b_{i,j}$按照$h_{i,j}$的方式拆开, 但是实际上是我们为每一个$2^\\tau\\mathbf s[i]\\mathbf s[j]$单独准备的\u0026quot;密文\u0026quot;, 但是他们并不是对$2^\\tau\\mathbf s[i]\\mathbf s[j]$的加密, 因为我们的加密方案只会加密1 bit, 在$\\tau \\geq 1$的时候, 整个$2^\\tau\\mathbf s[i]\\mathbf s[j]$会在模2的时候被一同模掉. 不过好在是$b_{i,j,\\tau}-\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle\\approx 2^\\tau\\cdot \\mathbf s[i]\\mathbf s[j]$还是成立的.\n但是这样做也有一个好处, 就是我们可以利用对$h_{i,j}$的拆分, 用以上的这组\u0026quot;密文\u0026quot;来表示$h_{i,j}$, 我们有 $$ h_{i,j}\\cdot \\mathbf s[i]\\mathbf s[j]=\\sum_{\\tau=0}^{\\lfloor\\log q\\rfloor}h_{i,j,\\tau} 2^\\tau \\mathbf s[i]\\mathbf s[j] \\approx \\sum_{\\tau=0}^{\\lfloor\\log q\\rfloor}h_{i,j,\\tau}(b_{i,j,\\tau}-\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle) $$ 这个时候$h_{i,j,\\tau}$较小, $h_{i,j,\\tau}\\cdot (b_{i,j,\\tau}-\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle)\\not\\approx h_{i,j,\\tau}\\cdot \\mathbf s[i]\\mathbf s[j]$的情况就不会出现了, 因此整个等式的$\\approx$也就能得到保持.\nBootstrapping准备工作 回想一下每进行一次乘法的噪声增长. $$ \\begin{aligned}f_{\\mathbf a,b}(\\mathbf s)\\cdot f_{\\mathbf a',b'}(\\mathbf s) \u0026amp;= (2e+m)\\cdot (2e'+m')\\newline \u0026amp;= 4ee'+2e\u0026rsquo;m+2em'+mm' \\newline\u0026amp;= 2(2ee'+e\u0026rsquo;m+em')+mm'\\end{aligned} $$ 从$ee'$项可以看出, 每进行一次乘法运算, 噪声都从$E$变成了$E^2$, 同GSW方案一样, 我们的噪声是按双对数的方式进行增长的. 即在进行$L$层乘法之后, 噪声至少变成了$E^{2^L}$. 我们的模数1$q$的选择只能是$n$的不能达到双指数而只能达到$2^{n^\\epsilon}$(其中$\\epsilon$为常数), 要使得噪声不超过$O(q)=O(2^{n^\\epsilon})$, 我们的$L$只能选择在$\\text{polylog } n$. 但是, LWE解密电路的深度是$\\max(n,\\log q)$, 也就是说, 我们的的方案不能支持我们的解密电路! 也就无法实现Bootstrapping来达到FHE!\n此时我们的办法是, 用大的模数和维数来进行Bootstrapping, 而用小的模数和维数来进行同态运算. 这样, 我们同态运算过程中解密电路的深度就不会太深, 能够被模数和维数大的Bootstrapping过程所支持. 现在我们来介绍如何从参数$(n,\\log q)$转换到$(k,\\log p)$2. 其中, $n=k^c, p=\\text{poly}(k)$, 由于$q=2^{n^\\epsilon}$, 我们就可以用大参数做约$D=n^\\epsilon=k^{c\\cdot \\epsilon}$层同态运算, 成功地将小参数下地解密电路包括进来.\n我们首先可以发现, 在我们进行一次乘法, 将密钥从$\\mathbf s$切换到$\\mathbf t$时, 我们并不以一定需要$\\mathbf t$与$\\mathbf s$的维数相同, 通过选择维数更小的$\\mathbf t$我们就可以降低维数. 降低模数时, 采用的思想是近似逼近. 假设在模$p$时我们用如下的方式来生成\u0026quot;密文\u0026quot; $$ \\hat b_{i,j,\\tau}=\\langle\\hat {\\mathbf a}_{i,j,\\tau},\\mathbf t\\rangle+e+\\left\\lfloor\\frac pq\\cdot 2^\\tau\\cdot \\mathbf s[i]\\right\\rceil $$ 其中$(\\hat {\\mathbf a}_{i,j,\\tau},\\hat b_{i,j,\\tau})\\in \\mathbb Z^k_p\\times \\mathbb Z_p$是按照LWE加密生成的, 则 $$ 2^\\tau\\cdot \\mathbf s[i]\\mathbf s[j]\\approx \\frac qp\\cdot (b_{i,j,\\tau}-\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle) $$ 即可大致还原出$2^\\tau\\cdot \\mathbf s[i]\\mathbf s[j]$. 我们用$\\frac qp\\cdot (\\hat b_{i,j,\\tau}-\\langle\\hat {\\mathbf a}_{i,j,\\tau},\\mathbf t\\rangle)$来代替之前的$b_{i,j,\\tau}-\\langle\\mathbf a_{i,j,\\tau},\\mathbf t\\rangle$用于构造新的一次多项式函数, 使得新的多项式模数变得更小了. 值得一提的是, 这里需要引入**稀疏子集和假设**. 也许你看到这里又迷糊了, 这里又还原不出$2^\\tau\\cdot \\mathbf s[i]\\mathbf s[j]$, 那又有意义呢? 单独来看是没有什么意义, 但它的噪声是偶数的, 所有的这样的东西拼凑在一起最终可以帮助我们解密出同态运算的结果.\n到此为止, 我们就可以将切换到$\\mathbf t$进行计算时的模数和维数都变小了.\nBV11b中的SWHE同态加密方案 这一部分将分为两个小部分介绍, 第一步就是不做模数切换和维数切换的基础同态方案$\\mathsf{SH}$. 第二部分就是采用模数切换和维数切换的技术, 将$\\mathsf{SH}$转换成一个可以加入Bootstrapping的方案$\\mathsf{BTS}$, 在$\\mathsf{BTS}$的基础上加上Bootstrapping技术就可以得到一个FHE方案.\n即使是本节内容大多已经在前面介绍过了, 这里只是将其形式化, 并对整个方案的流程做一定的解读.\n密钥生成、加密、解密 第一步和GSW一样, 都要有一个Setup, 之所以需要这个过程是因为我们要选择需要做同态的层数. 注意, 这一步在原文中是没有显式地写出来地, 但是它确实也这一做了.\n $\\mathsf{SH.Setup}(1^L, 1^\\lambda)$: 用$\\lambda$表示安全参数, $L$表示同态运算的层数, 选择参数$m,n,q$满足$n=\\text{poly}(\\lambda)$, $m\\geq n\\log q+2\\lambda$, $L\\approx \\epsilon\\log n$和$q$为奇数且$q\\in [2^{n^\\epsilon},2\\cdot 2^{n^\\epsilon})$, 其中$\\epsilon\\in(0,1)$为常数. 选择$\\mathbb Z_q$上的噪声分布$\\chi$.  这些参数的选择大多是为了保证基于的LWE加密的安全性. 如果不关注实现的细节和安全性规约, 可以忽略大部分的参数选择. 需要记住的选择规则是: $q$可以是$n$的超指数的, 但不能达到$n$的双指数, 且$m$大约是$n\\log q$.\n接下来的$\\mathsf{KeyGen}$看起来会有一些复杂, 因为我们把每一层的密钥的一次和二次项用下一层密钥加密后的结果写在了一起, 作为计算密钥(Evaluation Key), 但是他们的本质实际上读者已经见过了\n  $\\mathsf{SH.KeyGen}(1^\\lambda)$: 选择$L+1$个向量$\\mathbf s_0,\\cdots,\\mathbf s_L\\overset{$}\\leftarrow \\mathbb Z_q^{n}$, 对于所有的$\\ell\\in[L],0\\leq i\\leq j\\leq n$和$\\tau\\in\\lbrace 0,\\cdots,\\lfloor\\log q\\rfloor\\rbrace$计算\n$$ \\psi_{\\ell,i,j,\\tau}:=\\left(\\mathbf a_{\\ell,i,j,\\tau},b_{\\ell,i,j,\\tau}:=\\langle\\mathbf a_{\\ell,i,j,\\tau},\\mathbf s\\rangle+2\\cdot e_{\\ell,i,j,\\tau}+2^\\tau\\cdot \\mathbf s_{\\ell-1}\\cdot \\mathbf s_{\\ell-1}[j]\\right)\\in \\mathbb Z_q^n\\times \\mathbb Z_q $$\n同时选择$\\mathbf A\\leftarrow \\mathbb Z_q^{m\\times n}$和$\\mathbf e\\leftarrow\\chi^m$, 计算$\\mathbf b:=\\mathbf A\\mathbf s_0+2\\mathbf e$.\n输出公钥$sk=s_L$, 计算密钥$evk=\\Psi=\\lbrace \\psi_{\\ell,i,j,\\tau}\\rbrace_{\\ell\\in[L],0\\leq i\\leq j\\leq n,\\tau\\in\\lbrace 0,\\cdots,\\lfloor\\log q\\rfloor\\rbrace}$和私钥$pk=(\\mathbf A,\\mathbf b)$.\n  计算密钥这一长串的东西, 读者在前面已经见过很多次了, 应该比较熟悉了. 唯一多了的参数是$\\ell$是代表当前同态的层.\n $\\mathsf{SH.Enc(pk,m)}$: 选择$\\mathbf r\\leftarrow \\lbrace 0,1\\rbrace^m$, 计算$\\mathbf v:=\\mathbf A^T\\mathbf r$和$w:=\\mathbf b^T\\mathbf r+m$, 输出密文$c:=((\\mathbf v,w),0)$.  注意这里最后的$0$代表当前同态(乘法)运算的层数. 同时由于噪声始终是偶数累计的, 因此模2仍然可以消除噪声.\n在做完同态运算后, 我们得到的是第$L$层的密文, 即密文的格式是$c=((\\mathbf v,w),L)$.\n $\\mathsf{SH.Dec(sk, c)}$: 输出$((w-\\langle\\mathbf v,\\mathbf s_L\\rangle)\\mod q)\\mod 2$  这里注意$\\mathbf v$连同$w$就构成了最终解密多项式函数的描述, $(w-\\langle\\mathbf v,\\mathbf s_L\\rangle)\\mod q$就相当于是求解密多项式在$\\mathbf s_L$点的值.\n同态运算 加法的同态比较简单, 将多个同一层的密文相加即可.\n 加法门: 对于n个密文$\\lbrace c_i=((\\mathbf v_i,w_i),\\ell)\\rbrace_{i\\in [n]}$做加法同态, 计算和输出 $$ c_{+}=((\\mathbf v_+,w_+),\\ell)=\\left(\\left(\\sum_i\\mathbf v_i,\\sum_i w_i\\right),\\ell\\right). $$  解密的正确性留给读者. 可以看出, 加法同态不消耗同态层数, 因此我们的同态层数$L$是指乘法层数.\n对于乘法来说, 我们需要用到前面介绍的技术.\n 乘法门: 对于两个同层的乘法密文$c=((\\mathbf v,w),\\ell)$和$c'=((\\mathbf v',w'),\\ell)$, 计算 $$ \\phi(\\mathbf x)=(w-\\langle \\mathbf v,\\mathbf x\\rangle)(w'-\\langle\\mathbf v',\\mathbf x\\rangle)=\\sum_{0\\leq i\\leq j\\leq n} h_{i,j}\\cdot\\mathbf x[i]\\mathbf x[j] $$ 令$h_{i,j}=\\sum\\limits_{\\tau=0}^{\\lfloor\\log q\\rfloor}h_{i,j,\\tau}\\cdot 2^\\tau$, 并带入$evk=\\Psi$, 得到 $$ \\mathbf v_\\times=\\sum_{\\begin{aligned}0\\leq i\\leq \u0026amp;j\\leq n\\\\tau\\in\\lbrace 0,\\cdots\u0026amp;,\\lfloor\\log q\\rfloor\\rbrace\\end{aligned}} h_{i,j,\\tau}\\cdot \\mathbf a_{\\ell+1,i,j,\\tau} $$ 和 $$ w_{\\times}=\\sum_{\\begin{aligned}0\\leq i\\leq \u0026amp;j\\leq n\\\\tau\\in\\lbrace 0,\\cdots\u0026amp;,\\lfloor\\log q\\rfloor\\rbrace\\end{aligned}} h_{i,j,\\tau}\\cdot b_{\\ell+1,i,j,\\tau} $$ 最终输出$((\\mathbf v_\\times,w_\\times),\\ell+1)$.  注意$\\sum$记号处发扬了我们在符号说明处的关于下标的说明, 实际上其内容包括常数项$h_0=ww'$, 一次项(系数为$h_{i\\neq 0,j=0}$)和二次项(系数为$h_{i\\neq0,j\\neq 0}$). 同样这里的同态计算验证留作.\n将加法门和乘法门的Eval方式结合起来, 我们就可以得到\n $\\mathsf{SH.Eval}(evk,f,c_1,\\cdots, c_t)$: 采用加法门和乘法门Eval的方式输出最终运算结果.  要使得结果正确, $f$点电路必须是我们支持的电路, 必须是一个加法乘法交替的电路, 第$\\ell$层的乘法密文的输出只能通向$\\ell+1$层的乘法. 如果不考虑深度限制, 实际上所有的布尔电路都可以转化为这一的电路, 但是考虑到深度限制, 我们还有工作要做. 到这里, SWHE方案就算介绍完了, 采用该方案可以做到$n$的对数多项式(polylog)层的同态运算.\nBV11b中的FHE方案 我们用$\\mathsf{BTS}$来表示我们的可以加入Bootstrapping的方案, 该方案需要用到$\\mathsf{SH}$方案的内容, 阅读这一部分, 请确保对前面知识的熟悉. 为了使我们的方案支持Bootstrapping, 我们必须降低解密电路的深度, 我们使用的方法是用维数切换和模数切换, 将密文的模数和维数变得更小.\n $\\mathsf{BTS.Setup}(1^L, 1^\\lambda)$: 用$\\lambda$表示安全参数, $L$表示同态运算的层数, 选择参数$m,n,q$满足$n=\\text{poly}(\\lambda)$, $m\\geq n\\log q+2\\lambda$, $L\\approx \\epsilon\\log n$和$q$为奇数且$q\\in [2^{n^\\epsilon},2\\cdot 2^{n^\\epsilon})$, 其中$\\epsilon\\in(0,1)$为常数. 选择$\\mathbb Z_q$上的噪声分布$\\chi$. 选择$\\mathbb Z_p$上的噪声分布$\\hat\\chi$.  $\\mathsf{Setup}$是和$\\mathsf{SH}$方案是一样的, 实际上我们$\\mathsf{SH}$中参数的设定就是为了方便$\\mathsf{BTS}$中的方案描述. 来自[BV11b]作者的建议: 在阅读时可以带入参数$k=\\lambda,n=k^4,q\\approx \\sqrt n, L=1/3\\log n=4/3\\log k,p=(n^2\\log n)\\cdot\\text{poly}(k),m=O(n\\log q)$以及$n$-bounded的$\\chi$和$k$-bounded的$\\hat\\chi$进行理解.\n  $\\mathsf{BTS.KeyGen(1^\\lambda)}$: 调用$\\mathsf{SH.KeyGen}(1^\\lambda)$得到$\\mathbf s_L,\\Psi,(\\mathbf A,\\mathbf b)$. 生成短的私钥$\\hat{\\mathbf s}\\overset{$}\\leftarrow \\mathbb Z_p^k$并计算对应于这个短私钥的计算密钥, 即对于所有的$i\\in[n],\\tau\\in \\lbrace 0,\\cdots,\\lfloor\\log q\\rfloor\\rbrace$, 生成$\\hat{\\mathbf a}_{i,\\tau}\\overset{$}\\leftarrow \\mathbb Z_p^k,\\hat e\\overset{$}\\leftarrow \\hat \\chi$ 并计算\n$$ \\hat b_{i,\\tau}:=\\langle\\hat{\\mathbf a}_{i,\\tau},\\hat{\\mathbf s}\\rangle+\\hat e_{i,\\tau}+\\left\\lfloor\\frac pq\\cdot(2^\\tau\\cdot\\mathbf s_L[i])\\right\\rceil \\mod p $$\n记$\\hat\\psi_{i,\\tau}:=(\\hat{\\mathbf a}_{i,\\tau},\\hat b_{i,\\tau})\\in \\mathbb Z_p^k\\times \\mathbb Z_p$和$\\hat\\Psi=\\lbrace \\hat\\psi_{i,\\tau}\\rbrace_{i\\in[n],\\tau\\in\\lbrace 0,\\cdots,\\lfloor\\log q\\rfloor\\rbrace}$.\n最终输出公钥$pk=(\\mathbf A,\\mathbf b)$, 私钥$sk = \\hat {\\mathbf s}$, 计算密钥$evk=\\lbrace \\Psi, \\hat \\Psi\\rbrace$.\n  实际上可以看出, 我们仍然需要借用原先方案的密钥. 原因是我们在做同态运算的时候, 接收到的输入是大密文, 而最后输出必须是小密文. 我们要求大密文和小密文的解密结果是一样的, 但是小密文的解密电路却更浅. 因此, 我们首先需要调用原先的$\\mathsf{SH.Eval}$, 得到计算结果后, 再将密文变成小密文. 因此我们的加密算法, 应当和$\\mathsf{SH.Enc}$相同:\n $\\mathsf{BTS.Enc}(pk,m)$: 输出$\\mathsf{SH.Enc}(pk,m)$.  具体的计算过程:\n  $\\mathsf{BTS.Eval}(evk, f, c_1,\\cdots, c_t)$: 计算$c_f\\leftarrow \\mathsf{SH.Eval}(\\Psi, f, c_1,\\cdots, c_t)$. 记$c_f=((\\mathbf v,w), L)\\in\\mathbb Z^{n}_q\\times \\mathbb Z_q\\times \\lbrace L\\rbrace$. 考虑多项式函数\n$$ \\phi(\\mathbf x):=\\frac pq\\cdot \\left(\\frac{q+1}p\\cdot (w-\\langle\\mathbf v,\\mathbf x\\rangle)\\right) \\mod p $$\n按照之前的方式将其系数整理为$h_0,\\cdots, h_n\\in\\mathbb Z_q$的形式, 即\n$$ \\phi(\\mathbf x)=\\sum^n_{i=0}h_i\\cdot(\\frac pq \\cdot \\mathbf x[i]) $$\n再将$h_i$按照二进制展开, 得到\n$$ \\phi(\\mathbf x)=\\sum^n_{i=0}\\sum_{\\tau=0}^{\\lfloor\\log q\\rfloor}h_{i,\\tau}\\cdot (\\frac pq\\cdot 2^\\tau\\cdot\\mathbf x[i]) $$\n采用$\\hat\\Psi$中的密钥来替换上式中的$\\frac pq\\cdot(2^\\tau\\cdot\\mathbf s_L[i])$可以得到一个新的一次多项式函数, 记常数项为$\\hat w$, 一次项系数向量为$\\hat{\\mathbf v}$则\n$$ \\begin{aligned} \\hat{\\mathbf v}:=2\\cdot \\sum^n_{i=0}\\sum^{\\lfloor\\log q\\rfloor}_{\\tau=0}h_{i,\\tau}\\cdot\\hat{\\mathbf a}_{i,\\tau} \\mod p\\in \\mathbb Z_p^k\\\n\\hat w:=2\\cdot \\sum^n_{i=0}\\sum^{\\lfloor\\log q\\rfloor}_{\\tau=0}h_{i,\\tau}\\cdot\\hat b_{i,\\tau}\\mod q\\in\\mathbb Z_q \\end{aligned} $$\n最后输出密文$\\hat c=(\\hat{\\mathbf v},\\hat w)$.\n  最后密文确实是小密文的格式, 因此我们的解密需要按照小密文的格式进行解密:\n $\\mathsf{BTS.Dec}(sk=\\hat{\\mathbf s},\\hat c)$: 计算并输出 $$ m^\\ast:=((\\hat w-\\langle\\hat{\\mathbf v},\\hat{\\mathbf s}\\rangle) \\mod q)\\mod 2 $$  这里仍然有一个问题, 就是要验证经过大密钥转换后的小密钥用$\\mathsf{BTS.Dec}$解密的结果与大密钥用$\\mathsf{SH.Dec}$解密出的结果相同, 其基本思想已经在本文中有所体现, 具体的验证过程也可以参考[BV11b]论文.\n注释   我一般将modulus翻译成模数, 以同代数结构中的模(module)区分开来. 注意modulus的复数是moduli.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 此处参数的格式是(维数, 模数)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2019-08-14T13:06:22Z","image":"https://lingerois.com/p/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%862-bv11b%E6%96%B9%E6%A1%88/fog_hu165ac214da6e531d826e0fd7ad766063_27843_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%862-bv11b%E6%96%B9%E6%A1%88/","title":"同态加密(2) BV11b方案"},{"content":"Some Information about the Course\nIn this course, we mainly talk about the foundation of Cryptography. We talk about the big picture of cryptography, not the cryptosystem based on a specific assumption. Basic knowledge of probability theory, computational complexity is necessary for this course.\nThis serie of notes mainly follows Goldreich\u0026rsquo;s legendary book Foundations of Cryptograph. With some basic knowledge of computational complexity, one would enjoy the book a lot. (Though still difficult to learn.)\nFurthermore, since Goldreich\u0026rsquo;s book has been finished for several years, newly research results are not included in it. Results being found in resent years might be added in the notes by me.\nThanks to Mr. Yu and Mrs. Liu at SJTU for giving us wonderful cryptographic courses.\nSome Information about the Symbols\nWe are not going to write too many conditions in a probabilistic formula. We sometimes write conditions by distributions under the simbol $\\Pr$.\nAs for make of a probabilistic distribution like $U_n$, it has two means. Firstly, it denotes a distribution as it is. E.g. Random variable $X$ sampled by $U_n$ is denoted by $X\\leftarrow U_n$, then we for each string $x\\in U_n$ we have $$ \\Pr[x\\in U_n]=\\frac 1 {2^n} $$ In other situations, these kind of mark can represent an anonymous random variable sampled from the distribution it denotes. We must make it clear that in the same math block, same mark of distribution $D$ always represents the same anonymous random variable sampled from $D$. For different anonymous random variable sampled from the same distribution $D$, we can use superscript to distinguish them. E.g. $D^{(1)}, D^{(2)},\\cdots,D^{(m)}$.\nOne-Way Function Strong One-way Function The existence of cryptography is based on $\\mathbf P\\neq \\mathbf{NP}$. But $\\mathbf P\\neq \\mathbf{NP}$ is not enough, cryptography asks for stronger precondition, that is the existence of (Strong) One-way Function.\n Strong One-way Function (OWF)\nA function $f:\\lbrace 0,1\\rbrace ^\\ast\\to \\lbrace 0,1\\rbrace ^\\ast$ is a strong one-way function if it is\n Easy to compute: There is a deterministic polynomial-time algorithm $\\mathsf{EvalF}$ such that for all $n$ and all $x\\in\\lbrace 0,1\\rbrace ^n$ we have $\\mathsf{EvalF(x)} = f(x)$. Hard to invert: There is no probabilitistic polynomial-time algorithm could invert the function with probability better than $\\mathsf{negl(n)}$.   The second property can be restate more formally as\n There is no PPT algorithm $\\mathcal {A}$ satisfy $$ \\Pr[\\mathcal A(1^n,f(U_n))\\in f^{-1}(f(U_n))]\u0026gt;\\frac{1}{n^c} $$ for any $c\u0026gt;0$.\n When you see a distribution been used as a random variable in a probabilitistic formula, it means you first sample once from that distribution and use the result as a random variable. It\u0026rsquo;s easy to understant this since we do this just because we don\u0026rsquo;t want to give the random variable a explicit name.\n! Another thing to pay attention to is that $f$ is defined for all $n$. Or wey say, $f$ is uniform.\nAs it is shown in the definition, a strong one-way function cannot be revert efficiently in average-case. That is, the function might somehow be inverted by a algorithm once, but hard on average.\n Theorem\nIf strong one-way function exists, then $\\mathbf{P}\\neq \\mathbf{NP}$.\n Proof: Suppose $\\mathbf{P}=\\mathbf{NP}$ and there exists an one-way function $f:\\lbrace 0,1\\rbrace ^\\ast\\to \\lbrace 0,1\\rbrace ^\\ast$. Then decide $$ L=\\lbrace\\langle x^\\ast,y\\rangle| \\exists x:x^\\ast\\sqsubset x \\text{and} f(x)=y\\rbrace $$ $L$ is the collection of tuples like $\\langle x^\\ast, y\\rangle$ that $x^\\ast$ is the prefix of some $x$ that $f(x)=y$. Clearly $x$ itself is a certificate, so $L\\in \\mathbf{NP}$. But we have $\\mathbf{P}=\\mathbf{NP}$, so for every $y$, we can recover $x$ one bit by one bit. This can be done by call the oracle of $\\mathcal O_L$. To invert $y$, we firstly ask $\\langle 0, y\\rangle$. If it returns $0$ then we ask $\\langle 10, y\\rangle$, otherwise we ask $\\langle 00, y\\rangle$.\n One-way function seems to be a very strong assumption, we improve the situation a little by introduce the weak version of one-way function.\nWeak One-Way Function  Weak One-Way Function\nA function $f:\\lbrace 0,1\\rbrace ^\\ast\\to \\lbrace 0,1\\rbrace ^\\ast$ is a one-way function if it is\n  Easy to compute: There is a deterministic polynomial-time algorithm $\\mathsf{EvalF}$ such that for all $n$ and all $x\\in\\lbrace 0,1\\rbrace ^n$ we have $\\mathsf{EvalF(x)} = f(x)$.\n  Slightly Hard to invert: There exists a polynomial $p(\\cdot)$ such that for every PPT algorithm $\\mathcal A$ and all sufficiently large n\u0026rsquo;s, $$ \\Pr[\\mathcal A(f(U_n,1^n)\\notin f^{-1}(f(U_n))]\u0026lt;1-\\frac 1{p(n)} $$\n   See, it\u0026rsquo;s not \u0026ldquo;very hard\u0026rdquo; to invert weak one-way function. But pay attention that every algorithm shares the same $p(\\cdot)$ in the definition. It means that every algorithms could only invert the function correctly with a upper bound probability. We can regard it as a \u0026ldquo;gap\u0026rdquo;.\nIt seems that weak one-way function is useless, since their might be an adversary almost always inverts it. However, later we\u0026rsquo;ll see a amazing result about it.\nIn another view, weak one-way function seems not too weak. The failure probability of weak one-way function has essential difference from such of a PPT algorithm $\\mathcal A$ solves some $L\\in\\mathbf{BPP}$. In the later, since every $x\\in L$ can be decide by $\\mathcal A$ with large probability, we can decrease the failure probability to negligible by repeating $\\mathcal A$ with different coin tosses. But for the former, even repeating for polynomial times can\u0026rsquo;t help with decreasing the gap. It says these there are cases that be solved by any PPT algorithm.\nOne-Way Function Defined for Some Lengths. We could define one-way function for some lengths. Let $I\\in \\mathbb N$, then $I$ contains some natural numbers. We define the successor of $n$ in $I$ the minimal number in $I$ that is larger than $I$, denoted by $s_I(n)$.\nE.g. Let $I= \\lbrace 2,3,7,9,10,12,14,\\cdots\\rbrace $, then $s_I(8)=9$.\n$I$ is called polynomial-time-enumerable if there exists a $poly$-time turing machine that on input $n$ output $1^{S_I(n)}$.\nTo modify the definition of strong/weak one way function, change \u0026ldquo;every $n$\u0026rdquo; to \u0026ldquo;every $n\\in I$\u0026rdquo; to get the definiton of strong/weak one-way functions for some lengths.\nFact One-Way function for polynomial-time-enumerable $I$ can be easily transformed to the original one-way function.\n Theorem\nLet $f(\\cdot)$ be a one way function defined for lengths of polynomial-time-enumerable set $I$. Let $x=x^\\prime x^\u0026quot;$, where $x^\\prime$ is the longest prefix of $x$ with length in $I$. Define $$ g(x)=f(x^\\prime)x^\u0026quot; $$ Then $g(x)$ is a one-way function.\n Proof: The proof is simple, which is omitted here. But we review the basic thought of the proof. The technique used here is reduction. Suppose there is a algorithm $\\mathcal A$ that invert $g(\\cdot)$ efficiently, then we call construct a efficient algorithm $\\mathcal A^\\prime$ which could invoke $\\mathcal A$ polynomial times and invert $f(\\cdot)$ efficiently.\n! This is the basic ideal for strong one-way function. As for weak one-way function, the basic idea is similar.\nLength-Regular \u0026amp; Length-Preserving One-Way Function The following two definitions can be used to both strong \u0026amp; weak one-way functions.\n Length-Regular One-Way function\nA one-way function is length-regular if for every $|x_1|=|x_2|$, it holds that $|f(x_1)|=|f(x_2)|$.\n  Length-Preserving One-Way function\nA one-way function is length-preserving if for every $x$, it holds that $|x|=|f(x)|$.\n Given a one-way function, we can construct a length-preserving one-way function by the following 2 steps. Given one-way function $f(\\cdot)$, we first construct a length-preserving function $g$ by adding the pad $10^\\ast$ $$ g(x)\\doteq f(x)10^{p(|x|)-|f(x)|} $$ Then $p(\\cdot)+1$ is fixed output length of $g(x)$. Then we transform $g$ to a length-preserving one-way function $g^\\prime$ by the following: $$ g^\\prime(x^\\prime x^\u0026quot;)\\doteq g(x^\\prime), \\quad\\text{where } |x^\\prime x^\u0026quot;|=p(|x^\\prime|)+1 $$ We\u0026rsquo;ve done. The one-wayness of $g^\\prime$ can be also proved by reduction.\nBut the previous technique might not preserving the injectivity of a one-way function. For injectivity one-way fucntion $f$, the first step do construct an injectivity length-regular one-way function. But the second step break its injectivity.\nNon-uniformly One-Way Function $\\mathbf{BPP}\\subseteq \\mathbf{P}_{/\\text{poly}}$ as we known, a one-way function might still be invert efficiently by an non-uniform algorithm. If we design cryptosystem based on one-way function, it might still be analysis by using non-uniform algorithms. How strong are you going to define cryptosystem? It\u0026rsquo;s up to you. You might still define security means can\u0026rsquo;t be efficiently analized by quantum computers…\nNon-uniformly one-way function is a stronger version of one-way function, it is those one-way functions has non-uniform one-wayness, which means it can\u0026rsquo;t be revert efficiently by a non-uniform algorithm. Notice that non-uniform algorithms are deterministic if they are represented by circuit families.\n Non-uniformly One-Way Function\nA function $f:\\lbrace 0,1\\rbrace ^\\ast\\to \\lbrace 0,1\\rbrace ^\\ast$ is a strong one-way function if it is\n  Easy to compute: There is a deterministic polynomial-time algorithm $\\mathsf{EvalF}$ such that for all $n$ and all $x\\in\\lbrace 0,1\\rbrace ^n$ we have $\\mathsf{EvalF(x)} = f(x)$.\n  Hard to invert: For all $poly$-size circuit family $\\lbrace C_n\\rbrace $ , polynomial $p(\\cdot)$ and efficient large $n$, it holds that $$ \\Pr[C_n(f(x))\\in f^{-1}(f(x))]\u0026lt;\\frac 1 {p(n)} $$\n   Look, to compute the function, a $\\mathbf {BPP}$ algorithm is enough, but even a non-uniform circuit familiy of $poly$-size cold invert it.\nWeak One-Way Functions Imply Strong Ones  Theorem\nWeak one-way function exists if and only if strong one-way function exitst.\n Not all weak one-way functions are strong one-way functions, refer to Goldreich\u0026rsquo;s textbook for a counterexample. And $\\Leftarrow$ direction is trivial, so we focus on prove the $\\Rightarrow$ direction.\nLet $f$ be a weak one-way function with $p(\\cdot)$ to be guaranteed by definition. Then we might construct $$ g(x_1,\\cdots,x_{t(n)})\\doteq (f(x_1),\\cdots,f(x_{t(n)})) $$\nwhere $t(n)=n\\cdot p(n)$ .\nNaive Proof It is obvious that $g$ is easy to compute. As for invertion, one might think the success probability is less than $(1-\\frac{1}{p(n)})^{n\\cdot p(n)}$.\nHowever, there\u0026rsquo;s a severe mistake in this proof. In such proof, one have opened the adversary and limited its strategy on inverting $g$ by inverting every $f(x_i)$ independently. This alert us that not to open the adversary in the proof of universal security.\nTo see this kind of proof gives wrong results, let\u0026rsquo;s consider a simple example. Suppose $f,g$ are one-way functions. Then is $h(x)=(f(x), g(x))$ a one way function? By the naive proof, the probability any PPT $\\mathcal A$ inverse $f(x)$ and $g(x)$ both with negligible probability, $\\epsilon_1,\\epsilon_2$ correspondingly. Then it inverse $h$ with probility $1-(1-\\epsilon_1)(1-\\epsilon_2)=\\epsilon_1+\\epsilon_2-\\epsilon_1\\epsilon_2$, which is negligible. However, if $f(x)$ is a length-regular one-way function, one can prove that $g(x)=f(x)\\oplus x$ is an one-way function. Let $h(x)=(f(x),g(x))$, an adversary can easily inverse $g(x)$ by computing $f(x)\\oplus g(x)=x$.\nRight Proof The fact is the construction is right but the proof is wrong. A detailed right proof is given in the following. Suppose we have the algorithm $\\mathcal B$ to invert $g$ efficiently, that is $$ \\Pr[\\mathcal B(g(U_m))\\in g^{-1}(g(U_m))]\u0026gt;\\frac 1{q(m)} $$ then as for $m=n^2p(n)$ there is $$ \\Pr[\\mathcal B(g(U_{n^2p(n)}))\\in g^{-1}(g(U_{n^2p(n)}))]\u0026gt;\\frac{1}{q(n^2p(n))} $$\nConstruct Independent Inversion Procedure To done the proof, we use the pradigm of the proof of unversal security. Namely, by reduction. Assume that $g$ is not a strong one-way function, we construct an algorithm that invert $f$ with probability greater than $1-1/p(n)$. Let $\\mathcal B$ be the PPT algorithm that inverts $g$ with non-negligible probability.\nNow do a brainstorm: The counterexample of the naive proof shows that invert $f(x)$ independently might not be good as put $f(x)$ into $g(x_1,\\cdots, x_{t(n)})=(f(x_1),\\cdots,f(x_{t(n)})$ and asks $\\mathcal B$ to invert is nonindependently. The counterexample shows that this ideal might work. Thus, we come up with the procedure $I$, shown as follows:\n Procedure $I$\nInput: $y$\n $n\\leftarrow |y|$ for $i=1$ to $t(n)$ do  $x_1,\\cdots,x_{t(n)}\\leftarrow U_n$ $z_1,z_2,\\cdots,z_{t(n)}\\leftarrow \\mathcal B(f(x_1), \\cdots, f(x_{i-1}), y,f(x_{i+1}),\\cdots,f(x_{t(n)}))$ if $f(z_i)=y$ then return $z_i$   end for   Why don\u0026rsquo;t we repeat the algorithm that invert $f(x)$ for random $x$ with probability $1/p(n)$? One might think about the definition of $\\mathbf{BPP}$ s.t. $\\mathbf{BPP}(1/2-1/n^c)=\\mathbf{BPP}(2^{-n^d})$. However, this is not the case. $\\mathbf{BPP}$ stands for those prombes that every input $x$ can be solved in PPT. For weak one-way function, there might be a small very hard fraction of $f(x)$ that cannot be revert in PPT. As we\u0026rsquo;ll see, by procedure $I$, we have analogued this fraction of $f(x)$. It it obvious that, if any of $(f(x_{i-1}), y,f(x_{i+1}),\\cdots,f(x_{t(n)}))$ is in the very hard fraction, then $\\mathcal B$ could not invert it with probability better then $1/p(n)$.\nTo invert $y$, we test $y$ with procedure $I$ with $a(n)$ times, and with to get right $x$ s.t. $y=f(x)$ with good probability. We say $x$ is good if $x$ satisfies $$ \\Pr[I(f(x))\\in f^{-1}(f(x))]\u0026gt; \\frac{n}{a(n)} $$ Otherwise, we say $x$ is bad. For a good $x$, repeating the procedure for $b(n)$ times one reaches wrong probability $$ \\left(1-\\frac{1}{a(n)}\\right)^{n(n)}\u0026lt; \\frac1{2^n} $$ Which can be proved by $e^-1=(e^{-1/x})^x\\geq (1-1/x)^{x}$. Thus if one prove that such $x$ contributes an $1/2p(n)$ fraction of $\\lbrace 0,1\\rbrace^n$, one achieves our results. (This is the best interpretation for me that how comes up with the value $a$. If you have a better one, please remind me). Moreover, we denote $$ S_n\\doteq \\lbrace\\Pr[(f(x))\\in f^{-1}(f(x))]\u0026gt;\\frac{n}{a(n)}\\rbrace $$\nNotice that for $x\\in S_n$, no matter how large the polynomial $a(n)$ is, we can invert $f(x)$ with overwhelming probability. Though this fact also holds for any inverter that inverts $f(x)$ directly with success probability $1/p(n)$, we\u0026rsquo;ll see later $I$ improve this probability.\nAveraging Arguments for Successful Inversions Let us assume that $$ s(n)\\doteq \\Pr[g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))]\u0026gt;\\frac{1}{q(n\\cdot t(n))} $$ by the assumption that $g$ is not a strong one-way function. (Notice that for any $N\u0026gt;0$, such $n\u0026gt;N$ can be find.)\nNow we are going to focus on the size of $S_n$. Since $S_n$ collects all the good ones, if the input $\\left(f(x_1),\\cdots,f(x_{t(n)})\\right)$ of $g$ satisfy that all $x_i$ come from $S_n$, then it will be easy to be inverted; otherwise, it we be hard to be inverted. Then if we bound the probability of $\\left(f(x_1),\\cdots,f(x_{t(n)})\\right)$ that contains a bad $x_i$ being inverted by $I$, we\u0026rsquo;ve also bound the probability of such that contains no bad $x_i$ being inverted by $I$.\nWe seperate $\\lbrace 0,1\\rbrace^{nt(n)}$ into two parts, one contains one or more bad $x_i$\u0026rsquo;s in $f(x_i)$\u0026rsquo;s and the other don\u0026rsquo;t. We bound the probability that the string in these two parts being inverted by $\\mathcal B$, that is $$ s_1(n)\\doteq \\Pr [\\mathcal B(g(U_{n\\cdot t(n)})))\\in g^{-1}(g(U_{n\\cdot t(n)}))\\wedge(\\exists i: U^{i}_n\\notin S_n)] $$ and $$ s_2(n)\\doteq \\Pr[\\mathcal B(g(U_{n\\cdot t(n)})))\\in g^{-1}(g(U_{n\\cdot t(n)}))\\wedge(\\forall i: U^{i}_n\\in S_n)] $$ It is clear that $s(n)=s_1(n)+s_2(n)$.\nBefore giving the acual bound, let\u0026rsquo;s do a mental experiement and \u0026ldquo;review what\u0026rsquo;s happening next\u0026rdquo;. We want to have a subset $S_n$ of $\\lbrace 0,1\\rbrace^n$ that every $x\\in S_n$ says $f(x)$ can be inverted with overwhelming probability. If this achieves, it would be good that $S_n$ contribute a large fraction of $\\lbrace 0,1\\rbrace^n$. To have large $S_n$, $s_1$ has to be bounded, by averaging argument.\nProbability Bound for $s_1(n)$\n$s_1(n)$ can be bounded by following:\n$$ \\begin{align} s_1(n) \u0026amp;=\\Pr[\\exists i:\\mathcal B(g(U_{n\\cdot t(n)})\\in g^{-1}(g(U_{n\\cdot t(n)}))\\wedge(U^{(i)}_n\\notin S_n)] \\newline \u0026amp; \\leq \\sum^{n\\cdot p(n)}_{i=1}\\Pr[\\mathcal B(g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))\\wedge(U^{(i)}_n\\notin S_n)] \\newline \u0026amp;\\leq \\sum^{n\\cdot p(n)}_{i=1}\\sum_{x\\notin S_n}\\Pr[\\mathcal B(g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))\\wedge(U^{(i)}_n\\neq x)] \\newline \u0026amp;= \\sum^{n\\cdot p(n)}_{i=1}\\sum_{x\\notin S_n}\\Pr[U^{(i)}_n=x]\\cdot\\Pr[\\mathcal B(g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))|U^{(i)}_n=x] \\newline \u0026amp;\\leq \\sum^{n\\cdot p(n)}_{i=1} \\max_{x\\notin S_n}\\lbrace\\Pr[\\mathcal B(g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))|U^{(i)}_n=x]\\rbrace \\end{align} $$\nNext, since whenever $\\mathcal B$ inverts $\\left(f(x_1),\\cdots,f(x_{t(n)})\\right)$ with $y=f(x)$ in the $i$th place, $I$ always invert $y=f(x)$, then it holds that $$ \\Pr[I(f(x))\\in f^{-1}(f(x))]\\geq \\Pr[\\mathcal B(g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))|U^{(i)}_n=x] $$ Thus, we have $$ \\begin{align} s_1(n)\u0026amp;\\leq \\sum^{n\\cdot p(n)}_{i=1} \\max_{x\\notin S_n}\\lbrace\\Pr[\\mathcal B(g(U_{n\\cdot t(n)}))\\in g^{-1}(g(U_{n\\cdot t(n)}))|U^{(i)}_n=x]\\rbrace \\newline \u0026amp;\\leq \\sum^{n\\cdot p(n)}_{i=1} \\max_{x\\notin s_n}{\\Pr[I(f(x))\\notin f^{-1}(f(x))]} \\newline \u0026amp;\\leq n\\cdot p(n)\\cdot \\frac{n}{a(n)} \\newline \u0026amp;= \\frac{n^2\\cdot p(n)}{a(n)} \\end{align} $$ Next, we are going to prove that $|S_n|\u0026gt;(1-\\frac{1}{2p(n)})\\cdot 2^n$\nIf we assume $|S_n|\\leq (1-\\frac 1 {2p(n)})\\cdot 2^n$, then $$ \\begin{align} s_2(n) \u0026amp;\\leq \\Pr[\\forall i:U^{(i)}_n\\in S_n]\\newline \u0026amp;\\leq (1-\\frac{1}{2p(n)})^{n\\cdot p(n)}\\newline \u0026amp;\u0026lt; \\frac 1 {2^{n/2}} \u0026lt; \\frac{n^2\\cdot p(n)}{a(n)} \\end{align} $$ holds for efficient large $n$. By contradiction\n$$ \\frac 1{q(n^2p(n))}\u0026lt;s(n)\u0026lt;s_1(n)+s_2(n)\u0026lt;\\frac {2n^2p(n)}{a(n)} $$ let $a(n)=2n^2p(n)q(n^2p(n))$, we have $$ |S_n|\u0026gt;(1-\\frac 1 {2p(n)})\\cdot 2^n $$\nBound the lower probability of $\\mathcal A$ We now bound the success invert probability of $\\mathcal A$. For $x\\in S_n$, the failure probability can be bounded by $$ \\Pr\\limits_{x\\leftarrow U(S_n)}[\\mathcal{A}(f(x))\\notin f^{-1}(f(x))]\u0026lt;(1-\\frac{n}{a(n)})^{a(n)}\u0026lt;\\frac 1{2^n} $$ Now its easy to bold the success probability of $\\mathcal A$. $$ \\begin{align} \u0026amp;\\quad,\\Pr[\\mathcal A(f(x))\\in f^{-1}(f(x))] \\newline \u0026amp;\\geq \\Pr[\\mathcal A(f(x))\\in f^{-1}(f(x)) \\wedge(U_n\\in S_n)] \\newline \u0026amp;= \\Pr[\\mathcal A(f(x))\\in f^{-1}(f(x))|U_n\\in S_n]\\cdot\\Pr[U_n\\in S_n] \\newline \u0026amp;\\geq (1-\\frac 1 {2p(n)})\\cdot(1-2^{-n}) \u0026gt; 1-\\frac 1{p(n)} \\end{align} $$ Which is contradicted with the fact that $f$ is promised to be failed to invert with probability of $p(n)$. We\u0026rsquo;ve done the proof.\nSome Comments As we can see, the algorithm $\\mathcal I$ that invert every $f(x_i)$ independently is only one of such algorithms that inverts $g$, and it is not the best. If $\\mathcal I$ is the best, we don\u0026rsquo;t even need $t(n)$ to be a polynomial of $n$, it only has to be larger than $\\operatorname{poly}(n)$ to make $c^{-t(n)}$ negligible.\nA Naive Example On date.\nSummary for One-Way Function As we have learned, there is a universal construction method for strong one-way function by weak one-way function. We are going to use the word \u0026ldquo;one-way function\u0026rdquo; in future discussing.\nFuthermore, since we\u0026rsquo;ve known that one-way functions for polynomial-time-enumerable sets exists imply one-way function for all lengths exists. And the existence of the later implies the existence of length-regular or length-preserving functions. We might use these attributes without declaration.\nUniversal One-Way Function We can define a function $$ f_{\\text{uni}}(\\llcorner\\boldsymbol M\\lrcorner,x) \\doteq(\\llcorner\\boldsymbol M\\lrcorner,\\boldsymbol M(x)) $$ where $\\boldsymbol M$ is a turing machine as $\\llcorner\\boldsymbol M\\lrcorner$ is its description. This is called a universal one-way function, which is obviously computable on a universal TM with a step counter. It is interesting that if there is any one-way function $g$, so is $f_{\\text{uni}}$.\nFurthermore, we can use $f_{\\text{uni}} $ to construct the polynomial-time computable strong one-way function.\nOne-Way Function Family (Also refered as one-way functions as s collection)\nIf we put some of one-way functions together, we get a collection of one-way funtions. This is meaningless unless we have a good way to compute them by a single efficient evaluation function. If such a function do exists, with some extra attributes, the collection would be quite useful. Based on this main idea, we define one-way function family.\n One-Way Function Family\nA collection of functions $\\lbrace f_i:D_i\\to\\lbrace 0,1\\rbrace ^\\ast | i\\in I\\rbrace$ is called a strong (resp., weakly) one-way function family if there exists three PPT algorithms $\\mathcal G,\\mathcal S,\\mathcal E$ satisfy\n The generation algorithm $\\mathcal G $: given the input $1^n$, output a random variable $i$ from $I_n=I\\cap \\lbrace 0,1\\rbrace ^n$. The sampling algorithm $\\mathcal S$: given the input $1^n$ and $I_n$, output a random value $x$ from $D_i$. Then evaluation algorithm $\\mathcal E$: given the input $1^n, I_n, x$, output $f_i(x)$ correctly.  and one-wayness:\n For every PPT algorithm $\\mathcal A$, every polynomial $p(\\cdot)$ and all sufficient large $n$\u0026rsquo;s, it holds that  $$ \\Pr\\limits_{i\\leftarrow \\mathcal S(1^n); x\\leftarrow\\mathcal G(1^n,i)}[\\mathcal A(i,f_{i}(x))\\in f^{-1}_{i}(f_{i}(x))]\u0026lt;\\frac 1 {p(n)} $$\nfor any polynomial $p(n)$.\n The definition is straight forward, but there are still somewhere to pay attention to.\n  In order to efficiently sample from $I\\cap \\lbrace 0,1\\rbrace ^n$ for all efficient large $n$, the size of $I$ has to be noticable, which means $|I\\cap \\lbrace 0,1\\rbrace ^n|\\geq 2^n/\\text{poly}(n)$. The generation algorithm $\\mathcal G$ don\u0026rsquo;t have to sample $I_n$ uniformly at random on $I\\cap \\lbrace 0,1\\rbrace ^n$. Likewise, the output of sample algorithm $\\mathcal S$ on input $i$ do not necessarily distributed uniformly over $D_i$.\n  The three algorithms $\\mathcal G,\\mathcal S,\\mathcal E$ are allowed to fail with negligible probability. This doesn\u0026rsquo;t affects its cryptographic usage.\n  Have you ever find out something wired in the definition? The defintion of \u0026ldquo;One-way function family\u0026rdquo; doesn\u0026rsquo;t mentioned that all the functions in it has to be one-way function! Otherwise, it might allows for a negligible fraction of $I\\cap \\lbrace 0,1\\rbrace^n$, $f_i$ is not a one-way function.\n  Here we recall the reduction of $\\mathbf{RP}$ again. We can always construct a generation or a sampling algorithm that outputs YES with overwhelming probability by repeat $\\mathcal G$ or $\\mathcal S$ polynomial times. We are going to use this in the definition of trapdoor permutation family.\nTrapdoor One-Way Permutations With various assumptions made, an trapdoor one-way function family can be constructed. An trapdoor one-way function is a one-way function s.t. being easy to be inverted when extra information is given. This extra information is called the trapdoor. A trapdoor one-way function would be quite useful if it is injective, since it allows us to construct public encryption schemes and many other cryptography primitives that can\u0026rsquo;t be constructed from one-way function.\nFor OWP family (One-Way Permutation family) with trapdoors, we are going to use the most convenient definition for cryptography.\n Trapdoor Permutation Family\nLet $I\\subseteq \\lbrace 0,1\\rbrace ^n$ and define $I_n=I\\cap\\lbrace 0,1\\rbrace ^n$. A trapdoor permutation famility with indices in $I$ is a set of functions $\\lbrace f_i:D_i\\to D_i|i\\in I \\rbrace$ such that each $f_i$ is a permutation on the corresponding $D_i$. Such a collection is called a trapdoor permutation if there exist four PPT algorithms $\\mathcal G, \\mathcal S, \\mathcal E, \\mathcal E^{-1}$ such that the following five conditions hold:\n  Index and trapdoor generation $\\mathcal G$: $$ \\Pr[\\mathcal G(1^n)\\in I_n\\times \\lbrace 0,1\\rbrace ^\\ast]\u0026gt;1-2^{-n} $$\n  Random variable in domain sampling $\\mathcal S$, for every $n\\in\\mathbb N$ and $i\\in I_n$\n  $\\Pr[\\mathcal S(i)\\in D_i]\u0026gt;1-2^{-n}$\n  If the output of $\\mathcal S$ is in $D_i$, then its distributed uniformly at random on $D_i$, that is $$ \\Pr[\\mathcal S(i)=x|\\mathcal{S}(i)\\in D_i]=\\frac1{|D_i|} $$\n  Efficient evaluation $\\mathcal E$, for every $n\\in\\mathbb N,i\\in I_n$, and $x\\in D_i$ $$ \\Pr[\\mathcal E(i,x)=f_i(x)]\u0026gt;1-2^{-n} $$\n  Hard to invert:\n   Hard-Core Predicates As we know, to invert a trapdoor one-way function is hard without giving the trapdoor. However, given one-way function $f$, and $f(x)$, extract any information $h(x)$ for efficiently computed $h$ is not allowed. The one-wayness doesn\u0026rsquo;t imply this fact directly. To construct encryption schemes, we need this strong information hiding probability being implied by the existence of one-way function in some sence.\nContinue to our example, if $b:\\lbrace 0,1\\rbrace^{|x|}\\to \\lbrace 0,1\\rbrace$, is hard to be predicate, then we can hide one bit $b$ by\n$b(x)\\oplus m$. Moreover, such $h$ has to be efficiently computable, otherwise the encryption can\u0026rsquo;t be done efficiently. Due to the unpredicability of $h(x)$, the information of $b$ would be hide well. If all above $b$ holds, we call it a hard-core bit.\n Hard-Core Predicate\nA PPT computable predicate $b:\\lbrace 0,1\\rbrace ^\\ast\\to\\lbrace 0,1\\rbrace $ is called a hard-core of a function $f$ if for every PPT algorithm $\\mathcal A$, every polynomial $p(\\cdot)$ and all sufficient large $n$, it holds that $$ \\Pr[\\mathcal A(f(U_n))=b(U_n)]\u0026lt;\\frac{1}{2}+\\frac 1 {p(n)} $$\n Don\u0026rsquo;t be confused with the word \u0026ldquo;predicate\u0026rdquo;; it just means a function with range $\\lbrace 0,1\\rbrace $. It is obvious that a function $f:\\lbrace 0,1\\rbrace^n\\to \\lbrace 0,1\\rbrace^n$ has a hard-core bit only if it is one-way.\nWe can also define hard-core for a one-way function family.\n Hard-Core Predicate for One-Way Function Family\nFor one-way function family $(\\mathcal G,\\mathcal S ,\\mathcal E)$, a $poly$-time alogrithm $\\mathcal B:\\lbrace 0,1\\rbrace ^\\ast\\times \\lbrace 0,1\\rbrace ^\\ast\\to \\lbrace 0,1\\rbrace $ is called a hard-core of the family if for every PPT algorithm $\\mathcal A$, every polynomial $p(\\cdot)$, and all sufficiently large n\u0026rsquo;s, $$ \\Pr\\limits_{i\\leftarrow \\mathcal G(1^n); x\\leftarrow \\mathcal S(1^n,i)}[\\mathcal A(i,f_i(x))=\\mathcal B(i,x)]\u0026lt;\\frac 12+\\frac 1{p(n)} $$\n Hard-Core for Any One-Way Function In this section, we are going to prove \u0026ldquo;where there is a one-way function, there is a hard-core bit\u0026rdquo;. The construction of the hard-core is based on a very simple idea of generalize the XOR lemma of statistical indistinguishable to computational indistinguishable.\n Goldreich-Levin Theorem\nLet $f$ be an arbitrary strong one-way function, and let $g$ be defined as $g(x,r)=(f(x),r)$, where $|x|=|r|$. Then predicate $b=\\bigoplus_{i=1}^{|x|}x\\cdot r$ is a hard-core of function $g$.\n Well the proof of this theorem is quite long, but is basic idea is simple, by voting. Assume that there is some alogrithm $\\mathcal B$ that predict $b$ with non-negligible probability, we are going to construct an algorithm $\\mathcal A$ whom invokes $\\mathcal B$ for polynomial times and recover $x\\in f^{-1}(y)$ bit by bit. We are going to prove a weaker theorem first in order to build up the intuition of this theorem.\nWeaker Version: The constant successful prdiction probability $\u0026gt; 0.76$ We are going to show how to recover one bit by invoking the algorithm hard-core predicting algorithm $\\mathcal B$ that satisfy $$ \\Pr[\\mathcal B(f(x),r)=b(x,r)]\u0026gt;0.75+\\frac{1}{2p(n)} $$ where $p(n)$ is a polynomial.\nLet $e_i$ be the $n$-dimensional binary vector with $1$ in the $i$th component and $0$ in the others. Since $r$ is uniformly random, $r\\oplus e_i$ is uniformly random. We can use to $\\mathcal B(f(x),r \\oplus e_i)$ to predict $b(x,r\\oplus e_i)$, and get the right result with probability $\u0026gt; 0.75+\\frac 1{2p(n)}$.\nIf $\\mathcal B$ succesfully predicates both $b(x,r)$ and $b(x,r\\oplus e+i)$, then $$ \\begin{align} \\mathcal B(f(x),r)\\oplus \\mathcal B(f(x),r\\oplus e_i) \u0026amp;= b(x,r)\\oplus b(x,r\\oplus e_i) \\newline \u0026amp;= b(x,e_i) \\newline \u0026amp; = x_i \\end{align} $$ Then we can constuct an algorithm $\\mathcal A(f(x),r)=\\mathcal B(f(x),r)\\oplus \\mathcal B(f(x),r\\oplus e_i)$ it holds that $$ \\Pr[\\mathcal A(f(x),r)=x_i]\u0026gt;\\frac 1 2 +\\frac 1 {p(n)} $$ By Chernoff bound, we can predicate $x_i$ with overwhelming probability by repeating for polynomial times.\nProof of Goldreich-Levin Theorem For $\\mathcal B$ with success probability less than $0.75$, the previous method cannot work.\nI think Goldreich has introduced his intuition finely, so I\u0026rsquo;m going to quote the contents in his book here, with some slightly modify to the symbols.\n What is required is an alternative way of using the algorithm $\\mathcal B$, a way that does not double the original error probability of $\\mathcal B$. They key idea is to generate the $r$\u0026rsquo;s in a way that requires applying algorithm $\\mathcal B$ only once per each $r$ (and $i$), instead of twice. Specifically, we shall use algorithm $\\mathcal B$ to obtain a \u0026ldquo;guess\u0026rdquo; for $b(x,r\\oplus e_i)$ and obtain $b(x,r)$ in a different way. The good news is that the error probability is no longer doubled, since we use $\\mathcal B$ get a \u0026ldquo;quess\u0026rdquo; of $b(x,r\\oplus e_i)$. The bad news is that we still need to know $b(x,r)$ for only one $r$ (or logarithmacally in $|x|$ many $r$\u0026rsquo;s), but the problem is that we need to know (and hence guess) the values of $b(x,r)$ for polynomially many r\u0026rsquo;s. An obvious way of guessing these $b(x,r)$\u0026rsquo;s yields an exponentially vanishing success probability. Instead we generate these polynomially many $r$\u0026rsquo;s such that, on one hand, they are \u0026ldquo;sufficiently random,\u0026rdquo; whereas, on the other hand, we can guess all the $b(x,r)$\u0026rsquo;s with noticable success probability. Specifically, generating the $r$\u0026rsquo;s in a particular pairwise-independent manner will satisfy both (seemingly contradictory) reqirements.\n Back to the proof with some explaination\nSuppose there is an algorithm $\\mathcal B$ holds that $$ \\Pr\\limits_{x\\leftarrow U_n;;r\\leftarrow U_n}[\\mathcal B(f(x),r)=b(x,r)]\u0026gt;\\frac12+\\frac1{p(n)} $$ where $p(\\cdot)$ is a polynomial and $|x|=n$.\nWe define a \u0026ldquo;good\u0026rdquo; subset of $\\lbrace 0,1\\rbrace ^n$. $S_n$ defines as $$ S_n=\\lbrace x:\\Pr\\limits_{r\\leftarrow U_n}[\\mathcal B(f(x),r)=b(x,r)]\u0026gt;\\frac 12+\\frac1{2p(n)}\\rbrace $$ We have proved that $|S_n|\u0026gt;\\frac1{2p(n)}\\cdot 2^n$ in the article Averaging Argument.\nWe set $l\\doteq \\lceil \\log_2(2n\\cdot p(n)^2+1)\\rfloor$. We construct a algorithm $\\mathcal B$ proceeds as follows:\n  Sample $s^1,\\cdots, s^l\\in\\lbrace 0,1\\rbrace ^\\ast $and $\\sigma^1,\\cdots, \\sigma^l\\in\\lbrace 0,1\\rbrace $ uniformly at random.\n  For every one-empty set $J\\subseteq [l]$, computes $r^J=\\bigoplus_{j\\in J} s_j$ and a bit $\\rho^J=\\bigoplus_{j\\in J}\\sigma_j$.\n  For every $i\\in [n]$ and every non-empty $J \\subseteq [l]$, computes $$ z^J_i\\leftarrow \\rho^J\\oplus \\mathcal B(y,r^J\\oplus e_i) $$\n  For evry $i\\in[n]$, it sets $z_i$ to be the majority of the $z^J_i$ values.\n  Output $z=z_1\\cdots z_n$.\n  We have some comments. $\\sigma_j$ is regard as the approximation of $b(x, s_j)$. It might sound wired since $\\sigma_j$ is sampled uniformly at random. It sounds more like a \u0026ldquo;bad guess\u0026rdquo; since it do predication with a coin. Thanks to the fact we only guess $O(\\log n)$ bits, thus the probability of guessing all bits right can be bounded by $$ \\Pr[\\forall i\\in[l].\\sigma_i=b(x,s_i)]= 2^{-l}\u0026gt;\\frac 1 {4n\\cdot p(n)^2} $$ which is an inverse polynomial. However, polynomial time of guess is far from enough. We generate more guess by combine multiple $s$\u0026rsquo;s as we have done in step 2. Recall that we predicate $x_i$ by $\\mathcal B(x,r^J)\\oplus \\mathcal B(x,r^J\\oplus e_i)$, but his doubles the wrong probability of $\\mathcal B$, which lead the method can\u0026rsquo;t be use for such $\\mathcal B$ with wrong probability larger than $1/4$. To overcome this, we instead use $\\rho^J$ as a guess of $\\mathcal B(x,r^J)$. For pairwise-independent $r^J$\u0026rsquo;s, Chebyshev\u0026rsquo;s inequality would be helpful. We review Chebyshev\u0026rsquo;s inequality as follows:\n Theorem\nIf $X$ is a random variable with expectation $\\mu$, then $$ \\operatorname{Pr}[|X-\\mu| \\geq \\varepsilon] \\leq \\frac{\\operatorname{Var}[X]}{\\varepsilon^{2}} $$\n We define a new random variable $\\zeta^J_i$: $\\zeta^J_i = 1$ if and only if we use $r^J$ guesses $x_i$ correctly, which means $b(x,r^J)\\oplus \\mathcal B(f(x),r^J\\oplus e_i)=x_i$. Since for $J\\neq K$, there exists $j\\notin J\\cap K$, such that $r^J\\oplus r^K=r^j\\oplus r^T$ for some $T\\subset [l]$, $r^J$ and $r^K$ are independent, and thus $\\zeta^J_i$ and $\\zeta^K_i$ are independent. Then for all $J\\subset [l]$, $\\zeta^J_i$ are pair-wise independent.\nWe omit $i$ for $\\zeta_i^J$ for simplicity. Since $b(x,r^J)\\oplus b(x,r^J\\oplus e_i)$, if follows that $\\zeta^J =1 $ if and only if $\\mathcal B(f(x),r^J\\oplus e_i)=b(x,r^J\\oplus e_i)$. For $x\\in S_n$, We have $$ \\begin{align} \\Pr\\left[\\sum_{J\\subseteq[l]} \\zeta^J\\leq \\frac m 2\\right] \u0026amp;\\leq \\Pr\\left[\\left|\\sum_{J\\subseteq[l]}\\zeta^J-\\left(\\frac12+\\frac1{2p(n)}\\right)\\cdot m\\right|\\geq \\frac1{2p(n)m}\\right] \\newline \u0026amp;\\leq \\frac{m\\cdot \\text{Var}[\\zeta]}{\\left(\\frac1{2p(n)}\\cdot m\\right)^2} \\newline \u0026amp;\\leq \\frac{m\\cdot \\text{Var}[\\zeta]}{\\left(\\frac1{2p(n)}\\right)^2 \\cdot (2n\\cdot p(n)^2)} \\newline \u0026amp;= \\frac 1{2n} \\end{align} $$ Notice that we have used $$ \\begin{align} \\operatorname{Var}\\left[\\left|\\sum_{J\\subseteq[l]}\\zeta^J-\\left(\\frac12+\\frac1{2p(n)}\\right)\\cdot m\\right|\\right] \u0026amp;=\\operatorname{E}\\left[\\left(\\sum_{J\\subseteq[l]}\\zeta^J-\\left(\\frac12+\\frac1{2p(n)}\\right)\\cdot m\\right)^2\\right] \\newline \u0026amp;= \\sum_{J,K\\subset [l]}\\operatorname{E}\\left[(\\zeta^J-u)(\\zeta^K-u)\\right] \\newline \u0026amp;= \\sum_{J\\subset [l]}\\operatorname{E}\\left[(\\zeta^J-u)^2\\right] \\newline \u0026amp;= m\\cdot \\operatorname{Var}[\\zeta] \\end{align} $$ for $u=1/2+1/(2p(n))$, where the second last equality rely on the pairwise independent of $\\zeta^J$ and $\\zeta^K$ for $J\\neq K$.\nThus, if we output the majority of $\\zeta^J$, we have probability of wrong predication of $1-1/2n$.\nAnd now its time to evaluate the probability of $z_1\\cdots z_n=x_1\\cdots x_n$, $$ \\begin{align} \\Pr[z_1\\cdots z_n=x_1\\cdots x_n|x\\in S_n]\u0026amp;\\geq 1- \\sum^n_{j=1}x\\in \\Pr[x\\in S_n]\\cdot \\Pr[x_j\\neq z_j] \\newline \u0026amp; =\\frac {(1-\\frac n{2n})}{4n\\cdot p(n)^2}=\\frac 1{8n\\cdot p(n)^2} \\end{align} $$ ​\tThen $\\Pr[z_1\\cdots z_n=x_1\\cdots x_n] \\geq \\Pr[z_1\\cdots z_n=x_1\\cdots x_n|x\\in S_n]\\cdot \\Pr[x\\in S_n]$ which is polynomial and can be made overwhelming by repeating for polynomial times (Chernoff bound).\n","date":"2019-08-11T21:29:13Z","image":"https://lingerois.com/p/cryptography-1-one-way-function/cover_hucfa47b172b5c5f273fbf09f67f803465_295767_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/cryptography-1-one-way-function/","title":"Cryptography (1) One-Way Function"},{"content":"GSW方案是由Craig Gentry1, Amit Sahai与Brent Waters于2013年提出的方案, 发表于论文[GSW13]中.\nGSW方案确实如论文标题一样, 概念清晰明了, 其Intuition简单到一个刚学完线性代数的大一新生也能理解. GSW还支持基于属性的加密, 但本文中我们将不介绍这一部分内容.\n当然, 完全理解GSW方案仍然需要用到一些比较进阶的知识, 如LWE问题的困难性等. 我们在本文中不会对这些知识做过多的介绍, 这些知识将在今后其他的博文中介绍.\nBasic Intuition 密文的基本格式 最基本的GSW同态加密方案的私钥($sk$)是一个向量$\\mathbf v\\in\\mathbb Z_q^N$, 而所有的明文$\\mu_i\\in{0,1}$都被加密一个矩阵$C_i\\in\\mathbb Z_q^{N\\times N}$中, 其中$C_i$是以$v$为近似特征向量并以$\\mu_i$为近似特征值的矩阵, 即我们要求 $$ C_i\\mathbf v\\approx \\mu_i \\mathbf v $$ 这里可以看出， 我们只需要挑选$\\mathbf v$中非$0$的位(最好是选较大的位), 如第$j$位$v_j$, 并比较$v_j$与$\\mu_iv_j$的值就可以解出$\\mu_i$的值.\n一个需要注意的地方就是, 虽然$\\mu_i$取自${0,1}$, 但被视作是$\\mathbb Z_q$中的元素, 因此具体的运算也是按照$\\mathbb Z_q$的运算方式来进行.\n我们也可以将噪声(error)显式地写出来, 记作 $$ C_i\\mathbf v=\\mu_i\\mathbf v+\\mathbf e $$ 其中$\\mathbf e$是非常小的向量. 因此可以看出, 如果$\\mathbf e$确实是一个较小的噪声, 那么我们就可以正确地解出$\\mu_i$.\n乘法同态性质 现在我们来验证该加密方案具有同态性质. 现在假设有两个密文$C_1, C_2$, 对对应的明文分别是$\\mu_1,\\mu_2$, 即 $$ \\begin{aligned} C_1\\mathbf v=\\mu_1\\mathbf v+\\mathbf e_1 \\newline C_2\\mathbf v=\\mu_2\\mathbf v+\\mathbf e_2 \\end{aligned} $$ 其中$\\mathbf e_1,\\mathbf e_2$均为较小的噪声, 那么令$C^\\times=C_1\\cdot C_2$, 我们检验$C^\\times$的解密结果 $$ \\begin{aligned} C^\\times\\mathbf v \u0026amp;=(C_1\\cdot C_2)\\mathbf v \\newline \u0026amp;=C_1(\\mu_2\\mathbf v+\\mathbf e_2) \\newline \u0026amp;=\\mu_2(\\mu_1\\mathbf v+\\mathbf e_1)+C_1\\mathbf e_2\\newline \u0026amp;= \\mu_1\\mu_2\\mathbf v+\\mu_2\\mathbf e_1+C_1\\mathbf e_2 \\end{aligned} $$ 这里可以看出, $\\mu_2\\mathbf e_1$确实是一个比较小的噪声项, 但是要让$C^\\times$的噪声比较小, 那么就需要让$C_1$是一个较小的矩阵(即其最大的元素较小), 我们稍后会解释如何做到这一点.\n虽然说是乘法同态性质, 但是由于$\\mu_i\\in{0,1}$, 我们也可以将$C^\\times$视作是做了同态的与(AND)运算. 与运算相对来说是比较简单的, 但是仅有与运算是不够的, 因为与运算是单调的, 单调的电路不可能是完备的, 我们需要实现一个超强的逻辑门\u0026mdash;-与非门的同态运算.\n与非门的同态性质 设$C^\\mathsf{NAND}=I_N-C_1C_2$, 其中$I_N$为$N$阶单位矩阵, 则 $$ \\begin{aligned} C^\\mathsf{NAND}\\mathbf v\u0026amp;=(I_N-C_1C_2)\\mathbf v \\newline \u0026amp;=(1-\\mu_1\\mu_2)\\mathbf v-\\mu_2\\mathbf e_1-C_1\\mathbf e_2 \\end{aligned} $$ 根据之前的讨论, 如果$C_1$是一个较小的项, 我们有把握能从$C^\\mathsf{NAND}$中解出$\\mathsf{NAND}(\\mu_1,\\mu_2)$.\n到这里有没有一种心情舒畅的感觉? 与非门生万物, 我们确实可以通过不断地叠加与非门来实现相当复杂的函数运算, 并且由于与非门是完备的, 仅用与非门可以实现任何一个布尔函数.\n别高兴得太早! 虽然与非门非常强大, 但是每一次进行与非门运算, 都会导致新密文得噪声变得更大, 因此较多层的运算后, 噪声可能大得导致解密错误! 因此我们必须评估我们究竟能进行多少次的运算, 以及在快要达到极限的时候使用Bootstrapping技术. 这一点我们将在详细介绍方案的时候来说明.\nLattice Gadget 这里我们要首先介绍一种工具, 我们称其为Lattice Gadget, 它的本质是一些代数运算, 能够辅助我们从标准的LWE加密方案生成满足同态性质的密文.\n第一个运算是$\\mathsf{BitDecomp}$, 它的作用是将一个$\\mathbf a=(a_1,\\cdots,a_n)\\in\\mathbb Z_q^n$向量的每一位按照二进制展开, 即每一个元素$a_i$表示成二进制的形式$a_0,a_1,\\cdots,a_\\ell$, 其中$\\ell=\\lfloor\\log q\\rfloor+1$. 即 $$ \\begin{aligned} \\mathsf{Bit}\u0026amp;\\mathsf{Decomp}(\\mathbf a)= (a_{1,0},\\cdots,a_{1,\\ell-1},\\cdots,a_{n,0},\\cdots,a_{n,\\ell-1}) \\end{aligned} $$ 即将$\\mathbf a$的每一位都展开成了二进制, 变成$\\ell$位, 整个结果一共是$n\\cdot \\ell$位. 显然, $a_i=\\sum_{j=0}^{\\ell-1} 2^j\\cdot a_{i,j}$.\n类似的, 我们可以定义$\\mathsf{BitDecomp}$的反函数$\\mathsf{BitDecomp}^{-1}$, 令$\\mathbf a'=(a_{1,0},\\cdots,a_{1,\\ell},\\cdots,a_{n,0},\\cdots,a_{n,\\ell})\\in\\mathbb Z_q^{n\\cdot \\ell}$ $$ \\begin{aligned} \\mathsf{Bit}\u0026amp;\\mathsf{Decomp}^{-1}(\\mathbf a')=(\\sum_{j=0}^{\\ell-1} 2^j\\cdot a_{1,j},\\cdots, \\sum_{j=0}^{\\ell-1} 2^j\\cdot a_{n,j}) \\end{aligned} $$ 即将每一位的二进制表示重新组合成了$\\mathbb Z_q$表示. 但是要注意的是, $\\mathsf{BitDecomp}$并没有要求参数一定要是只由${0,1}$构成的向量, 我们可以定义一个全新的函数 $$ \\begin{aligned} \\mathsf{Flatten}(\u0026amp;\\mathbf a')=\\ \u0026amp;\\mathsf{BitDecomp}(\\mathsf{BitDecomp}^{-1}(\\mathbf a')) \\end{aligned} $$ 这个操作有什么意义? 它将那些不是全由${0,1}$构成的$\\mathbf a'\\in\\mathbb Z^{n\\cdot \\ell}$重新\u0026quot;抹平\u0026quot;成了由${0,1}$中的元素构成, 并且能够保持其一定的性质.\n下面介绍另一个不是那么好看, 但是却非常简单的操作$\\mathsf{Powerof2}$. $\\mathsf{Powerof2}$的功能也是将一个$\\mathbf b\\in\\mathbb Z_q^n$向量转换为$\\mathbf b'\\in\\mathbb Z_q^{n\\cdot \\ell}$向量, 但是却使用的是完全不一样的方式. $$ \\begin{aligned} \\mathsf{Power}{of2}\u0026amp;\\mathsf(\\mathbf b)=(b_1,2b_1,\\cdots,2^{\\ell-1}b_1,\\cdots, b_n,2b_n,\\cdots,2^{\\ell-1}b_n) \\end{aligned} $$ 即将$\\mathbf b$的每一位, 展开为$\\ell$位, 并且后一位是前一位的两倍. 使得整个向量变成$\\mathbf b'$. 这样做的好处是, 如果$a_i,b_i$分别是$\\mathbf a,\\mathbf b\\in\\mathbb Z_q^n$中的一位, 那么 $$ a_i\\cdot b_i=\\sum_{j=1}^{\\ell -1}2^j \\cdot a_{i,j}\\cdot b_i=\\sum_{j=1}^{\\ell-1}(a_{i,j})\\cdot (2^{j}\\cdot b_j) $$ 前面一部分就是$\\mathbf a'$中第$i$组的第$j$位, 而后一部分就是$\\mathbf b'$中第$i$组的第$j$位, 那么显然有 $$ \\langle \\mathbf a,\\mathbf b\\rangle=\\langle\\mathsf{BitDecomp}(\\mathbf a),\\mathsf{Powerof2}(\\mathbf b)\\rangle $$ 如果将$\\mathsf{BitDecomp}(\\mathbf a)$直接写成$\\mathbf a'$的形式, 我们还有 $$ \\begin{aligned} \\langle\\mathbf a',\\mathsf{Powerof2}(\\mathbf b)\\rangle \u0026amp;=\\langle\\mathsf{BitDecomp}^{-1}(\\mathbf a'),\\mathbf b\\rangle \\newline \u0026amp;=\\langle \\mathsf{Flatten}(\\mathbf a'),\\mathsf{Powerof2}(\\mathbf b)\\rangle \\end{aligned} $$\n 第一个等号左边, 可以通过对第一个等号右边的两项分别做$\\mathsf{BitDecomp}$和$\\mathsf{Powerof2}$操作得到 第二个等号右边可以对第二个等号左边两项分别做$\\mathsf{BitDecomp}$和$\\mathsf{Powerof2}$操作得到  实际上左右两边的两项都是由中间得到的, 这样就可以将左右两边连接在一起. 这样我们发现一个惊人的事实: 如果内积的第二项是标准的$\\mathsf{Powerof2}$结果的形式, 那么对第一项做$\\mathsf{Flatten}$操作不会改变内积的结果! 实际上这也不难理解, 因为Flatten操作就是把数值过高的位分到权重更高的位而已. 但是这样做有一个好处就是, 使得$\\mathbf a'$变成每一位都是${0,1}$的$\\mathsf{Flatten}({\\mathbf a'})$.\n我们将以上几种记号都推广到对矩阵可用, 例如对于$C=[\\mathbf c_1,\\cdots,\\mathbf c_N]$, 令 $$ \\begin{aligned} \\mathsf{Flatten}(\u0026amp;C)=[\\mathsf{Flatten}(\\mathbf c_1),\\cdots,\\mathsf{Flatten}(\\mathbf c_N)] \\end{aligned} $$ 其余几种记号也做类似的推广, 总之就是, 对矩阵的每一列的列向量做相应的操作. 这时我们发现, 如果密钥$\\mathbf v$确实是某个向量$\\mathbf s$进行$\\mathsf{Powerof2}$的结果, 即$\\mathbf v=\\mathsf{Powerof2}(s)$, 那么就有 $$ C_i\\mathbf v=\\mathsf{Flatten}(C_i)\\mathbf v $$ 这可以使得$C_i'=\\mathsf{Flatten}(C_i)$变成一个较小的矩阵, 而不改变最后与$\\mathbf v$的相乘的结果! 这样使得$C'_i$可以代替$C_i$进行下一层的同态运算使得我们要求的$C_2$项较小! 我们直接将$\\mathsf{NAND}$的结果记作 $$ C^{\\mathsf{NAND}}=\\mathsf{Flatten}(I_N-C_1C_2) $$\nGSW方案 现在我们开始具体介绍方案. 我们要说的是, GSW方案根据解密算法的选区不同, 实际上有构造两套方案. 第一种是选择$\\mathsf{Dec}$作为解密算法, 该算法仅能解出$\\mu_i\\in{0,1}$, 因此整个同态运算中主要用与非门构建逻辑电路进行计算. 另一个解密算法$\\mathsf{MPDec}$可以解出$\\mu_i\\in\\mathbb Z_q$, 这样就可以自然地使用加法与乘法进行运算.\n首先我们要说的是, GSW并不是一个标准假设下的全同态加密方案. GSW如果要做到全同态加密, 需要用到Bootstrapping, 进而需要用到LWE加密方案的Circular Security假设(即用一对公私钥中的公钥来加密私钥相关信息的加密结果是安全的). 我们这里不介绍Bootstrapping的具体过程, 仅介绍Somewhat HE.\n $\\mathsf{Setup}(1^\\lambda,1^L)$: 我们用$\\lambda$表示安全参数, $L$表示同态运算的层数, 则$|q|=\\kappa(\\lambda,L)$表示模数$q$的位数. 选择$n=n(\\lambda,L)$和LWE的错误分布$\\chi=\\chi(\\lambda,L)$, 选择$m=m(\\lambda,L)=O(n\\log n)$. 设$\\ell=\\lfloor\\log q\\rfloor+1$和$N=(n+1)\\cdot \\ell$, 参数集$params=(n,q,\\chi,m)$.  这里的参数较多, 需要逐一解释一下. 首先$\\lambda$是安全参数, 表示密码方案中基于的困难的问题的复杂程度, 所有的参数都应该(直接或间接)基于这个参数选择. 参数$L$表示同态运算的层数, 由于同态运算的层数由噪声的占比决定, 因此想要做更多的同态运算次数, 那么噪声就不应该太快掩盖$q$, $q$就应该相应地选择大一些. 而LWE问题的错误分布$\\chi$还有维数$n$按理来说是应该根据$\\lambda$来选择, 但是这两个参数是可以根据$q$来进行权衡(tradeoff)的, 这里直接用基础参数$L$来代替$q$. 而参数$\\ell,N$则是为了方便我们进行表示而引入的记号, 并且他们在前面也出现过.\n $\\mathsf{SecretKeyGen}(params)$: 选择$\\mathbf t\\leftarrow \\mathbb Z_q^n$, 令$\\mathbf s\\leftarrow (1,-\\mathbf t)=(1,-t_1,\\cdots,-t_n)\\in\\mathbb Z_q^{n+1}$,$\\mathbf v=\\mathsf{Powerof2}(\\mathbf s)$. 输出$sk=\\mathbf s$. $\\mathsf{PublicKeyGen}(params,sk)$: 生成矩阵$B\\leftarrow \\mathbb Z_q^{m\\times n}$和$\\mathbf e\\leftarrow\\chi^m$. 令$\\mathbf b=B\\mathbf t+\\mathbf e$. 令$A=[\\mathbf b|B]$, 输出公钥$pk=A$.  实际上这里就是变相生成了一组LWE问题的实例.\n $\\mathsf{Enc}(params,sk,\\mu)$: 生成矩阵$R\\leftarrow {0,1}^{N\\times m}$, 输出密文 $$ \\begin{aligned} C=\\mathsf{Flatten}(\\mu\\cdot I_N+\\mathsf{BitDecomp}(R\\cdot A)) \\end{aligned} $$  这就是整个加密的过程, 其中$\\mathsf{Flatten}$操作是为了保证$C$是一个较小的矩阵, 我们知道$\\mathbf v$是一个$\\mathsf{Powerof2}$向量, 那么 $$ \\begin{aligned} C\\mathbf v \u0026amp;=(\\mu\\cdot I_N+\\mathsf{BitDecomp}(R\\cdot A))\\mathbf v \\newline \u0026amp;= \\mu\\cdot I_N\\cdot \\mathbf v + R\\cdot A\\cdot \\mathbf s \\newline \u0026amp;= \\mu\\cdot \\mathbf v+R\\cdot \\mathbf e \\end{aligned} $$ $R\\cdot \\mathbf e$也是一个小噪声, 因此密文符合我们的要求.\n $\\mathsf{Dec}(params, pk,C)$: 选择一个$\\mathbf v$的系数$v_i=2^i\\in (q/4,2/q]$. 设$C_{i}$是$C$的第$i$列, 则计算$x_i=\\langle C_i,v_i\\rangle$, 输出解密结果$\\mu'=\\lfloor x_i/v_i\\rceil$.  实际上这里的解密过程就是比较$C\\mathbf v$与$\\mathbf v$的值. 而为了使得解密出错的概率最低, 所以选择$v_i$较大的一项, 这样使得错误最多可以积累到$q/4$而解密不出错.\n $\\mathsf{MPDec}(params,sk,C)$: 参考[MP12].  噪声分析 接下来我们看一下进行$L$层同态运算后, 噪声的增长. 我们知道, 两个噪声为$E$的密文行一次加法运算, 噪声增长到$2E$. (这里$E=\\max_{i\\in [N]}\\mathbf e$, 表示解密中的噪声项), 而两个噪声为$E$的密文乘法结果的的噪声项为$\\mu_2\\mathbf e_1+C_1\\mathbf e_2$, 最多为$(N+1)B^2$. 如果初始噪声为$E$的密文进行$L$层运算, 则噪声最多增长为$(N+1)^LB^{2^L}$, 由这一点可以看出, 我们最多可以进行对数次数的同态运算. 但是对数次的运算已经足够用于解密运算, 因此我们可以基于Circular Security假设, 使用Bootstrapping技术实现全同态.\n文中提到的论文 [GSW13] Craig Gentry, Amit Sahai and Brent Waters. Homomorphic Encryption from Learning with Errors: Conceptually-Simpler, Asymptotically-Faster, Atribute-Based. Annual Cryptology Conference. Springer, Berlin, Heidelberg, 2013.\n[MP12] Daniele Micciancio and Chris Peikert. Trapdoors for lattices: Simpler, tighter, faster, smaller. In EUROCRYPT, pages 700-718, 2012.\n  第一个全同态加密方案的人,可以说是同态加密方案的鼻祖.现在的大多数同态加密方案都是在Gentry最初的方案的基础上改造而来的.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2019-08-11T21:29:13Z","image":"https://lingerois.com/p/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%861-gsw%E6%96%B9%E6%A1%88/fog_hu165ac214da6e531d826e0fd7ad766063_27843_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%861-gsw%E6%96%B9%E6%A1%88/","title":"同态加密(1) GSW方案"},{"content":"图灵机是一种计算复杂性常用的一种计算模型, 图灵机由于结构简单并且功能完善而被广泛采用, 贯穿整个计算复杂性研究的始终.\n 这将是非常长的一个章节. 本节开始, 我们正式开始讲解现代复杂性理论. 当你看到一套科学理论中有\u0026quot;现代\u0026quot;这两个字的时候, 你应该做好心里准备, 因为这意味着它并不是那么容易懂. 这些理论是现当代著名科学家的重要研究成果, 需要花上一些时间去理解.\n 符号约定    符号 意义     $\\mid x\\mid$ 串$x$的长度   $ \\llcorner M\\lrcorner$ 图灵机$M$的编码   $\\mathbb M$ 所有图灵机的集合    图灵机计算模型 图灵机是一种计算复杂性常用的一种计算模型, 图灵机由于结构简单并且功能完善[^1]而被广泛采用, 贯穿整个计算复杂性研究的始终.\n图灵机 我们前面已经看到, 自动机确实能解决一些判定问题, 即正则语言的判定问题. 那么, 正则语言到底有多少? 实际上我们会发现, 正则语言真的非常少. 判定一个语言是不是正则语言, 可以根据著名的泵引理(pumping lemma)来完成, 我们这里不对其进行正式介绍, 但是我们直接说明, 通过泵引理, 下面这一的简单的语言都不是正则语言: $$ L=\\lbrace x:x中的0和1个数相同 \\rbrace $$ 如果要直观地理解, 我们的自动机中并没有结构来记录串中的$0$和$1$到底有多少个, 也就无法完成判定工作, 因为我们可以猜测这个语言不是正则语言. 为了加强自动机的计算能力, 我们引入一种新的强大的计算模型, 并且出人意料的是, 它的结果相当简单. 为什么它很强大, 我们可以通过比较它和现代冯·诺伊曼机来初步认识.\n图灵机(turing machine)是在自动机的基础上, 和用于记录数据(即符号)的纸带(tape)组成. 图灵机的纸带是无限长的, 并且一般来说是有起点的. 另外, 纸带是离散的, 就像是有一个一个的小格子. 纸带通过读写头(head)来进行操作, 且自动机可以控制读写头的移动, 且一般来说, 我们只允许每一步计算中, 读写头位置保持不变或移动一格. 与自动机不同, 图灵机中的转移函数要根据读写头下纸带上的符号来决定, 同时, 转移的结果也应当包含纸带的移动方向.\n标准的图灵机只有一条纸带, 但是为了方便起见, 我们使用的是具有$k$条纸带的图灵机. 其中, 第一条纸带是输入带, 只记录问题的输入, 余下的$k-1$条纸带是工作带, 图灵机将在整个计算过程中对它进行读写. 图灵机如果完成计算(称为\u0026quot;停机\u0026quot;), 则最后一条纸带上的结果就是问题的答案. 我们约定, 以后说\u0026quot;标准图灵机\u0026ldquo;就是指单带且无额外功能的图灵机.\n\r 定义 $k$带图灵机\n一个图灵机$\\mathbb M$是一个三元组$(\\Gamma, Q, \\delta)$.\n 有限集$\\Gamma$是字母表, 表示纸带可以记录的符号集. 有限集$Q$是状态集, 表示状态机的状态, 其中一个特殊的状态$q_\\text{start}$为起始状态, $q_\\text{halt}$为停机状态. 转移函数$\\delta: Q\\times \\Gamma^k\\to Q\\times \\Gamma^{k-1}\\times \\lbrace\\text L,\\text S,\\text R\\rbrace^k$   我们依次来解释上述符号. 首先字母表和状态集很简单, 它类似于自动机的字母表和状态集. 图灵机在运行的时候, 首先需要向输入带上写入输入串, 然后再启动图灵机. 在启动图灵机时, 读写头处在纸带最左的位置, 而状态处于起始状态$q_\\text{start}$. 当状态为$q_\\text{halt}$时, 图灵机将会停止运算, 此时输入带上的串就是问题的答案. 对于求解判定问题的图灵机, 停机时输出带上的串只能是$0$或$1$(否则当作非法的图灵机处理即可).\n图灵机的计算方式, 是转移函数来规定的, 每执行一步转移函数, 称为一步计算. 仔细看转移函数中的每条映射的内容, 左边有$\\Gamma^k$表示每个读写头下纸带的符号, 需要作为转移的条件. 而转移的结果, 则包括非输入带上要写入的内容$\\Gamma^{k-1}$和读写头的运动方向$\\lbrace\\text L,\\text S,\\text R\\rbrace^k$. 其中\u0026quot;L\u0026quot;\u0026ldquo;S\u0026quot;\u0026ldquo;R\u0026quot;分别表示\u0026quot;左移\u0026quot;\u0026ldquo;不动\u0026quot;\u0026ldquo;右移\u0026rdquo;. 我们约定, 每一次转移发生时, 图灵机的读写头都先执行移动再写入, 因此$\\Gamma^{k-1}$总表示上一步计算结束后读写头的位置需要写入的内容.\n注意: 图灵机的状态集是有限的, 纸带的条数也应该有限, 在你设计图灵机上运行的算法时, 你应该考虑该算法是否对于任意长度的输入都能被有限个状态集和有限条纸袋数目处理.\n由于即使是非常简单的问题, 图灵机的精确描述(即写出它的状态集\\转移函数\\字母表)都回非常麻烦, 所有我们很少去精确描述一台图灵机, 取而代之, 我们用自然语言大致地叙述其功能. 对于这样的功能具体应该如何实现, 在学习计算复杂性时可以逐步积累. 常简的合法描述包括有例如:\n  将所有的读写头移动到最左的位置.\n我们可以通过存放一个特殊的符号$\\triangleright$在每条纸带的开头, 然后让图灵机进入一些列特殊的状态, 这些状态会不断地控制图灵机读写头左移, 知道所有的读写头都在符号$\\triangleright$处即可.\n  将某条纸带清空\n这里的原理类似于上一条, 只是将移动(实际上就是写和刚读入符号一样的符号)改为写空格即可.\n  读到某些符号组合时停机\n直接由一系列这样的转移函数控制: 处于任意状态并读到规定的符号转移到随机状态.\n  同时, 图灵机的描述不能过于抽象, 以免产生图灵机根本无法在规定条件下完成的指令:\n 在第一条工作带写下$\\mathbf P \\overset{?}{=}\\mathbf{NP}$的答案 计算Ramsey数$R(|x|,|x|)$并写在第一条纸带上  图灵机和冯·诺伊曼计算机的关系 图灵机的纸带的功能类似于就是现代计算机的内存的功能. 现代计算机的内存有个重要的特点就是随机访问, 但是图灵机的纸带不能随机访问, 需要访问某个位置的元素时, 纸带上读写头需要逐步移动过去. 但是这并不影响我们使用图灵机来分析算法的复杂度, 因为实际上我们可以证明, 一台可以随机访问纸带的图灵机和一台标准的图灵机的计算速度之差一个多项式, 而且是一个很小的多项式. 即如果一个问题$f$能被一台随机访问纸带内容的图灵机在$T(|x|)$时间(即步骤数)内求解, 那么也能被一台图灵机在$p(|x|)\\cdot T(|x|)$内求解, 其中$p$是一个多项式函数. 因此如果我们只关注复杂度类时, 使用图灵机和使用现代计算机没有什么区别. 当你发现一个问题肯定不能被图灵机在多项式时间内解决的时候, 现代计算机同样也不能在多项式时间内解决它. 如果你要问为什么我们能接受这样的结果, 那么请你继续往下看, 你学到复杂度类P的时候自然会明白.\n图灵机的转移函数, 就相当于是CPU中的控制单元, 他们根据微指令(转移函数的前半段)来产生具体操作(包括内存的写入和寻址). 而图灵机的状态机, 就相当于是CPU的寄存器, 它表示CPU当且所处的计算状态. 现代计算机运算的最小单元是一个CPU周期, 而对于图灵机来说, 最小的计算步骤就是一步转移, 在这一点上二者也是很类似的.\n\r这样看来, 似乎图灵机和标准的计算没有什么隔阂. 实际上, 丘奇-图灵论题将是一个比这个结论强很多的论题, 尽管尚未被证明, 但是目前为止它都未被证伪, 因此它成为了计算机科学的一条公理. 我们将在介绍可计算性的时候介绍这个结论.\nWarming Up: 用图灵机计算二进制加法 现在我们来尝试构建一台用于计算两个数的加法的图灵机, 为了方便起见, 我们做如下限定:\n  两个数的位数相同\n  我们用特殊符号\u0026rdquo;$+$\u0026ldquo;来分割两个加数, 用\u0026rdquo;$=$\u0026ldquo;来表示输入的结束.\n  输入和输出都是从低位开始\n如果你希望从高位开始, 你只需要多写几个翻转的程序即可.\n  每条纸带上的最左端的位置, 都有一个符号\u0026rdquo;$\\triangleright$\u0026rdquo;\n这个符号我们永远不会改写, 它的唯一功能就是标注每条纸袋最左边的位置, 方面程序(转移函数)的构造.\n  有一个特殊符号\u0026rdquo;$\\square$\u0026ldquo;表示空格.\n  我们将工作分为两步完成:\n 拷贝第二个输入数到工作带 计算两个加数的和, 写在输出带上  在写好大致的工作步骤后, 我们需要写出更加详细的工作步骤, 来让我们更加详细地写出图灵机.\n 让输入带上的读写头向右移动, 直到找到符号\u0026rdquo;$+$\u0026rdquo; 拷贝第二个输入数到工作带, 并以\u0026quot;$+$\u0026ldquo;结束 让工作带和输入带上的读写头向左移动, 直到均找到符号\u0026rdquo;$\\triangleright$\u0026quot; 计算步骤, 按位计算, 将结果写在输出带上, 并且将进位结果用状态机表示; 直到输入带和工作带都遇到\u0026quot;$+$\u0026quot; 停机  现在我们来设计图灵机的状态机和转移函数. 我们用\u0026quot;$(a,b)\\to(x,y,\\text{LLL})$\u0026ldquo;的格式来表示转移, 其中$a$和$b$分别是输入带和工作带上读取到的内容, $x$和$y$分别是工作带和输出带上要写入的内容, 而三个连续字母如$\\text{LSR}$分别表示输入带, 工作带, 输出带上读写头的移动方向, 和前面一样, \u0026ldquo;L\u0026quot;\u0026ldquo;S\u0026quot;\u0026ldquo;R\u0026quot;分别表示\u0026quot;左移\u0026quot;\u0026ldquo;不动\u0026quot;\u0026ldquo;右移\u0026rdquo;. 并且记住, 图灵机始终是先根据当前映射的结果先移动再写入. 同时, 为了简便起见, 我们用希腊字母$\\alpha,\\beta,\\cdots$表示$\\lbrace0,1\\rbrace$的通配符. 例如$(a,\\beta)\\to(\\beta,y,\\text{LLL})$表示:$(0,1)\\to(1,y,\\text{LLL})$和$(0,1)\\to(1,y,\\text{LLL})$ . 而$\\bar{\\alpha}$z则表示和$\\alpha$相反的比特.\n{% asset_img diagram-20190306.svg 计算加法的图灵机 %}\n这个图相当复杂对吧? 我们做一些解释\n 首先, 图灵机从$q_\\text{start}$处开始运行, 通过一步操作让输入带和工作带跳出$\\triangleright$. 在$q_\\text{right}$处, 输入带上的纸带会不断右移, 直到遇见$+$. 在$q_\\text{left}$处, 输入带和工作带上的纸带会不断左移, 分别直到遇到$\\triangleright$ 在$q_\\text{left}$处, 如果输入带和工作带均抵达$\\triangleright$, 则会右移动一步, 开始计算 在计算过程中, 每一步计算会根据上一步的进位结果, 以及输入带和工作带上的数, 决定当前位的和以及进位. 同时根据进位来选择计算状态$q_\\text{carry0}$或$q_\\text{carry1}$ 在计算时, 如果遇到$+$, 标志计算结束, 进入$q_\\text{halt}$  此外, 在计算过程中, 遇到任何不符合上述步骤的情况, 均可断定输入是非法的, 此时图灵机直接停机即可.\n即使是这样简单的问题, 解决它的图灵机描述出来也是相当复杂, 因此我们真的会很少这样描述, 因此建立对图灵机能力的直观感受对于研究计算复杂性来说尤为重要.\n时间复杂度 在这之前, 我们先说一下, 对于图灵机来说, 计算时间意味着什么? 假如有这样一个世界, 这个世界里有各种各样的图灵机. 同我们的世界一样, 这个世界有它的时空规则, 图灵机们也有自己的信仰. 我们称这个世界为图灵世界(Turing Word). (这个故事和这种说法都是我虚构的, 学术界并没有这么叫, 只是我觉得图灵机很多地方真的可以和人类比, 因此我觉得讲出这个故事有助于读者理解, 如果你不喜欢这个故事, 你完全可以忽略这些内容而不影响阅读).\n关于为什么要引入图灵世界 等了解了强丘奇-图灵论题后, 读者应该会觉得引入这个世界自然一些. 很多时候, 我们在讨论密码协议的时候, 我们都直接假设是Alice和Bob或者更多人之间的协议, 也就是人与人之间的协议. 实际上, 这些协议是图灵机与图灵机之间的, 之所以可以这么做, 是因为我们有强丘奇-图灵论题作为假设, 即人也可以看作图灵机, 也就是人, 图灵机, 电脑三者之间是\u0026quot;等同\u0026quot;的. 更多内容请参考对应章节.\n我们来说图灵世界的时空观. 图灵世界是的时间是离散的, 即量子化的. 所有的图灵机, 在每个时间单位内, 都执行一步计算\u0026mdash;-无论这个图灵机是复杂还是简单. 对于图灵机来说, 计算的时间就是计算的步数. 而每一步计算, 就是执行一次转移函数. 因此, 请等同这两个概念: 计算时间和计算步数.\n时间函数  时间函数\n设$T: \\N \\to \\N$是一个函数, 且图灵机$M$计算函数$f$. 称图灵机$M$在$T$时间计算$f$, 如果对于任意输入$x$, $M$在$T(|x|)$时间内停机.\n 时间可构造函数 图灵机要怎么才能知道自己花了多少时间? 一种办法是, 让图灵机一边计算, 一边维持一个时钟. 图灵机有些计算步骤得花在维护这个时钟上, 另一些步骤用于计算. 那么, 我们可以根据时钟来规定图灵机在指定的时间停机. 对于固定的停机时间, 这一点并不难, 但是对于规定的停机时间也是一个函数, 问题就要相对复杂一些. 如果时间是一个和输入长度有关的函数, $T(\\cdot)$, 那么图灵机要在$T(n)$步时停机, 首先就是得将$T(n)$的值算出来. 这通常来讲也很容易, 但是一种极端的情况是, 图灵机根本没法在$T(n)$时间内将$T(n)$计算出来! 为了避免这种情况发生, 我们经常排除这种情况带来的困扰, 转而定义时间可构造函数来限排除极端情况而得到通常情况下更加普适的结论.\n 时间可构造函数\n函数$T(n)$是时间可构造函数, 如果存在一台图灵机$M$满足${M}(1^n)=T(n)$且在$O(T(n))$时间内停机.\n 注意输入串$1^n$是计算复杂性中常用的技巧, 该输入的内容没有任何意义, 但是其长度限定了问题计算所用的资源, 如时间.\n 强时间可构造函数\n函数$T(n)$是强时间可构造函数, 如果存在一台图灵机$M$满足${M}(1^n)=T(n)$且正好在$T(n)$时间停机.\n 显然, 一个函数是强时间可构造函数, 仅当它是时间可构造函数.\n带计时器的图灵机 如果一个函数$T(n)$是强时间可构造函数, 那么我们可以控制图灵机在$T(n)$时间内停机: 只需要向图灵机$M$添加计算这个计时器的部件$T$, 然后交替得进行$M$和$T$的计算, 并且在$T$停机的时候停机.\n其他型的图灵机 图灵机相比自动机, 多了一些结构, 因此可以形成多种不同的变体. 但是, 如何界定图灵机是我们需要考虑的问题\u0026mdash;-我们将多带图灵机视作了一种图灵机, 而标准的图灵机是单带的. 回忆\u0026lt;自动机模型\u0026gt;中的内容, 我们从来不认为\u0026quot;非确定自动机\u0026quot;是自动机, 但是为什么我们能容忍将多带图灵机划分到图灵机中? 为了回答这个问题, 我们首先介绍一些种类的图灵机, 再来考虑如何界定图灵机.\n双向访问图灵机 我们之前介绍的图灵机, 纸带一头是无限延伸的, 而另一头确是有起点的. 现在有这样一种图灵机, 它的纸带双向都是无限的, 那么这样一台图灵机和标准图灵机有什么不一样? 为了简便起见, 我们只考虑单带双向访问图灵机. 现在, 我们证明由一台单带双向访问图灵机在$T(n)$时间内解决的问题, 也能被普通图灵机在$(T(n))^2$时间内解决.\n实际上, 上述命题的证明采用了\u0026quot;折叠\u0026quot;的思想, 即将一条可以双向访问的纸带, 用一条\u0026quot;折叠\u0026quot;了的纸带来表示. 你可以通过扩大字母表, 来使得它的每个位置都能放下两个字符. 如将双向访问图灵机的字母表$\\Gamma$扩大为$\\Gamma\\times\\Gamma^\\ast$, 原先在$-5$位置的$\\alpha$和$+5$位置的$\\beta$都被放置在折叠后的纸带中$+5$位置中, 并记作$(\\alpha,\\beta^\\ast)$. 当然, 也可以通过正向位置和负向位置交替放置的方式来折叠.\n随机访问图灵机 我们假设我们使用的是双带随机访问图灵机, 即数据输入\\输出\\工作均在一条纸带上(这条纸带称为工作带), 但配备一条特殊的地址带. 在地址带上写上相应的地址, 然后再进入一个特殊的访问状态, 就可以使得图灵机的工作带上的读写头立即跳转到地址带上内容所标注的地址的内容.\n健忘1图灵机 健忘图灵机是一类特殊的图灵机, 它们在结构上和普通的图灵机没有任何不同, 但是它们在针对具体输入数据时, 读写头运动的方式以及计算的总步数只与输入长度相关, 而与输入的具体内容无关. 换句话说, 也就是健忘图灵机在得到相同长的任意输入时, 读写头运动的方式, 以及从开始计算到停机所经过的总步骤数是相同的.\n试想解密服务者为你提供了解密服务, 你可以询问他任何密文所对应的明文, 假设服务者是用图灵机来为你解密, 如果他的图灵机是非健忘的, 你输入不同密文时, 他给你明文的时间也就不同, 这就泄露了一定的信息. 但是如果解密使用一台健忘图灵机来为你解密, 无论你输入任何数据, 你拿到明文所需要的时间都是相同的-—-你无法从解密时间中得到和密钥相关的任何信息.\n通用图灵机 图灵机和算法的关系 其实, 似乎每台图灵机只能解决一个问题, 并不像现代计算这样具有可编程性. 这样看来一台图灵机更像是电子计算机上执行的一个算法. 我们不妨换一个角度, 想一想你在计算机上求解一个具体问题时会怎么做呢? 首先是写一个程序, 然后再让计算机执行这个程序, 然后输入必要的数据并等待输出对吧? 试想一下, 如果将程序和数据一起交给计算机会怎样呢? 即我们将数据hard code到程序里面, 会怎样呢? 这个时候就可以将程序和数据一起看作是输入! 而计算机就是解决这个输入(程序+数据)集映射到的结果的函数计算器. 即计算机就是解决函数$f:(P,x)\\to \\lbrace0,1\\rbrace^\\ast$的机器.\n试想, 我们是否也可以通过这样的方式来构造一台图灵机$\\mathcal U$, 输入其他一台图灵机$M$的描述$ \\llcorner M\\lrcorner$, 以及需要结计算的数据$x$, 让$\\mathcal U$来计算$M(x)$? 即是否可以构造一台图灵机$\\mathcal U$, 使得对于任意的图灵机$M$和数据$x$, 满足$\\mathcal U(\\llcorner M\\lrcorner,x)=M(x)$? 如果可行, 那么我们就可以得到一台真正的像现代计算机一样的图灵机.\n图灵机的编码 在介绍通用图灵机之前, 我们首先要介绍如何来描述图灵机, 即我们确实有办法将一台图灵机$M$编码为$\\llcorner M\\lrcorner $. 如果我们将同一个自然数的不同编码, 视作是等同的, 那么这种对图灵机的该编码就是函数$f: \\mathbb M\\to \\mathbb N$, 我们要求它满足\n $f$是一个满射, 即任何一个自然数$\\alpha\\in\\mathbb N$都能编码一台图灵机 任何一台图灵机$M$, 都有无限多个不同的编码, 即$f(M)$是无限集  我们记自然数$\\alpha$确定的图灵机为$M_\\alpha$.\n通用图灵机  定理\n存在一台通用图灵机$\\mathcal U$ 满足\n $\\mathcal{U}(x,\\alpha)=M_\\alpha(x)$ 如果对于任意$x\\in\\lbrace0,1\\rbrace^\\ast$, $M_\\alpha$在$T(|x|)$ 时间内停机, 则$\\mathcal U(x,\\alpha)$在$cT(|x|)\\log T(|x|)$时间内停机   定理的证明将在专题中完成.\n可计算性 可计算性是一个相对复杂但是有很有趣的话题, 要是单独拿出来写的话可以写成整整一本书. 在这方面, 丘奇可以说是先驱, 之后还有图灵, 哥德尔等很多史诗级的科学家研究. 本节, 我们将介绍可计算性的概念, 评估图灵机的计算能力, 以及应用一个重要的技术来证明问题的不可解性.\n实际上, 这一部分并不是计算复杂性的核心内容, 因为我们很少关注不可计算的问题. 但是学习这一部分有助于理解图灵机的工作原理, 以及熟悉我们经常在计算复杂性\\密码学\\数学中使用的一个重要技巧: 归约(reduction).\n对角化方法 现在介绍一个不可计算的问题, 然后我们将证明它不可计算.\n定义函数$\\mathsf{UC}:\\lbrace0,1\\rbrace^\\ast\\to\\lbrace0,1\\rbrace$为 $$ \\mathsf{UC}(\\alpha)=\\left\\lbrace\\begin{align}\u0026amp;0,\\quad M_\\alpha(\\alpha)=1\\\u0026amp;1, \\quad\\text{otherwise}\\end{align}\\right. $$ 这个问题用语言描述出来也不算复杂, 即对于输入$\\alpha$, 如果它表示的图灵机$M_\\alpha$接收到这个输入时, 在有限步骤内停机并输出$1$时, 则$\\mathsf{UC}(\\alpha)=0$. 否则, 即$M_\\alpha(\\alpha)=0$或者甚至不停机的时候, $\\mathsf{UC}(\\alpha)=1$. 现在我们来证明他的不可计算性.\n假设存在一台图灵机$M_\\beta$能够计算$\\mathsf{UC}$, 那么根据$\\mathsf{UC}$的定义有 $$ \\mathsf{UC}(\\beta)=1\\iff M_\\beta(\\beta)\\neq 1 $$ 而根据$M_\\beta$能够计算$\\mathsf{UC}$, 有$M_\\beta(\\beta)=\\mathsf{UC}(\\beta)$, 这显然是矛盾的. 因此我们的假设不成立, 也就没有图灵机能够计算$\\mathsf{UC}$. 这个证明的方法叫做对角线方法, 如果想知道为什么这个方法叫对角线方法, 可以参考原教材.\n图灵停机问题 图灵停机问题是一个经典的不能被图灵机解决的问题, 通过这个问题, 你会发现图灵停机并不是可以解决所有的为你, 即并不是所有问题都有解决的算法.\n图灵停机问题$\\mathsf{HALT}$就是要我们判定一个图灵在给定输入下是否能在有限步骤内停机. 其形式化描述如下 $$ \\mathsf{HALT}(x,\\alpha)=1\\iff M_\\alpha(x) \\text{ halts in finite steps } $$ 我们将通过归约的方法来证明这个问题不能被一台图灵机解决. 我们的思路是用一台图灵机$\\mathsf{UC}$问题转换为$\\mathsf{HALT}$问题, 那么如果$\\mathsf{HALT}$问题可以被一台图灵机解决, 则$\\mathsf{UC}$问题也可以被一台图灵机先转化为$\\mathsf{HALT}$问题再解决, 这就违背了$\\mathsf{UC}$问题不可解的前提, 也就是说我们的假设不成立, $\\mathsf{HALT}$问题不能被一台图灵机解决.\n假设有一台图灵机$M_\\mathsf{HALT}$能够解决$\\mathsf{HALT}$, 那么我们尝试就用他来结局$\\mathsf{UC}$. 构造图灵机$M_\\mathsf{UC}$用于计算$\\mathsf{UC}$.\n $M_\\mathsf{UC}(\\alpha)$的计算如下:\n$M_\\mathsf{UC}$首先调用$M_\\mathsf{HALT}(\\alpha, \\alpha)$, 如果他输出0, 则$M_\\mathsf{UC}(\\alpha)=1$. 否则, $M_\\mathsf{UC}$使用通用图灵机$\\mathcal U$来模拟计算$b=M_\\alpha(\\alpha)$并输出$\\bar b$.\n 这里需要稍微说一下为什么要这么归约. 其实之所以我们不能计算$\\mathsf{UC}$就是因为我们处理不了不停机的情况, 那么现在已经给出了能够处理不停机的情况的$M_\\mathsf{HALT}$, 我们直接调用它就可以了, 至于其他的情况, 我们可以使用通用图灵机来模拟计算即可.\n显然, 上述构造的$M_\\mathsf{UC}$能够在有限步骤内计算$\\mathsf{UC}$. 根据我们之前的解释, 能够在有限步骤内求解$\\mathsf{UC}$的图灵机不存在.\n丘奇-图灵论题 图灵机不能计算的问题, 人能够计算吗? 也许你会觉得你可以穷举所有的答案. 并不是这这样的, 我们已知丢番图方程问题是图灵不可计算的, 那么如果给你一组丢番图方程, 你能判定他是解还是没有解的吗? 也许这个方程组的解会会非常大, 大到你穷尽一生也无法找到他的解, 也或许他根本就没有解\u0026mdash;\u0026mdash;我们根本不能通过穷举来判定方程是否有解. 一些特殊的丢番图方程, 我们确实能找到求解或判定是否有解的办法, 但是对于所有的丢番图方程, 寻找通用的算法来判定它是否有解, 我们真的无能为力.\n图灵停机问题也是一样, 也许你面前的图灵机陷入了一个非常大的循环, 比如需要$10^{99}$步骤才能完成一个循环, 这个时候你根本无法判定. 即使你的寿命足够长, 判定了这个结果, 那么对于一个长达$10^{999999999999}$步的循环呢? 其实我们也没有办法解决这样的问题.\n根据大量合理的计算模型构造, 最后都被证明计算能力和图灵机的计算能力等价, 我们有如下结论\n 丘奇-图灵论题\n任何物理上可以实现的计算设施, 其计算都可以被一台图灵机模拟.\n 也即是说, 我们造不出来比图灵机更强的计算机. 这个论题虽然没有被证明, 但是也没有被证伪, 是计算理论的一条基本公理(或基本假设).\n$\\mathbf{R}$和$\\mathbf{RE}$ 为了避免读者没有接触过可计算性的知识, 我们首先解释两个术语: 判定和识别. 我们说判定和识别的时候, 都是针对某个语言而言, 正如我们在之前的文章中提到, 语言和判定问题可以视作是等价的概念.\n\u0026ldquo;语言$L$被图灵机$M$判定\u0026rdquo;, 就是说这台图灵机在接受到任何串$x$的输入时都能在有限步骤内停机, 且$M(x)=1\\iff x\\in L$. 换句话说, 图灵机$M$总是能在有限时间内给我们一个明确的答案$x\\in L$是否成立. 实际上这个一个非常准确的术语, 因为\u0026quot;判定\u0026quot;就是\u0026quot;判断\u0026rdquo;, 那么必须真($x\\in L$)假($x\\notin L$)命题都能判断.\n而\u0026quot;语言$L$被图灵机$M$识别\u0026quot;则是说, 图灵机$M$在接受到任意$x\\in L\\iff$M在有限步骤内停机且$M(x)=1$. 对于那些$x\\notin L$的串, $M$要么拒绝它(即在有限步骤内输出$0$), 要么不会停机. 同样, \u0026ldquo;识别\u0026quot;这个术语也是非常精确的, 即说任何$x\\in L$的串都能被$M$接受.\n这是我们最先接触到的一类问题, 虽然我们不去过多研究他们.\n 复杂度类$\\mathbf{R}$ $$ \\mathbf{R}=\\lbrace L:L \\text{ is turing computable}\\rbrace $$\n 它表示那些能被一台图灵机判定的语言的集合. 类似地,\n 复杂度类$\\mathbf{RE}$ $$ \\mathbf{RE}=\\lbrace L:\\exists M\\in\\mathbb M, \\forall x\\in L: M(x) \\text{ halts in finite steps}\\rbrace $$\n 表示能被一台图灵机识别的语言的集合.\n由于一个语言$L$能被某台图灵机$M$判定蕴含$L$能被$M$识别, 因此我们有$\\mathbf{R}\\subseteq \\mathbf {RE}$. 有关$\\mathbf R$更多的研究, 请参阅可算理论有关的书籍和论文.\n可数和不可数 如果我们只证明存在一些语言不能被一台图灵机判定, 而不需要找出一个具体这样的语言, 一个简单的技术可以很快地解决这个问题. 这个办法需要用到数学上可数的概念, 我们仅做简要说明. 显然, 根据图灵机的编码方式, 我们知道, 图灵机是可数的. 由于语言(即二进制串的集合)是不可数的, 我们建立一个图灵机集合$\\mathbb M$到语言集合$\\mathbb L$的映射, 那么根据有可数集到不可数集的映射不可能是满射, 肯定存在语言$L\\in\\mathbb L$不能被任何$M\\in\\mathbb M$映射到. 且任何一个$\\mathbb M$到$\\mathbb L$的映射都满足这样的性质, 那么\u0026quot;被解决\u0026rdquo;(即如果$M\\mapsto L\\iff M$判定$L$)这个映射也满足这个性质(它显然是一个映射, 因为一台图灵机至多能判定一个语言, 此外, 我们将所有不用于判定语言的图灵机映射到$\\emptyset$即可), 那么肯定有语言不能被图灵机判定.\n计算复杂性 在计算复杂性理论中, 我们要做的事情的为问题根据其难度分类(或者称分层), 但在这之前我们需要回答的问题时, 问题是否真的有难度之分?\n也许你曾经没有注意到, 有些问题真的很难, 因为试卷上让你求解问题真的都很简单—––我们这样说绝对没有针对你的意思, 因为我们所说困难, 不是你一个人做不出来, 而是也许所有人都做不出来. 现在, 让我们思考一下下面的问题.\n 命题\n在任意6个人中, 至少有3个人相互之间认识, 或者相互之间不认识.\n 上述命题是可以被证明的, 只是他的证明还是相对比较麻烦, 如果你没有学过这个命题, 但是有良好的数学基础, 应该能够在半个小时内证明他. 但是, 5个人可以吗? 7个人可以吗? 或者我们换一种问法: 至少需要多少个人, 才能保证其中至少3个人相互之间认识或者3个人相互之间不认识. 这个问题可以被推广, 就是判定给定$\\langle t,x,y\\rangle$个人, 判定, 是否$t$是满足命题\u0026quot;任意$t$个人中, 至少$x$个人相互之间认识, 或者$y$相互之间不认识\u0026quot;的最小正整数. 如果我们将人看作点, 将认识看作红边, 将不认识看作蓝边, 我们可以将问题叙述如下\n 问题\n求问$t$是否是满足如下命题的最小正整数: 在任意$t$个点且边被染成红色或蓝色的完全图$K_t$中, 至少存在一个红色的$x$个点的完全图$K_x$或蓝色的有$y$个点的完全图$K_y$.\n 你可以试试当$x,y$很大时解决这个问题有多难. 如果我们将满足命题的三元组$\\langle t,x,y\\rangle$看作是一个语言, 那么我们记$t=R(x,y)$. 这个问题难到, 人们到目前为止还不知道$R(5,5)$是多少.\n我们以上介绍的问题中, 这些满足条件且$x=y$的数就是Ramsey数(可翻译为拉姆齐数). 这个问题可以扩展为染成$n$个颜色的版本, 使得问题更加困难. 实际上你可以发现, 当输入的规模很小的时候, 解决这个问题已经足够困难, 因此我们对问题的复杂度做划分是有意义的.\n当然, 没人能说这个问题一定需要多少的步骤才能被解决, 也许有一个非常精巧的办法来解决他—\u0026mdash;这意味着这是一个相当简单的问题\u0026mdash;\u0026mdash;这种可能是存在的. 但是, 好在我们对问题复杂度进行划分的时候, 考虑的是上界, 也就是说解决一个问题的更优算法可能被发现, 但是他不影响我们已有的对他的复杂度的断定. 例如, 复杂度类$A$是包含在复杂度类$B$中的, 我们已知有个算法使得问题$L$一定在$B$中, 但是我们某一天发现了一个算法, 使得$L$在$A$中, 那么\u0026rdquo;$L$在$B $中\u0026quot;仍然是正确的.\n复杂性与复杂度类 我们不需要对\u0026quot;复杂度类\u0026quot;这个概念做过多的介绍, 因为定义他们的模型很不相同. 但是, 我们会对每个复杂度类做精确的定义, 在这之前, 我们先介绍重要的符号$\\mathbf{DTIME}(\\cdot)$.\n $\\mathbf{DTIME}(\\cdot)$ $$ \\mathbf{DTIME}(t(|x|))=\\lbrace L:\\exists c\\in \\mathbb N,\\exists M\\in \\mathbb M, \\forall x\\in\\lbrace0,1\\rbrace^\\ast: x\\in L\\iff M(x) =1 \\text{ and } M \\text{ halts in } t(|x|) \\text{ steps.}\\rbrace $$\n 也许符号看起来有些复杂, 但是你要适应并学会翻译这种语言, 在这里, 我们用自然语言将它陈述一次. \u0026ldquo;$\\forall x\\in\\lbrace0,1\\rbrace^\\ast: x\\in L\\iff M(x) =1$\u0026ldquo;很容易理解, 我们已经见过很多次了, 其实它就是说, $M$能够判定语言$L$. 前面加上\u0026rdquo;$\\exists M\\in \\mathbb M$\u0026rdquo;, 就是说存在一台图灵机能够判定$L$. 而\u0026rdquo;$\\exists c\\in \\mathbb N\\cdots\\text{ and } M \\text{ halts in } t(|x|) \\text{ steps.}$\u0026ldquo;则是对$M$的运行时间做了限定, 要求它必须在$t(|x|)$的某个常数倍内完成, 而\u0026rdquo;$\\exists c\\in \\mathbb N$\u0026ldquo;写在最前边则是要求我们最先确定$c$, 一旦$c$被确定, 就不能随着$x$变化而变化, 对于任何长度的$x$, $c$都必须是同一个值.\n$\\mathbf P$ $\\mathbf P$是最基础的复杂度类, 其定义相当简洁.\n $\\mathbf P$ $$ \\mathbf P = \\bigcup_{i\\in \\mathbb N}\\mathbf{DTIME}(n^i) $$ 其中$n$是输入的长度\n 用自然语言来说, $\\mathbf P$问题就是那些能够在输入长度的多项式步骤内被一台图灵机解决的问题. 如果单从自然语言来理解, 我们会想, 我们可以构造任意大的多项式, 这样不就可以让所有在有限步骤内可解的问题都是在输入的多项式时间内可解了吗? 是的, 但是要注意的是量词出现的顺序. 我们将定义展开来解释\n $\\mathbf P$ $$ \\mathbf P =\\lbrace L:\\exists M\\in\\mathbb M,\\exists C,c\\in \\mathbb N,\\forall x\\in L: M(x)=1\\iff x\\in L\\wedge (M \\text{ halts in } Cn^c \\text{ steps})\\rbrace $$\n 这个多项式的系数次数是出现在$x$之前的, 因此我们的要求是对于所有的$x$, 要有同样一个多项式来约束图灵机执行的步骤数. 实际上这就相当于是如果你宣称一个问题是$\\mathbf{P}$问题, 那么你就要经得起如下考验: 首先由你给出一个多项式和一台图灵机, 然后你的对手会给出一个输入规模, 在这个输入规模下的任何输入都能使得该图灵机在这个多项式时间内正确判定该问题. 在这个考验中, 你必须要总是胜利.\n指数时间 指数时间是另一个复杂度类, 记作$\\mathbf{EXP}$, 表示那些能够在一个指数时间下被一台图灵机判定的问题的集合. 其定义如下\n $\\mathbf{EXP}$ $$ \\mathbf{EXP}=\\bigcup_{i\\in\\mathbb N}\\mathbf{DTIME}(2^{n^i}) $$\n 类似地, 还可以定义双指数时间\n $\\mathbf{2EXP}$ $$ \\mathbf{2EXP}=\\bigcup_{i\\in \\mathbb N}\\mathbf{DTIME}(2^{2^{n^i}}) $$\n 实际上还可以定义$\\mathbf{3EXP},\\mathbf{4EXP}\\cdots$ 如果定义$E_0(i)=i, E_n(i)=2^{E_{n-1}(i)}$, 那么有 $$ \\mathbf{nEXP}=\\bigcup_{i\\in\\mathbb N}\\mathbf{DTIME}(2^{E_n(i)}) $$ 需要这多时间的问题人类能解吗? 耍滑的回答是能, 因为$\\mathbf{P}$问题也是它的子集, 至少我们能解$\\mathbf P$问题\u0026hellip;.但是目前为止, 我们知道肯定有一些问题, 在$\\mathbf{EXP}/\\mathbf P$内, 这个结论我们稍后再证明, 我们先介绍一个假设, 说明这些问题真的很难.\n丘奇-图灵强论题  丘奇-图灵强论题\n任何物理上可以实现的计算机器都可以被一台多项式时间内停机的图灵机模拟.\n 这句话是说, 物理上任何一台能够制造出来的计算机, 总能被一台图灵机模拟, 且存在一个多项式$p$使得这台图灵机在输入任何$x$时总能在$p(|x|)$时间内停机且输出和物理上实现的机器相同的输出.\n这个论题也仅仅是一个猜想, 但是目前为止也是尚未被证明. 该论题直接限制了我们的计算能力. 好消息是, 量子计算机的出现对这一论题发起了挑战, 也许我们真的能算出那些我们之前认为不可能算出的问题.\n时间谱系定理 你有没有想过, 是不是所有的$\\mathbf{P}$算法都能在线性时间内被求解, 只是我们没有找到相应的算法? 例如, 会不会有一种算法能够在线性时间内判定稀疏图的单源最短路径是否正确给出? 这个理想就要被我们下面介绍的定理打破.\n 时间谱系定理 (Hartmains and Stearns, 1965)\n设$f$和$g$是时间可构造函数, 且$f(n)\\log f(n)=o(g(n))$, 则$\\mathbf{DTIME}(f(n))\\subsetneq \\mathbf{DTIME}(g(n))$.\n 时间谱系定理的证明看起来很繁琐, 但是其还是利用我们之前介绍过的对角化方法. (可以理解为将模拟输出翻转后输出的方法).\n 证明: 定义语言$L$如下:\n设$L$被图灵机$D$判定, 输入$x$, $D$模拟$M_x(x)$的$g(|x|)$步计算. 如果模拟完成, 则输出$\\overline{M_x(x)}$, 否则输出$0$.\n根据上述定义, $L\\in\\mathbf{DTIME}(g(n))$, 因为我们最多计算$g(|x|)$步就强制输出答案. 现在假设$L\\in\\mathbf{DTIME}(f(n))$, 且设$M_z$就是那台在$ f(n)$时间内判定$L$的图灵机且$f(|z|)\\log f(|z|)\u0026lt;g(|z|)$. 则:\n $D(z)=M_z(z)$, 根据$D$和$M_z$都是判定$L$的这一假设 $D(z)=\\overline{M_z(Z)}$, 根据$D$能够完整模拟$M_z(z)$的计算  显然以上两个结论是矛盾的, 因此我们的假设\u0026rdquo;$L\\in\\mathbf{DTIME}(f(n))$\u0026ldquo;是错误的.\n 由此也可以得出, $\\mathbf P\\subsetneq\\mathbf{EXP}$\n其他主题 有关时间复杂性的重要定理, 如Gap定理和加速定理及其证明, 将在专题中完成. 这些结论是计算机科学中非常\u0026quot;怪\u0026quot;的结论, 因为我们日常根本见不到这样奇怪的问题, 但是它们确实存在.\n 加速定理: (未完成) Gap定理: (未完成)    健忘是对oblivous的翻译, 一般有两层意思: 1. 无关, 如这里执行的操作与输入的数据无关 2. 不泄露信息, 如密码学中的Oblivious Transformation (abbr. OT). 实际上2.的解释是可以归约到1.的, 我们在讲解到OT时会作一些解释.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2019-03-29T12:06:45Z","image":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A72-%E5%9B%BE%E7%81%B5%E6%9C%BA%E4%B8%8E%E5%8F%AF%E8%AE%A1%E7%AE%97%E6%80%A7/turing_machine_hu0166a620cecfe8b8446df8ecb324d4a0_390991_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A72-%E5%9B%BE%E7%81%B5%E6%9C%BA%E4%B8%8E%E5%8F%AF%E8%AE%A1%E7%AE%97%E6%80%A7/","title":"计算复杂性(2) 图灵机与可计算性"},{"content":" The following example can be regarded as a generalization of Pigeonhole Principle.\n\r Example 1\nIf every person likes at least $1/3$ of the books in a library, then the library has a book, which at least $1/3$ of people like.\n Proof: Suppose there are $N$ people in total and $B$ books in the library. Let all the people leave a mark on the books they like, then there are at least $NB/3$ marks. Presume there are no such book that has at least $M/3$ books on it, then the total number of marks would be less than $NB/3$, contradicted.\n When dealing with problems solved by the pigeonhole principle, we know the total number of pigeons and pigeonholes. For problems solved by averaging argument, we usually don\u0026rsquo;t see the number of pigeonholes or the number of pigeons or both of them. In this case, we \u0026ldquo;imagine\u0026rdquo; the number of pigeons and pigeonholes and keep them in mind.\nWhen talking about probability, the case is always the latter, because we don\u0026rsquo;t count the exact number of pigeons and their holes.\n Let\u0026rsquo;s introduce two formal discriptions of averaging argument.\n Averaging Argument\nLet $X$ and $Y$ be sets, and $p$ be a prediction on $X\\times Y$. Let $\\alpha$ be a real number in the interval $[0,1]$. If for each $x$ in $X$, there exists at least $\\alpha|Y|$ in $Y$ that satisfy $p(x,y)$. Then, there exists a $y$ in $Y$ such that there exist at least $\\alpha|X|$ elements $x$ in $X$ that satisfy $p(x,y)$.\n Proof: We can construct a proof of the same style as the proof of Example 1.\nNotice that averaging argument can be generalized to continuous sets $X$ and $Y$ as well as probabilistic situations in Averaging Argument.\n Averaging Argument \nLet $f$ be a function. If we have a circuit $C$ such that when $x$ is chosen uniformly at random and $y$ is chosen independently from some distribution $\\mathcal Y$ over $\\lbrace 0,1\\rbrace^m$, we have $C(x,y)=f(x)$ holds with probability at least $\\rho$. Then there exists a single string $y_0\\in\\lbrace0,1\\rbrace^m$ such that $\\Pr[C(x,y_0)]\u0026gt;\\rho$.\n Proof: Keeping the unseen pigeonhole number in mind, the proof might get simple. But we can also prove it in probabilistic style.\nIf there\u0026rsquo;s no such $y_0\\in\\lbrace0,1\\rbrace^m$ s.t. $\\Pr[C(x,y_0)]\u0026gt;\\rho$, then lets count the probability of $C(x,y)=f(x)$ s.t. $x$ is chosen uniformly at random and $y$ is chosen independently from some distribution $\\mathcal Y$. $$ \\begin{align} \\Pr_{x\\gets U,y\\gets \\mathcal Y}[C(x,y)=f(x)] \u0026amp;= \\sum_{y\\in\\lbrace0,1\\rbrace^m} \\Pr_{x\\gets U}[C(x,y)=f(x)]\\cdot \\Pr[\\mathcal y\\gets \\mathcal Y] \\\n\u0026amp;\u0026lt; \\sum_{y\\in\\lbrace0,1\\rbrace^m}\\rho\\Pr[\\mathcal y\\gets \\mathcal Y]=\\rho \\end{align} $$ Proof done.\n Averaging Argument  is a generalization of Averaging Argument, since it makes no limitation of $y$\u0026rsquo;s distribution, other than being independent to $x$.\n Averaging argument are used in the proofs of some interesting results of complexity. A simple example is the proof of $\\mathbf{BPP}\\in\\mathbf P_{/\\operatorname{poly}}$.\n Theorem\n$\\mathbf{BPP}\\in\\mathbf P_{/\\operatorname{poly}}$.\n Proof: For any $L\\in\\mathbf{BPP}$, there exists a polynomial time turing machine $\\mathsf {TM}$ s.t. $$ \\Pr_{r\\gets\\lbrace0,1\\rbrace^{p(n)}}[\\mathsf{TM}(x,r)\\neq L(x)]\\leq 1/2^{n+1} $$ holds for every $x\\in\\lbrace0,1\\rbrace^n$. We find out a $r_0$ s.t. $\\mathsf{TM}(x,r_0)=L(x)$ for all $x\\in\\lbrace0,1\\rbrace^n$. We interprete the above fact as follows:\nFor each $x\\in\\lbrace0,1\\rbrace^n$, there exists at least a $1-1/2^{n+1}$ fraction of $r$\u0026rsquo;s that makes $\\mathsf{TM}(x,r)=L(x)$ holds. Then by Averaging Argument, there exists a $r_0$ s.t. at least $1-1/2^{n+1}$ fraction of $x\\in\\lbrace0,1\\rbrace^n$ satisfy $\\mathsf{TM}(x,r_0)=L(x)$. Take this $r_0$ as advice, we get $L\\in \\mathbf P_{/\\operatorname{poly}}$.\n The basic idea of Averaging Argument can be used elsewhere.\nThe next exam is quite important, which will be used in the proof of Goldreich-Levin Theorem.\n Example 2\nLet $f$ be a function $f:\\lbrace0,1\\rbrace^n\\to \\lbrace0,1\\rbrace^{l(n)}$ and $f^\\prime :\\lbrace0,1\\rbrace^n \\times\\lbrace0,1\\rbrace^n\\to \\lbrace0,1\\rbrace^{l(n)}\\times \\lbrace0,1\\rbrace^n$ defines as $$ f^\\prime(x,r)=(f(x),r) $$ where $|x|=|r|$. Let $\\mathsf{gl}(x,r)=\\bigoplus_{i=1}^n x_i\\cdot r_i$.\nSuppose there exists a $\\mathsf{PPT}$ algorithm $\\mathcal A$ with running time $t$ and satisfy $$ \\Pr\\limits_{ x\\leftarrow{0,1}^n ;; r\\leftarrow{0,1}^n } [\\mathcal A(f(x),r)=\\mathsf{gl}(x,r)]\\geq\\frac 1 2+\\varepsilon(n) $$ Then there exists a set $\\mathcal S_n\\subseteq \\lbrace0,1\\rbrace^n$ of size at least $\\frac{\\varepsilon(n)}2\\cdot 2^n$ such that for every $x\\in \\mathcal S_n$ it holds that $$ \\Pr\\limits_{; r \\leftarrow {0,1}^n}[\\mathcal A(f(x),r)=\\mathsf{gl}(x,r)]\\geq \\frac 1 2+\\frac{\\varepsilon (n)} 2 $$\n Proof: Still, we keep in mind the unseen number of pigeonholes. We have \u0026ldquo;1\u0026rdquo; pigeonholes. \u0026ldquo;1\u0026rdquo; means if we choose a pigeonhole uniformly at random from all the pigeonholes then we have probability \u0026ldquo;1\u0026rdquo; that we chosen from the set of all pigeonholes… This is not verbose, since there are cases that we choose a pigeonhole from a subset with less than \u0026ldquo;1\u0026rdquo; pigeonhole.\nWe assume we have probability $p$ to choose $x$ from $\\mathcal S_n$ and then we have probability $(1-p)$ to choose $x$ from $\\overline{\\mathcal S_n}=\\lbrace0,1\\rbrace^n-\\mathcal S_n$. We want to reckon the lower bound of $\\mathcal S_n$, so we make event $\\Pr[\\mathcal A(f(x),r)=\\mathsf{gl}(x,r)]$ to happen as frequent as posible when $x\\gets \\mathcal S_n$. As for cases in $\\overline{\\mathcal S_n}$, by the assumption made it has to happen with probability as least $\\frac 1 2+\\frac{\\varepsilon (n)} 2$, then we have $$ \\frac 1 2+\\varepsilon(n) \\leq \\Pr\\limits_{x\\leftarrow{0,1}^n ;; r\\leftarrow{0,1}^n}[\\mathcal A(f(x),r)=\\mathsf{gl}(x,r)] \\leq p\\times 1+(1-p)\\times (\\frac 1 2+\\frac{\\varepsilon (n)} 2)\\leq p+\\frac 1 2+\\frac{\\varepsilon(n)}{2} $$ The las t inequality is obtained by drop $-p$ in $1-p$. By solving the inequality $$ p\\geq \\frac{\\varepsilon (n)}2 $$ Then we have $$ |\\mathcal S_n|\\geq \\frac{\\varepsilon(n)}2\\cdot 2^n $$\n","date":"2019-03-21T23:45:57Z","image":"https://lingerois.com/p/averaging-argument/cover_hu051f630a141098dbec723c4cdb2073a7_1476742_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/averaging-argument/","title":"Averaging Argument"},{"content":"计算问题 什么是计算机? 计算, 就是解决某个具体问题的算法, 得出相应的答案. 计算机就是能执行某个具体算法的机器. 即Computer就用来是Compute的机器. 此外, 讨论什么是机器, 对我们研究计算机科学毫无帮助, 你只需要知道, 计算机就是用来执行算法的机器. 我们要做的就是, 用最简单的理论模型, 最大程度的抽象化我们现有的计算机.\n语言  定义 语言\n一个字母表(alphabet)是一个非空有限集合, 该集合中的元素称为符号(symbol).\n一个字母表$\\Sigma$上的语言(language)是$\\Sigma$中的元素构成的有限序列(称为串, 即string)的集合.\n 例如字母表$\\Sigma=\\lbrace 0,1\\rbrace$, 则我们可以定义一个$\\Sigma$上的语言$L=\\lbrace x_1x_2\\cdots x_n:\\text{如果}x_i= 0,则x_{i+1}= 0\\rbrace$, 则该语言为 $$ L=\\lbrace\\varepsilon, 0,1,10,11,100,110,111,\\cdots\\rbrace $$ 即所有的$1$都出现在任何$0$之前的串. 其中, $\\varepsilon$表示空串, 即长度为$0$的串.\n这里要注意的是\n 我们说\u0026quot;序列\u0026quot;就要考虑顺序, 即$001$和$100$是不同的串. 串可以是空串, 即长度为$0$的串, 空串通常记作$\\varepsilon$.  我们也可用更加形式化的描述来定义语言.\n 定义 语言\n设$\\Sigma$是一个字母表, $\\Sigma^0=\\lbrace\\varepsilon\\rbrace$表示空串的集合, $\\Sigma^n=\\Sigma\\times \\Sigma\\times\\cdots\\times \\Sigma$为$n$个$\\Sigma$的直积. 则$\\Sigma$上的一个语言定义为$\\Sigma^\\ast=\\bigcup\\limits_{i\\in\\mathbb{N}}\\Sigma^i$的子集.\n 这里要注意的是$\\Sigma^0$不是空集, 而是含有一个特殊的元素$\\varepsilon$.\n语言这个词可以说是一个相当糟糕的术语, 我们在这里不对这个术语本身进行过多的讨论, 但我们举例说明语言有多强大. 我们举一个有意义的例子.\n例如, 一个语言可以用来表示所有的有向无环图, 我们试图用字母表$\\Sigma=\\lbrace 0,1\\rbrace$上的语言来对图进行编码. 首先我们需要表示图$G=(V,E)$中的$V$, 我们约定$\\dagger$之前的部分表示图中每个点的名称的长度$v$, 而$\\dagger$之后依次的每个长度为$v$的连续子串表示图所有点的名称. 在所有的名称后, 我们用另一个$\\dagger$作为分割, 其后依次的每个长度为$2v$子串表示一条有向边. 所有的有向边后以$\\ddagger$结束.\n例如图\n\r可以被表示为\n$$ 100\\dagger0010\\cdot0011\\cdot0101\\cdot0111\\cdot1000\\cdot1001\\cdot1010\\cdot1010\\cdot1011\\dagger\\0011\\to1000\\cdot0011\\to1010\\cdot0011\\to1010\\cdot0101\\to1011\\cdot\\0111\\to1000\\cdot0111\\to1011\\cdot 1000\\to1001\\cdot1011\\to0010\\cdot\\10011\\to1010\\ddagger $$\n在上述编码中, 作如下替换 $$ 0\\to01,1\\to10,\\dagger\\to00,\\ddagger\\to11,\\cdot\\to\\varepsilon $$ 即为该有向图的在该语言中的编码. 所有的有向无环图构成的语言, 即所有的有向无环图按照上述编码构成的语言. 值得一提的是, 上述语言对有向图的编码并不是双射, 但是我们可以增适当的限制使得该语言对有向图的编码成为双射.\n按照类似的方式, 我们可以用语言表示, 所有的合取范式\\无环布尔电路\\树等. 大多数情况下, 我们不讨论具体的编码方式, 而是直接讨论语言, 如\u0026quot;所有的合取范式构成的语言\u0026quot;.\n判定问题 计算理论中最简单的问题, 就是判定问题, 即只能用$\\text{YES},\\text{NO}$回答的问题. 这类问题非常普遍, 例如问某个有向图是不是有向无环图, 那么这个问题的算法, 实际上是建立了一个映射. 如果用$L_{G}$表示所有的有向图构成的语言, 并用$0,1$分别表示$\\text{YES},\\text{NO}$, 那么这个问题实际上就是建立了一个映射$f:\\lbrace 0,1\\rbrace^\\ast\\to \\lbrace 0,1\\rbrace$, 且$f(x)=1$当且仅当$x\\in L_G$. 而解决这个问题算法就是能够计算函数$f$的算法.\n不难得出, 每一个语言都对应一个判定问题, 因此我们不再区分语言和判定问题, 我们可以直接说判定问题$L_G$, 即判定一个有向图是否为有向无环图的问题. 此后的绝大多数情况, 我们关心的问题都是判定问题.\n有的读者会问, 为什么我们要如此关注判定问题? 因为在未接触到这方面理论的人的直观思维中, 判定问题是一类非常弱的问题, 弱到连自然数的加法都无法计算. 确实如此, 但是判定问题和非判定问题之间存在天然的关系, 每一个非判定问题都可以转换为判定问题. 例如, 计算问题$f:(x,y)\\mapsto x+y$可以转换为判定问题$g:\\lbrace(x,y,z):x,y,z\\in\\mathbb{Z}_+\\rbrace\\to\\lbrace 0,1\\rbrace$, 其中$g(x,y,z)=1$当且仅当$x+y=z$, 即判定$z$是否为$x$和$y$的和的问题. 而且两者的复杂度之间存在深刻的关系, 我们将在之后的章节中具体介绍.\n自动机模型 有限状态机  定义 有限状态机 (finite state machine) 一个有限状态机是一个五元组$(Q,\\Sigma,\\delta,q_0,F)$, 其中\n $Q$是一个有限集, 称为状态集 $\\Sigma$是一个有限集, 称为字母表 $\\delta:Q\\times\\Sigma \\to Q$称为转移函数 $q_0\\in Q$是起始状态 $F\\subseteq Q$是接受状态集  有限状态机也称为自动机(automaton).\n 自动机不是什么复杂的东西, 一个自动机可以用一张类似于这样的图表示:\n\r其中:\n  圆圈表示状态\n 有一条没有起点的箭头指向的状态为起始状态 双圈表示的状态是接受状态    带符号集的箭头表示转移函数中的一组映射\n例如$q_2\\overset{0,1}{\\longrightarrow}q_3$表示映射$(q_2,0)\\mapsto q_3$和$(q_2,1)\\mapsto q_3$两条映射\n  当有限自状态机处于某个状态的时候, 读取到相应的符号, 有限状态机会根据转移函数跳转到下一状态. 例如上图中, 当有限状态机处于$q_1$状态时, 如果读到的下一符号为$0$, 根据转移函数$(q_1,0)\\mapsto q_1$, 则在读取该符号后, 有限状态集仍会处于$q_1$状态\n注意:\n 有限状态机(finite state machine)也可以称为自动机(automaton), 但不能称为\u0026quot;有限自动机\u0026quot;. 我们说\u0026quot;自动机\u0026quot;就是指\u0026quot;有限状态机\u0026quot;, 而不是\u0026quot;有限状态机\u0026quot;\u0026ldquo;下推自动机\u0026quot;\u0026ldquo;非确定自动机\u0026quot;等一系列计算模型的统称.  复杂度类REG 现在我们要讨论一类相当简单的语言, 和由它们构成的复杂度类REG.\n从上面有关于自动机的描述, 我们可以看到, 当自动机$M=(Q,\\Sigma,\\delta,q_0,F)$处于起始状态$q_0$时, 我们输入一个$\\Sigma$上的串$x\\in\\Sigma^\\ast$, $M$会依次读取串$x$上的符号, 并根据状态机作相应的状态转换. 当整个串$x$读取完毕后, $M$可能处于某个接受状态$q\\in F$, 也可能处于某个非接受状态$q^\\prime\\notin F$. 如果一个串$x\\in \\Sigma^\\ast$使$M$按照上述运行方式运行后, 处于某个接受状态, 就记$M(x)=1$并称$M$接受串$x$, 否则记$M(x)0=$并称$M$拒绝串$x$.\n这里要注意拒绝状态有两种情况. 一种是在输入结束后, 自动机确实处于某个非接受状态. 另一种是, 在输入的过程中, 某一部计算根据状态和输入符号, 转移函数中并没有一条映射指出这种情况下机器应该转移到哪个状态. 即, 计算提前结束了.\n根据这一点, 我们可以发现, 自动机$M$根据上述运行的方式, 可以表示一个映射$f: \\Sigma^\\ast\\to\\lbrace 0,1\\rbrace$满足$f(x)=1$当且仅当$M(x)=1$. 如果一个语言$L$和一个自动机$M$满足$x\\in L$当且仅当$M(x)=1$我们就说$M$识别(recognize)$L$或判定(decide). 为了统一我们有关判定的问题的叙述, 我们总是使用\u0026quot;判定\u0026rdquo;.\n注意: 自动机是按照输入和转移函数按部就班地执行, 输入串中每一个符号都会让自动机执行一步, 且只会执行一步, 因此自动机总是在输入结束的时候停机, 因此不会出现不停机的情况. 在这样的限制下识别和判定是等价的, 但是对于其他的计算模型来说, 这两个概念并不等价.\n现在我们定义一类判定问题(不要忘了一个语言对应一个判定问题, 判定问题的集合就是语言的集合) $$ \\textsf{REG}=\\lbrace L:\\exists\\text{自动机}M: x\\in L\\iff M(x)\\rbrace $$ 即REG表示那些能够被一台自动机识别的语言.\n例: $L=\\lbrace所有包含\u0026quot;001\u0026quot;串\\rbrace\\in \\textsf{REG}$\n我们可以构造一台识别它的自动机来说明这一点\n\r自动机作为计算机 自动机可以被视为一台计算机, 但是是一台功能相当弱的计算机. 抽象能力比较强的读者可以发现, 自动机没有任何类似于内存的结构, 所有需要存储中间值的才能完成的判定问题都不能被自动机完成. 我们称一个计算模型能够解决问题的能力称为计算能力, 如果考虑的是判定问题, 那么它表示的就该模型能够判定的语言的集合的一些特征(如和其他模型能够判定的语言的).\n正则语言与自动机 正则语言 现在我们语言的三种运算方式, 它们的运算结果仍是一个语言. 设$L_1$与$L_2$均为语言, 定义它们之间的三种运算: $$ L_1\\circ L_2 = \\lbrace x_1x_2:x_1\\in L_1, x_2\\in L_2\\rbrace $$ 即$L_1\\circ L_2$是所有$L_1$中的串与$L_2$中的串拼接构成的串的集合, 在不产生歧义的时候, 这个圈可以不写. 根据concatenation的翻译, 我们可以称该运算为\u0026quot;串联\u0026rdquo;. $$ L_1\\cup L_2 = \\lbrace x:x\\in L_1 或 x\\in L_2\\rbrace $$ 它所表示的意义和集合的并集一样.\n而$L_1^\\ast$表示的是由$L_1$中的任意串重复任意次(如果重复$0$次就得到$\\varepsilon$)所得到的所有的串构成的集合. 例如$L_1=\\lbrace00, 01\\rbrace$, 那么$\\varepsilon,00,01,0000,0101,000000,010101$等都是$L_1^\\ast$的元素. 如果读者更倾向于形式化的定义, 那么$L_1^\\ast$可以定义为\n$$ L^0=\\lbrace\\varepsilon\\rbrace, \\quad L^n=\\lbrace x^n:x\\in L\\rbrace \\\nL^\\ast= \\bigcup_{i\\in\\mathbb{N}} L^i $$ 这三种运算称为**正则运算**, 我们不过度纠结运算的优先级问题, 并总是在需要的时候用括号表示运算的顺序.\n现在我们来定义正则语言(regular language), 它包括一类最基本的语言, 和这类最基本的语言按照上述三种方式做运算产生的语言.\n 定义 正则语言\n一个语言$L$是正则语言, 如果它满足以下命题之一\n $L=\\lbrace a\\rbrace$, 其中$a$是某个字母表$\\Sigma$上的符号; $L=\\lbrace\\varepsilon\\rbrace$; $L=\\emptyset$; $L=L_1\\cup L_2$, 其中$L_1$和$L_2$均为正则语言; $L=L_1\\circ L_2$, 其中$L_1$和$L_2$均为正则语言; $L=L_1^\\ast$, 其中$L_1$为正则语言;   要注意的是, 4.5.6.表示的运算中, 空集也可以参与, 并且有:\n 空集与任何语言作$\\circ$或$\\cup$运算得到的都是空集 $\\emptyset^\\ast=\\lbrace\\varepsilon\\rbrace$  这两点实际上也可以通过这些运算的定义得出.\n如果是初次接触正则语言可能会觉得有些奇怪, 但是我们在学习正则表达式并了解自动机与正则语言的关系后, 这个概念会变得更加清晰.\n从正则语言的定义种可以得到, 一个仅包含有限个串的语言总是一个正则语言, 因为它可以写成它的所有单个串构成的语言的$\\cup$. 而每个单个串构成的语言又可以看作是仅有一个长度为1的串构成的语言的并联.\n正则表达式 注意! 我们这里介绍的并不是用于在Linux系统中查询的正则表达式, 尽管我们介绍的正则表达式和它的功能一致. 但我们也会对Linux系统中的正则表达式某些符号的具体意思做出解释.\n正则表达式(regular expression)是用来描述一个正则语言的, 它由字母表种的符号, $\\cup$运算符, $\\circ$运算符, $^\\ast$运算符还有括号组成. 我们可以用这些符号连同括号的组合来表示一个正则语言, 同样的, 这里的$\\circ$在不产生歧义的情况下也可以略去不写.\n例如, 正则表达式$R = (0\\circ(0\\cup 1))^\\ast$, 表示语言 $$ L=\\lbrace\\varepsilon, 00, 01, 0000, 0100, 0101, \\cdots\\rbrace $$ 即所有长度为偶数且$1$只出现在从左至右第偶数位的串. 它的原理很简单, 它由长度为2单元$0\\circ (0\\cup 1)$重复任意次组成, 而在一以个单元种, 第一位必须是0, 第二位可以是1或0. 实际上这个语言确实是正则语言, 令$L_0=\\lbrace0\\rbrace, L_1=\\lbrace1\\rbrace$, 那么有 $$ L= (L_0\\circ (L_0\\cup L_1))^\\ast $$ 显然复合正则语言的定义.\n我们现在来定义正则表达式, 并用一些例子在说明它是如何运作的.\n 定义 正则表达式\n一个表达式$R$为正则表达式, 如果它是以下几种表达式之一\n $a$, 其中$a$是字母表$\\Sigma$中的一个元素; $\\varepsilon$; $\\emptyset$; $(R_1\\cup R_2)$, 其中$R_1$和$R_2$是正则表达式 $(R_1\\circ R_2)$, 其中$R_1$和$R_2$是正则表达式 $(R_1^\\ast)$, 其中$R_1$是正则表达式   同时这里也要注意和空集的运算, 与正则语言类似, 这里不再赘述.\n可以看出, 正则语言和正则表达式非常相似. 注意有时候, 我们会简化正则表达式的写法, 让整个串充当一个字母的角色, 并且可以用或($|$)连接一些串, 同时出现可选串$[]$. 例如 $$ R= (10 | 01) [00] 1 $$ 表示语言 $$ L={101,011,10001,01001} $$ 它的原理也非常简单, 每个串都是一些仅有字母表中一个符号构成的语言的串联, 而或($|$)表示的就是$\\cup$, 而$[x]$表示的是$x|\\varepsilon$. 用这种方式表达的正则表达式, 就是我们常用于查询的正则表达式.\n而如果或($|$)连接的是一些长度为1的串, 我们也更习惯将它表示为这些串的符号的集合, 例如$(a|b|c)^\\ast$可以表示为$\\lbracea,b,c\\rbrace^\\ast$, 如果这个集合就是字母表$\\Sigma$, 我们还可以写作$\\Sigma^\\ast$. 同时, 如果我们希望重复一个串$x$大于等于$1$次也可以用$x^+$来表示, 即$x^+=x \\circ (x^\\ast)$.\n例子 设$\\Sigma=\\lbrace 0,1\\rbrace$\n $0^\\ast 10^\\ast=\\lbrace w:w恰好有一个1\\rbrace$ $(\\Sigma\\Sigma\\Sigma)^\\ast=\\lbrace w:w的长度正好是3的倍数\\rbrace$ $2333(3^\\ast)=\\lbrace w:w是由2333开头且在之后是任意长度的纯3串\\rbrace$  注意: 我们始终没有证明正则语言和正则表达式的对等性, 即一个正则表达式表示一个正则语言, 一个正则语言总可以用一个正则表达式表示. 我们不打算证明这一点, 因为我们认为读者的直觉能够察觉这一点, 如果喜欢学习严格的证明, 还是请阅读教材或论文.\n 定理1\n一个语言$L$是正则语言, 当且仅当它能够被表示成某个正则表达式$R$.\n 非确定自动机 非确定性 非确定性(nondeterminism)是不是非确定自动机独有的, 我们还会在其他的计算模型中遇到非确定性, 因此我们决定先介绍非确定性, 再介绍非确定自动机.\n在自动机模型中, 一个自动机在接受相同的输入时, 总是执行相同的计算步骤, 并总是得到相同的结果, 这样的计算方式称为确定的(deterministic). 即, 计算步骤与时间无关(如果我们将从宇宙大爆炸到目前为止的时间视作一个隐藏的参数的话/如果读者知道实时系统的定义, 那么对这个描述应该不会感到突兀). 这可能有点决定论的味道, 但也是一种理解方式. 反之, 非确定性, 就是, 一次具体的计算过程, 与时间有关. 或者, 我们可以更加直观地说, 一台具有非确定性的计算机, 在接受相同输入时, 计算步骤和结果可能有所不同.\n非确定自动机 自动机具有确定性是因为自动机处在任意状态时, 对于某个具体的输入, 根据转移函数, 改机器仅能转移到至多一个状态, 即转移的结果是唯一的. 如果我们修改这一条定义, 将转移的方式改为不确定的, 那么我们就得到非确定自动机(nondeterministic automaton).\n为了避免读者对于陌生数学符号的恐惧, 我们解释一下超集. 有限集的超集非常容易理解, 一个有限集$S$的超集, 是它的所有子集的集合, 记作$\\mathcal{P}(S)$. 例如$S=\\lbrace a,b,c\\rbrace$, 那么它一共有8个子集 $$ \\emptyset,\\lbrace a\\rbrace,\\lbrace b\\rbrace,\\lbrace c\\rbrace,\\lbrace a b\\rbrace,\\lbrace ac\\rbrace,\\lbrace bc\\rbrace,\\lbrace a bc\\rbrace $$ 其超集就是以上8个集合组成的集族(一般我们称集合的集合为集族, 也可简称为族).\n 定义 非确定自动机\n一个非确定自动机是一个五元组$(Q,\\Sigma_{\\varepsilon},\\delta,q_0,F)$, 其中\n $Q$是一个有限集, 称为状态集 $\\Sigma_{\\varepsilon}$是一个有限集, 是字母表和空串$\\varepsilon$的并集. $\\delta:Q\\times\\Sigma_\\varepsilon \\to \\mathcal{P}(Q)$称为转移函数 $q_0\\in Q$是起始状态 $F\\subseteq Q$是接受状态集   这里与自动机相比, 唯一不同的一点在于转移函数, 非确定自动机的转移函数的上域(codomain)(注意不是值域!)变为了状态集$Q$的超集$\\mathcal{P}(Q)$. 除此之外, 非确定自动机的转移函数还能接受输入$\\varepsilon$, 即在不接受任何输入的时候也可能随机发生转移. 回想一下, 自动机在处于某个状态时, 接受某个符号会转移到一个唯一确定的状态, 而处于某个状态的非确定自动机, 接受某个符号的输入, 则会有一些状态构成的集合作为\u0026quot;候选\u0026quot;状态, 非确定自动机会随机地从这些状态中选择一个进行转移.\n如果我们将非确定自动机的每一次转移视作它产生了几个并行的计算分支, 那么我们由如下图所示的描述\n\r其中左图为自动机的计算步骤, 其每一步计算都是仅产生一个计算分支, 而整个计算过程由一个计算分支过程, 自动机是否决定某个串, 取决于这个唯一的计算分支是否在串的输入结束后处于接受状态. 类似的, 我们通过这一点将接受的概念推广到非确定自动机上.\n非确定自动机每一步都会产生多个计算分支, 而整个计算过程的计算分支可能会非常复杂. 非确定自动机的整个计算过程可以用一个深度和输入长度加1相等的树来表示, 其每个节点都是一个非确定自动机的状态, 而路径则是合法的转移. 通过这种方式, 我们可以知道, 每一条根到叶子的路径都是一条计算分支. 先在我们定义: 如果非确定自动机$N$在输入$x$时存在一条计算分支在输入结束后处于接受状态, 我们就说非确定自动机$N$接受输入$x$, 记作$N(x)=1$. 否则, 我们称非确定自动机$N$拒绝串$x$, 记作$N(x)=0$.\n例如下面的非确定自动机, 处在$q_1$状态时, 可能会随机转移到$q_3$状态. 而当它处于$q_2$状态并收到输入$a$时, 可能转移到$q_2$或$q_3$状态. 当模拟其计算过程时, 可以计算通过将每一步机器可能处于的状态视作一个集合(我们称为合法状态集), 并在收到某个输入符号时, 计算每个合法状态集中的状态对应该符号根据转移函数得到的状态集合的并集. 例如下图中的非确定自动机根据输入$bc$\n 首先在起始状态时, 可能随机转移到状态$q_3$, 因此此时的合法状态集是$\\lbrace q_1,q_3\\rbrace$ 在收到第一个输入$b$时, 状态$q_1$只能转移到$q_2$, 而状态$q_3$根据输入$b$无法转移, 因此这一步的合法状态集为$\\lbrace q_2\\rbrace$ 在收到第二个输入$c$时, 状态$q_2$无法转移, 因此这一步的合法状态集为$\\emptyset$.  因此该非确定自动机应该是拒绝串$bc$.\n\r如果熟悉并行计算, 那么非确定自动机的计算步骤可以理解为\u0026quot;并行的\u0026quot;, 即每一条计算分支相当于被非确定自动机并行的执行了. 需要注意的是, 计算分支数很可能是无限多的, 这样的机器在现实世界中也太可能被制造出, 但可以通过算法模拟.\n非确定自动机的计算能力 从自动机与非确定自动机的定义可以看出, 自动机是非确定自动机中很特殊的一类机器, 相当于是机器处于任意状态时, 收到任意输入符号, 仅能转移到至多一个状态的非确定自动机.\n现在我们通过建立一台指定任意非确定自动机$N$计算能力相同的自动机$M$, 来说明, 自动机和非确定自动的计算能力是相同的. 即\n 定理2\n设$L$为语言. 存在一台自动机$M$判定$L$, 当且仅当存在一台非确定自动机$N$判定$L$.\n 回想一下我们\u0026quot;合法状态集\u0026quot;, 非确定自动机$N$处在某一步计算时, 在接受另一个输入, 可以视作从一个合法状态集转移到了一个另一个合法状态集, 而一个输入是否被接受, 取决于非确定自动机在该输入下最后一步计算对应的合法状态集中是否有接受状态, 因此我们通过这一点, 将一台非确定自动机$N(Q, \\Sigma_\\varepsilon,\\delta, q_0,F)$, 变为一台自动机$M$.\n 由于每一步计算都视为合法状态集到合法状态集的转换, 因此, $M$中的状态集应该是$Q$的超集, 即$\\mathcal{P}(Q)$. 由于自动机不能发生随机转移, 因此, $\\varepsilon$不能参与转移, 即自动机的第二个参数退化为$\\Sigma$. 转移函数$\\delta^\\prime$肯定是一个$\\mathcal{P}(Q)\\times \\Sigma \\to \\mathcal{P}(Q)$的集合, 显然这个转移是确定的, 因为每一个$\\mathcal{P}(Q)$中的元素都能够被$M$的一个状态表示. $M$的起始$q_0^\\prime$状态是$q_0$及$q_0$能随机转移到的那些状态构成的集合. $M$的接受状态集是所有含有$F$中任意元素的集合的集合.  通过这样的转换, 我们容易证明, $M(x)=1$当且仅当$N(x)=1$.\n正则语言与非确定自动机 令人惊奇的是, 任何一个正则语言, 都能被一台非确定自动机判定, 而任何一台非确定自动机判定的语言都是正则语言. 我们不打算证明这一点(因为教材上的证明非常详细), 但是会介绍一下如何将一个正则语言转换为判定它的非确定自动机.\n 定理\n一个语言$L$是正则语言, 当且仅当存在一台非确定自动机$Ｎ$可以判定它.\n 广义非确定自动机**. 广义非确定自动机是非确定自动机的推广版本, 它的定义和非确定自动机类似. 唯一不同的一点在于, 其转移函数$\\delta$表示的映射是$Q\\times \\Pi \\to \\mathcal{P}(Q)$, 其中$\\Pi$表示所有正则表达式的集合. 用通俗的语言来讲, 它的状态集图上箭头的标号可以不仅是语言中的某个符号, 而是可以是整个正则表达式. 我们已经很清楚的知道, 每个正则表达式确实就是表示了某个正则语言, 因此, 广义非确定自动机的转移是在读取一个串后进行的.\n现在, 我们根据一个正则表达式可以做出最原始的广义非确定自动机, 例如对正则表达式$R$, 我们可以作出状态机图$q_0\\overset{R}{\\to}q_1$. 其中$q_0$是其实状态, $\\lbraceq_1\\rbrace$是接受状态集. 我们考虑正则语言的三种操作, 将它表示转移函数中的正则表达式仅有最基础的三种正则表达式(即$\\varepsilon$, $\\emptyset$, 单个符号$a$)的广义非确定自动机(这其中$\\emptyset$标注的转移函数又可以略去不写).\n我们的任务很简单: 逐步将判定$R$的广义非确定自动机$G$化为非确定自动机$N$. 首先, 如果$R$是三种最平凡的正则表达式($\\emptyset$, 仅含一个单个符号的正则表达式, 正则表达式$\\varepsilon$)中的一种, 那么$G$就已经是非确定自动机了. 如果$R$是由两个正则表达式$R_1,R_2$按照三种运算($\\cup$, $\\circ$, $\\ast$)组成的, 那么我们按照以下方式处理.\n  $R=R_1\\cup R_2$ 只需要将下图中的作图转换为右图即可. 如果左图中的$q_1$是接受状态, 则右图中的$q_{11},q_{12}$均为接受状态\n\r  $R=R_1\\circ R_2$ 只需将下图的左图转换为右图即可. 如果左图中的$q_1$是接受状态, 则右图中的$q_{12}$是接受状态.\n\r  $R=R_1^\\ast$ 只需将下图中的作图转换为右图即可\n\r  通过递归地进行以上三种操作, 任何一个正则表达式都可以在有限步骤内转为为一台判定它的非确定自动机, 因此我们证明了定理3. 同时, 根据定理1, 我们有\n 定理4\n语言$L$是正则语言, 当且仅当存在一台非确定自动机$N$, 满足$x\\in L\\iff N(x)=1$.\n 正则语言与自动机 根据定理2, 一台非确定自动机总能够转换为一台计算能力和它相同的非确定自动机, 因此, 根据定理4我们有\n 定理5\n语言$L$是正则语言, 当且仅当存在一台自动机$M$, 满足$x\\in L\\iff M(x)=1$.\n 泵引理 我们介绍的泵引理(pumping lemma)是一个用于判断一个语言是否为正则语言的引理. 泵引理给出了一个语言是正则语言的必要而非充分条件, 我们不证明该引理, 但是会对它做一些直观上的解释, 并且举例说名用它来证伪一个语言是正则语言.\n 引理6 泵引理\n假设 ${ L\\subseteq \\Sigma ^{*}}$是正则语言, 存在字符串 ${ w\\in L}$且$ { \\left|w\\right|\\geq n}$, 则以下说法成立：\n ${ \\left|xy\\right|\\leq n} $ ${ \\left|y\\right|\\geq 1}$ ${ \\forall k\\geq 0:xy^{k}z\\in L}$   习题  编写一个判定正则语言的程序$P_1:x\\to \\lbrace 0,1\\rbrace$, 程序的输入是一个正则表达式$R$和一个串$x$. 设正则表达式$R$表示的语言为$L$. $P_1(x)=1\\iff x\\in L$.  ","date":"2019-03-05T12:06:45Z","image":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A71-%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80/turing_machine_hu0166a620cecfe8b8446df8ecb324d4a0_390991_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A71-%E8%87%AA%E5%8A%A8%E6%9C%BA%E4%B8%8E%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80/","title":"计算复杂性(1) 自动机与正则语言"},{"content":"写在前面 该笔记是我学习计算复杂性课程以及阅读相关书籍的过程中整理的笔记及个人理解. 整理成笔记除了加深我的个人理解外, 在这里分享给大家, 一方面也是是希望更多人能够理解这些内容, 感受这个世界为我们准备的惊喜. 另一方面也是为现在或是将来准备学习计算机的同学展示他们或许没有接触到的计算机科学的一角, 让大家知道计算机科学内涵的深度和广度, 能够看到Coding以外其他的东西, 也许能改变他们以后的人生路径. 注意, 本文不能替代任何课程, 教材或论文, 想要真正学习计算复杂性知识, 还是需要通过正规途径学习. 除此之外, 计算复杂性是密码学等一系列计算机理论课程的基础, 想要从事计算机理论方面的研究, 该课程是技能树上必点的技能.\nThanks to Prof. Fu (Yuxi Fu) at SJTU for giving us wonderful lectures.\n如何学习? 不要沉溺于哲学问题(虽然可以作为兴趣偶尔讨论), 形式科学就要有形式科学该有的样子, 能从公理中得出的问题才是你该思考的问题.\n目录 目前目录中列出的是我个人至少知道要研究些什么的内容, 实际上这里远不止这么一点, 后续的内容我会在学习完毕相应内容后再补充.\n 自动机与正则语言 图灵机模型与可计算性 NP完备性 空间复杂性 多项式谱系 电路复杂性 随机化计算 扩展图和去随机化 计数复杂性 量子计算 交互证明 密码学 PCP定理  主要参考书目  Introduction to the Theory of Computation, Michael Sipser Computational Complexity: A Modern Approach, Sanjeev Arora and Boaz Barak  ","date":"2019-03-04T21:29:13Z","image":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A70-%E7%9B%AE%E5%BD%95/turing_machine_hu0166a620cecfe8b8446df8ecb324d4a0_390991_120x120_fill_q75_box_smart1.jpg","permalink":"https://lingerois.com/p/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A70-%E7%9B%AE%E5%BD%95/","title":"计算复杂性(0) 目录"}]